Progress[  0%], ETA[ 199m], Batch [  10], G_Loss[0.248], D_Real_Loss[1.476], D_Fake_Loss[0.364]
Progress[  0%], ETA[ 199m], Batch [  20], G_Loss[0.180], D_Real_Loss[0.747], D_Fake_Loss[0.574]
Progress[  0%], ETA[ 199m], Batch [  30], G_Loss[0.161], D_Real_Loss[0.934], D_Fake_Loss[0.559]
Progress[  0%], ETA[ 199m], Batch [  40], G_Loss[0.149], D_Real_Loss[0.696], D_Fake_Loss[0.731]
Progress[  0%], ETA[ 199m], Batch [  50], G_Loss[0.119], D_Real_Loss[0.470], D_Fake_Loss[0.944]
Progress[  0%], ETA[ 199m], Batch [  60], G_Loss[0.119], D_Real_Loss[0.681], D_Fake_Loss[0.822]
Progress[  0%], ETA[ 199m], Batch [  70], G_Loss[0.132], D_Real_Loss[0.782], D_Fake_Loss[0.634]
Progress[  0%], ETA[ 199m], Batch [  80], G_Loss[0.115], D_Real_Loss[0.544], D_Fake_Loss[0.824]
Progress[  0%], ETA[ 199m], Batch [  90], G_Loss[0.141], D_Real_Loss[0.838], D_Fake_Loss[0.587]
Progress[  0%], ETA[ 199m], Batch [ 100], G_Loss[0.123], D_Real_Loss[0.714], D_Fake_Loss[0.705]
Progress[  0%], ETA[ 199m], Batch [ 110], G_Loss[0.124], D_Real_Loss[0.742], D_Fake_Loss[0.743]
Progress[  0%], ETA[ 198m], Batch [ 120], G_Loss[0.121], D_Real_Loss[0.655], D_Fake_Loss[0.626]
Progress[  0%], ETA[ 198m], Batch [ 130], G_Loss[0.140], D_Real_Loss[0.635], D_Fake_Loss[0.732]
Progress[  0%], ETA[ 198m], Batch [ 140], G_Loss[0.131], D_Real_Loss[0.870], D_Fake_Loss[0.544]
Progress[  0%], ETA[ 198m], Batch [ 150], G_Loss[0.105], D_Real_Loss[0.597], D_Fake_Loss[0.815]
Progress[  0%], ETA[ 198m], Batch [ 160], G_Loss[0.134], D_Real_Loss[0.644], D_Fake_Loss[0.637]
Progress[  0%], ETA[ 198m], Batch [ 170], G_Loss[0.113], D_Real_Loss[0.616], D_Fake_Loss[0.763]
Progress[  0%], ETA[ 198m], Batch [ 180], G_Loss[0.131], D_Real_Loss[0.896], D_Fake_Loss[0.657]
Progress[  0%], ETA[ 198m], Batch [ 190], G_Loss[0.108], D_Real_Loss[0.641], D_Fake_Loss[0.743]
Progress[  0%], ETA[ 198m], Batch [ 200], G_Loss[0.110], D_Real_Loss[0.664], D_Fake_Loss[0.756]
    Saved train/batch000200_out.png
Progress[  0%], ETA[ 198m], Batch [ 210], G_Loss[0.115], D_Real_Loss[0.667], D_Fake_Loss[0.655]
Progress[  0%], ETA[ 198m], Batch [ 220], G_Loss[0.118], D_Real_Loss[0.688], D_Fake_Loss[0.639]
Progress[  1%], ETA[ 197m], Batch [ 230], G_Loss[0.112], D_Real_Loss[0.623], D_Fake_Loss[0.635]
Progress[  1%], ETA[ 197m], Batch [ 240], G_Loss[0.117], D_Real_Loss[0.626], D_Fake_Loss[0.671]
Progress[  1%], ETA[ 197m], Batch [ 250], G_Loss[0.126], D_Real_Loss[0.743], D_Fake_Loss[0.587]
Progress[  1%], ETA[ 197m], Batch [ 260], G_Loss[0.143], D_Real_Loss[0.779], D_Fake_Loss[0.525]
Progress[  1%], ETA[ 197m], Batch [ 270], G_Loss[0.125], D_Real_Loss[0.761], D_Fake_Loss[0.556]
Progress[  1%], ETA[ 197m], Batch [ 280], G_Loss[0.123], D_Real_Loss[0.703], D_Fake_Loss[0.582]
Progress[  1%], ETA[ 197m], Batch [ 290], G_Loss[0.116], D_Real_Loss[0.567], D_Fake_Loss[0.734]
Progress[  1%], ETA[ 197m], Batch [ 300], G_Loss[0.102], D_Real_Loss[0.541], D_Fake_Loss[0.748]
Progress[  1%], ETA[ 197m], Batch [ 310], G_Loss[0.121], D_Real_Loss[0.782], D_Fake_Loss[0.671]
Progress[  1%], ETA[ 197m], Batch [ 320], G_Loss[0.150], D_Real_Loss[0.713], D_Fake_Loss[0.608]
Progress[  1%], ETA[ 197m], Batch [ 330], G_Loss[0.151], D_Real_Loss[0.787], D_Fake_Loss[0.568]
Progress[  1%], ETA[ 197m], Batch [ 340], G_Loss[0.121], D_Real_Loss[0.644], D_Fake_Loss[0.693]
Progress[  1%], ETA[ 197m], Batch [ 350], G_Loss[0.134], D_Real_Loss[0.664], D_Fake_Loss[0.628]
Progress[  1%], ETA[ 196m], Batch [ 360], G_Loss[0.124], D_Real_Loss[0.686], D_Fake_Loss[0.579]
Progress[  1%], ETA[ 196m], Batch [ 370], G_Loss[0.123], D_Real_Loss[0.703], D_Fake_Loss[0.629]
Progress[  1%], ETA[ 196m], Batch [ 380], G_Loss[0.123], D_Real_Loss[0.671], D_Fake_Loss[0.576]
Progress[  1%], ETA[ 196m], Batch [ 390], G_Loss[0.104], D_Real_Loss[0.585], D_Fake_Loss[0.704]
Progress[  1%], ETA[ 196m], Batch [ 400], G_Loss[0.126], D_Real_Loss[0.679], D_Fake_Loss[0.637]
    Saved train/batch000400_out.png
Progress[  1%], ETA[ 196m], Batch [ 410], G_Loss[0.107], D_Real_Loss[0.656], D_Fake_Loss[0.712]
Progress[  1%], ETA[ 196m], Batch [ 420], G_Loss[0.100], D_Real_Loss[0.558], D_Fake_Loss[0.823]
Progress[  1%], ETA[ 196m], Batch [ 430], G_Loss[0.127], D_Real_Loss[0.688], D_Fake_Loss[0.577]
Progress[  1%], ETA[ 196m], Batch [ 440], G_Loss[0.132], D_Real_Loss[0.708], D_Fake_Loss[0.552]
Progress[  1%], ETA[ 196m], Batch [ 450], G_Loss[0.123], D_Real_Loss[0.727], D_Fake_Loss[0.630]
Progress[  1%], ETA[ 196m], Batch [ 460], G_Loss[0.129], D_Real_Loss[0.696], D_Fake_Loss[0.618]
Progress[  2%], ETA[ 196m], Batch [ 470], G_Loss[0.136], D_Real_Loss[0.768], D_Fake_Loss[0.644]
Progress[  2%], ETA[ 195m], Batch [ 480], G_Loss[0.125], D_Real_Loss[0.681], D_Fake_Loss[0.618]
Progress[  2%], ETA[ 195m], Batch [ 490], G_Loss[0.108], D_Real_Loss[0.708], D_Fake_Loss[0.632]
Progress[  2%], ETA[ 195m], Batch [ 500], G_Loss[0.132], D_Real_Loss[0.681], D_Fake_Loss[0.718]
Progress[  2%], ETA[ 195m], Batch [ 510], G_Loss[0.121], D_Real_Loss[0.714], D_Fake_Loss[0.573]
Progress[  2%], ETA[ 195m], Batch [ 520], G_Loss[0.108], D_Real_Loss[0.621], D_Fake_Loss[0.782]
Progress[  2%], ETA[ 195m], Batch [ 530], G_Loss[0.115], D_Real_Loss[0.772], D_Fake_Loss[0.599]
Progress[  2%], ETA[ 195m], Batch [ 540], G_Loss[0.139], D_Real_Loss[0.819], D_Fake_Loss[0.487]
Progress[  2%], ETA[ 195m], Batch [ 550], G_Loss[0.109], D_Real_Loss[0.580], D_Fake_Loss[0.722]
Progress[  2%], ETA[ 195m], Batch [ 560], G_Loss[0.096], D_Real_Loss[0.450], D_Fake_Loss[0.898]
Progress[  2%], ETA[ 195m], Batch [ 570], G_Loss[0.133], D_Real_Loss[0.598], D_Fake_Loss[0.572]
Progress[  2%], ETA[ 195m], Batch [ 580], G_Loss[0.149], D_Real_Loss[0.576], D_Fake_Loss[0.599]
Progress[  2%], ETA[ 195m], Batch [ 590], G_Loss[0.116], D_Real_Loss[0.635], D_Fake_Loss[0.673]
Progress[  2%], ETA[ 194m], Batch [ 600], G_Loss[0.101], D_Real_Loss[0.548], D_Fake_Loss[0.808]
    Saved train/batch000600_out.png
Progress[  2%], ETA[ 194m], Batch [ 610], G_Loss[0.111], D_Real_Loss[0.665], D_Fake_Loss[0.682]
Progress[  2%], ETA[ 194m], Batch [ 620], G_Loss[0.145], D_Real_Loss[0.765], D_Fake_Loss[0.703]
Progress[  2%], ETA[ 194m], Batch [ 630], G_Loss[0.129], D_Real_Loss[0.626], D_Fake_Loss[0.604]
Progress[  2%], ETA[ 194m], Batch [ 640], G_Loss[0.109], D_Real_Loss[0.571], D_Fake_Loss[0.689]
Progress[  2%], ETA[ 194m], Batch [ 650], G_Loss[0.133], D_Real_Loss[0.637], D_Fake_Loss[0.569]
Progress[  2%], ETA[ 194m], Batch [ 660], G_Loss[0.107], D_Real_Loss[0.608], D_Fake_Loss[0.730]
Progress[  2%], ETA[ 194m], Batch [ 670], G_Loss[0.097], D_Real_Loss[0.472], D_Fake_Loss[0.811]
Progress[  2%], ETA[ 194m], Batch [ 680], G_Loss[0.136], D_Real_Loss[0.646], D_Fake_Loss[0.609]
Progress[  2%], ETA[ 194m], Batch [ 690], G_Loss[0.147], D_Real_Loss[0.703], D_Fake_Loss[0.496]
Progress[  2%], ETA[ 194m], Batch [ 700], G_Loss[0.099], D_Real_Loss[0.426], D_Fake_Loss[0.870]
Progress[  3%], ETA[ 194m], Batch [ 710], G_Loss[0.163], D_Real_Loss[0.640], D_Fake_Loss[0.658]
Progress[  3%], ETA[ 193m], Batch [ 720], G_Loss[0.112], D_Real_Loss[0.439], D_Fake_Loss[0.824]
Progress[  3%], ETA[ 193m], Batch [ 730], G_Loss[0.117], D_Real_Loss[0.670], D_Fake_Loss[0.725]
Progress[  3%], ETA[ 193m], Batch [ 740], G_Loss[0.124], D_Real_Loss[0.738], D_Fake_Loss[0.599]
Progress[  3%], ETA[ 193m], Batch [ 750], G_Loss[0.110], D_Real_Loss[0.780], D_Fake_Loss[0.721]
Progress[  3%], ETA[ 193m], Batch [ 760], G_Loss[0.102], D_Real_Loss[0.445], D_Fake_Loss[0.847]
Progress[  3%], ETA[ 193m], Batch [ 770], G_Loss[0.122], D_Real_Loss[0.578], D_Fake_Loss[0.631]
Progress[  3%], ETA[ 193m], Batch [ 780], G_Loss[0.135], D_Real_Loss[0.772], D_Fake_Loss[0.510]
Progress[  3%], ETA[ 193m], Batch [ 790], G_Loss[0.135], D_Real_Loss[0.474], D_Fake_Loss[0.501]
Progress[  3%], ETA[ 193m], Batch [ 800], G_Loss[0.119], D_Real_Loss[0.386], D_Fake_Loss[0.625]
    Saved train/batch000800_out.png
Progress[  3%], ETA[ 193m], Batch [ 810], G_Loss[0.193], D_Real_Loss[0.869], D_Fake_Loss[0.304]
Progress[  3%], ETA[ 193m], Batch [ 820], G_Loss[0.142], D_Real_Loss[0.697], D_Fake_Loss[0.575]
Progress[  3%], ETA[ 193m], Batch [ 830], G_Loss[0.140], D_Real_Loss[0.755], D_Fake_Loss[0.506]
Progress[  3%], ETA[ 192m], Batch [ 840], G_Loss[0.118], D_Real_Loss[0.600], D_Fake_Loss[0.692]
Progress[  3%], ETA[ 192m], Batch [ 850], G_Loss[0.152], D_Real_Loss[0.607], D_Fake_Loss[0.582]
Progress[  3%], ETA[ 192m], Batch [ 860], G_Loss[0.096], D_Real_Loss[0.394], D_Fake_Loss[0.896]
Progress[  3%], ETA[ 192m], Batch [ 870], G_Loss[0.118], D_Real_Loss[0.731], D_Fake_Loss[0.778]
Progress[  3%], ETA[ 192m], Batch [ 880], G_Loss[0.153], D_Real_Loss[0.730], D_Fake_Loss[0.437]
Progress[  3%], ETA[ 192m], Batch [ 890], G_Loss[0.130], D_Real_Loss[0.456], D_Fake_Loss[0.528]
Progress[  3%], ETA[ 192m], Batch [ 900], G_Loss[0.142], D_Real_Loss[0.694], D_Fake_Loss[0.578]
Progress[  3%], ETA[ 192m], Batch [ 910], G_Loss[0.187], D_Real_Loss[1.173], D_Fake_Loss[0.284]
Progress[  3%], ETA[ 192m], Batch [ 920], G_Loss[0.111], D_Real_Loss[0.702], D_Fake_Loss[0.738]
Progress[  3%], ETA[ 192m], Batch [ 930], G_Loss[0.115], D_Real_Loss[0.634], D_Fake_Loss[0.710]
Progress[  3%], ETA[ 192m], Batch [ 940], G_Loss[0.140], D_Real_Loss[0.745], D_Fake_Loss[0.473]
Progress[  4%], ETA[ 192m], Batch [ 950], G_Loss[0.120], D_Real_Loss[0.780], D_Fake_Loss[0.646]
Progress[  4%], ETA[ 191m], Batch [ 960], G_Loss[0.099], D_Real_Loss[0.636], D_Fake_Loss[0.886]
Progress[  4%], ETA[ 191m], Batch [ 970], G_Loss[0.132], D_Real_Loss[0.609], D_Fake_Loss[0.674]
Progress[  4%], ETA[ 191m], Batch [ 980], G_Loss[0.183], D_Real_Loss[0.770], D_Fake_Loss[0.328]
Progress[  4%], ETA[ 191m], Batch [ 990], G_Loss[0.125], D_Real_Loss[0.579], D_Fake_Loss[0.727]
Progress[  4%], ETA[ 191m], Batch [1000], G_Loss[0.136], D_Real_Loss[0.544], D_Fake_Loss[0.545]
    Saved train/batch001000_out.png
Progress[  4%], ETA[ 191m], Batch [1010], G_Loss[0.191], D_Real_Loss[1.412], D_Fake_Loss[0.254]
Progress[  4%], ETA[ 191m], Batch [1020], G_Loss[0.181], D_Real_Loss[1.109], D_Fake_Loss[0.437]
Progress[  4%], ETA[ 191m], Batch [1030], G_Loss[0.148], D_Real_Loss[0.900], D_Fake_Loss[0.443]
Progress[  4%], ETA[ 191m], Batch [1040], G_Loss[0.161], D_Real_Loss[0.721], D_Fake_Loss[0.363]
Progress[  4%], ETA[ 191m], Batch [1050], G_Loss[0.111], D_Real_Loss[0.753], D_Fake_Loss[0.711]
Progress[  4%], ETA[ 191m], Batch [1060], G_Loss[0.105], D_Real_Loss[0.419], D_Fake_Loss[0.764]
Progress[  4%], ETA[ 190m], Batch [1070], G_Loss[0.106], D_Real_Loss[0.415], D_Fake_Loss[0.735]
Progress[  4%], ETA[ 190m], Batch [1080], G_Loss[0.119], D_Real_Loss[0.527], D_Fake_Loss[0.802]
Progress[  4%], ETA[ 190m], Batch [1090], G_Loss[0.099], D_Real_Loss[0.447], D_Fake_Loss[0.778]
Progress[  4%], ETA[ 190m], Batch [1100], G_Loss[0.134], D_Real_Loss[0.657], D_Fake_Loss[0.581]
Progress[  4%], ETA[ 190m], Batch [1110], G_Loss[0.119], D_Real_Loss[0.671], D_Fake_Loss[0.645]
Progress[  4%], ETA[ 190m], Batch [1120], G_Loss[0.106], D_Real_Loss[0.783], D_Fake_Loss[0.718]
Progress[  4%], ETA[ 190m], Batch [1130], G_Loss[0.078], D_Real_Loss[0.571], D_Fake_Loss[1.118]
Progress[  4%], ETA[ 190m], Batch [1140], G_Loss[0.105], D_Real_Loss[0.704], D_Fake_Loss[0.782]
Progress[  4%], ETA[ 190m], Batch [1150], G_Loss[0.106], D_Real_Loss[0.579], D_Fake_Loss[0.829]
Progress[  4%], ETA[ 190m], Batch [1160], G_Loss[0.132], D_Real_Loss[0.582], D_Fake_Loss[0.624]
Progress[  4%], ETA[ 190m], Batch [1170], G_Loss[0.148], D_Real_Loss[0.882], D_Fake_Loss[0.436]
Progress[  4%], ETA[ 190m], Batch [1180], G_Loss[0.100], D_Real_Loss[0.509], D_Fake_Loss[0.856]
Progress[  5%], ETA[ 189m], Batch [1190], G_Loss[0.102], D_Real_Loss[0.537], D_Fake_Loss[0.740]
Progress[  5%], ETA[ 189m], Batch [1200], G_Loss[0.116], D_Real_Loss[0.526], D_Fake_Loss[0.749]
    Saved train/batch001200_out.png
Progress[  5%], ETA[ 189m], Batch [1210], G_Loss[0.115], D_Real_Loss[0.653], D_Fake_Loss[0.642]
Progress[  5%], ETA[ 189m], Batch [1220], G_Loss[0.114], D_Real_Loss[0.539], D_Fake_Loss[0.686]
Progress[  5%], ETA[ 189m], Batch [1230], G_Loss[0.101], D_Real_Loss[0.415], D_Fake_Loss[0.848]
Progress[  5%], ETA[ 189m], Batch [1240], G_Loss[0.133], D_Real_Loss[0.823], D_Fake_Loss[0.474]
Progress[  5%], ETA[ 189m], Batch [1250], G_Loss[0.115], D_Real_Loss[0.632], D_Fake_Loss[0.649]
Progress[  5%], ETA[ 189m], Batch [1260], G_Loss[0.088], D_Real_Loss[0.480], D_Fake_Loss[0.924]
Progress[  5%], ETA[ 189m], Batch [1270], G_Loss[0.171], D_Real_Loss[0.892], D_Fake_Loss[0.337]
Progress[  5%], ETA[ 189m], Batch [1280], G_Loss[0.107], D_Real_Loss[0.530], D_Fake_Loss[0.720]
Progress[  5%], ETA[ 189m], Batch [1290], G_Loss[0.117], D_Real_Loss[0.729], D_Fake_Loss[0.674]
Progress[  5%], ETA[ 189m], Batch [1300], G_Loss[0.104], D_Real_Loss[0.744], D_Fake_Loss[0.716]
Progress[  5%], ETA[ 188m], Batch [1310], G_Loss[0.119], D_Real_Loss[0.591], D_Fake_Loss[0.617]
Progress[  5%], ETA[ 188m], Batch [1320], G_Loss[0.130], D_Real_Loss[0.614], D_Fake_Loss[0.711]
Progress[  5%], ETA[ 188m], Batch [1330], G_Loss[0.110], D_Real_Loss[0.873], D_Fake_Loss[0.622]
Progress[  5%], ETA[ 188m], Batch [1340], G_Loss[0.101], D_Real_Loss[0.485], D_Fake_Loss[0.701]
Progress[  5%], ETA[ 188m], Batch [1350], G_Loss[0.119], D_Real_Loss[0.772], D_Fake_Loss[0.579]
Progress[  5%], ETA[ 188m], Batch [1360], G_Loss[0.108], D_Real_Loss[0.470], D_Fake_Loss[0.867]
Progress[  5%], ETA[ 188m], Batch [1370], G_Loss[0.122], D_Real_Loss[0.646], D_Fake_Loss[0.583]
Progress[  5%], ETA[ 188m], Batch [1380], G_Loss[0.111], D_Real_Loss[0.570], D_Fake_Loss[0.668]
Progress[  5%], ETA[ 188m], Batch [1390], G_Loss[0.106], D_Real_Loss[0.604], D_Fake_Loss[0.780]
Progress[  5%], ETA[ 188m], Batch [1400], G_Loss[0.129], D_Real_Loss[0.786], D_Fake_Loss[0.515]
    Saved train/batch001400_out.png
Progress[  5%], ETA[ 188m], Batch [1410], G_Loss[0.151], D_Real_Loss[1.075], D_Fake_Loss[0.407]
Progress[  5%], ETA[ 188m], Batch [1420], G_Loss[0.158], D_Real_Loss[0.818], D_Fake_Loss[0.479]
Progress[  6%], ETA[ 187m], Batch [1430], G_Loss[0.144], D_Real_Loss[0.776], D_Fake_Loss[0.513]
Progress[  6%], ETA[ 187m], Batch [1440], G_Loss[0.123], D_Real_Loss[0.658], D_Fake_Loss[0.563]
Progress[  6%], ETA[ 187m], Batch [1450], G_Loss[0.152], D_Real_Loss[0.587], D_Fake_Loss[0.441]
Progress[  6%], ETA[ 187m], Batch [1460], G_Loss[0.091], D_Real_Loss[0.381], D_Fake_Loss[1.136]
Progress[  6%], ETA[ 187m], Batch [1470], G_Loss[0.126], D_Real_Loss[0.855], D_Fake_Loss[0.593]
Progress[  6%], ETA[ 187m], Batch [1480], G_Loss[0.128], D_Real_Loss[0.554], D_Fake_Loss[0.505]
Progress[  6%], ETA[ 187m], Batch [1490], G_Loss[0.108], D_Real_Loss[0.688], D_Fake_Loss[0.691]
Progress[  6%], ETA[ 187m], Batch [1500], G_Loss[0.123], D_Real_Loss[0.571], D_Fake_Loss[0.574]
Progress[  6%], ETA[ 187m], Batch [1510], G_Loss[0.133], D_Real_Loss[0.629], D_Fake_Loss[0.519]
Progress[  6%], ETA[ 187m], Batch [1520], G_Loss[0.107], D_Real_Loss[0.554], D_Fake_Loss[0.727]
Progress[  6%], ETA[ 187m], Batch [1530], G_Loss[0.126], D_Real_Loss[0.510], D_Fake_Loss[0.559]
Progress[  6%], ETA[ 187m], Batch [1540], G_Loss[0.136], D_Real_Loss[0.616], D_Fake_Loss[0.510]
Progress[  6%], ETA[ 187m], Batch [1550], G_Loss[0.109], D_Real_Loss[0.707], D_Fake_Loss[0.775]
Progress[  6%], ETA[ 186m], Batch [1560], G_Loss[0.164], D_Real_Loss[1.000], D_Fake_Loss[0.350]
Progress[  6%], ETA[ 186m], Batch [1570], G_Loss[0.142], D_Real_Loss[0.683], D_Fake_Loss[0.458]
Progress[  6%], ETA[ 186m], Batch [1580], G_Loss[0.099], D_Real_Loss[0.552], D_Fake_Loss[0.851]
Progress[  6%], ETA[ 186m], Batch [1590], G_Loss[0.120], D_Real_Loss[0.506], D_Fake_Loss[0.575]
Progress[  6%], ETA[ 186m], Batch [1600], G_Loss[0.155], D_Real_Loss[0.716], D_Fake_Loss[0.396]
    Saved train/batch001600_out.png
Progress[  6%], ETA[ 186m], Batch [1610], G_Loss[0.106], D_Real_Loss[0.594], D_Fake_Loss[0.702]
Progress[  6%], ETA[ 186m], Batch [1620], G_Loss[0.137], D_Real_Loss[0.832], D_Fake_Loss[0.488]
Progress[  6%], ETA[ 186m], Batch [1630], G_Loss[0.144], D_Real_Loss[0.936], D_Fake_Loss[0.427]
Progress[  6%], ETA[ 186m], Batch [1640], G_Loss[0.099], D_Real_Loss[0.682], D_Fake_Loss[0.782]
Progress[  6%], ETA[ 186m], Batch [1650], G_Loss[0.143], D_Real_Loss[0.901], D_Fake_Loss[0.481]
Progress[  6%], ETA[ 186m], Batch [1660], G_Loss[0.112], D_Real_Loss[0.594], D_Fake_Loss[0.649]
Progress[  6%], ETA[ 186m], Batch [1670], G_Loss[0.116], D_Real_Loss[0.731], D_Fake_Loss[0.713]
Progress[  7%], ETA[ 185m], Batch [1680], G_Loss[0.101], D_Real_Loss[0.530], D_Fake_Loss[0.828]
Progress[  7%], ETA[ 185m], Batch [1690], G_Loss[0.146], D_Real_Loss[0.605], D_Fake_Loss[0.434]
Progress[  7%], ETA[ 185m], Batch [1700], G_Loss[0.124], D_Real_Loss[0.879], D_Fake_Loss[0.592]
Progress[  7%], ETA[ 185m], Batch [1710], G_Loss[0.169], D_Real_Loss[1.059], D_Fake_Loss[0.476]
Progress[  7%], ETA[ 185m], Batch [1720], G_Loss[0.143], D_Real_Loss[0.671], D_Fake_Loss[0.581]
Progress[  7%], ETA[ 185m], Batch [1730], G_Loss[0.137], D_Real_Loss[0.704], D_Fake_Loss[0.554]
Progress[  7%], ETA[ 185m], Batch [1740], G_Loss[0.093], D_Real_Loss[0.345], D_Fake_Loss[0.968]
Progress[  7%], ETA[ 185m], Batch [1750], G_Loss[0.125], D_Real_Loss[0.631], D_Fake_Loss[0.560]
Progress[  7%], ETA[ 185m], Batch [1760], G_Loss[0.150], D_Real_Loss[1.020], D_Fake_Loss[0.409]
Progress[  7%], ETA[ 185m], Batch [1770], G_Loss[0.118], D_Real_Loss[0.382], D_Fake_Loss[0.629]
Progress[  7%], ETA[ 185m], Batch [1780], G_Loss[0.167], D_Real_Loss[0.661], D_Fake_Loss[0.358]
Progress[  7%], ETA[ 185m], Batch [1790], G_Loss[0.112], D_Real_Loss[0.464], D_Fake_Loss[0.663]
Progress[  7%], ETA[ 184m], Batch [1800], G_Loss[0.128], D_Real_Loss[0.606], D_Fake_Loss[0.595]
    Saved train/batch001800_out.png
Progress[  7%], ETA[ 184m], Batch [1810], G_Loss[0.108], D_Real_Loss[0.470], D_Fake_Loss[0.712]
Progress[  7%], ETA[ 184m], Batch [1820], G_Loss[0.143], D_Real_Loss[0.810], D_Fake_Loss[0.528]
Progress[  7%], ETA[ 184m], Batch [1830], G_Loss[0.128], D_Real_Loss[0.822], D_Fake_Loss[0.548]
Progress[  7%], ETA[ 184m], Batch [1840], G_Loss[0.150], D_Real_Loss[0.974], D_Fake_Loss[0.401]
Progress[  7%], ETA[ 184m], Batch [1850], G_Loss[0.110], D_Real_Loss[0.494], D_Fake_Loss[0.741]
Progress[  7%], ETA[ 184m], Batch [1860], G_Loss[0.116], D_Real_Loss[0.682], D_Fake_Loss[0.637]
Progress[  7%], ETA[ 184m], Batch [1870], G_Loss[0.134], D_Real_Loss[0.602], D_Fake_Loss[0.503]
Progress[  7%], ETA[ 184m], Batch [1880], G_Loss[0.154], D_Real_Loss[0.889], D_Fake_Loss[0.419]
Progress[  7%], ETA[ 184m], Batch [1890], G_Loss[0.138], D_Real_Loss[0.820], D_Fake_Loss[0.471]
Progress[  7%], ETA[ 184m], Batch [1900], G_Loss[0.123], D_Real_Loss[0.560], D_Fake_Loss[0.611]
Progress[  7%], ETA[ 184m], Batch [1910], G_Loss[0.107], D_Real_Loss[0.372], D_Fake_Loss[0.760]
Progress[  8%], ETA[ 183m], Batch [1920], G_Loss[0.106], D_Real_Loss[0.504], D_Fake_Loss[0.747]
Progress[  8%], ETA[ 183m], Batch [1930], G_Loss[0.099], D_Real_Loss[0.349], D_Fake_Loss[0.809]
Progress[  8%], ETA[ 183m], Batch [1940], G_Loss[0.134], D_Real_Loss[0.877], D_Fake_Loss[0.495]
Progress[  8%], ETA[ 183m], Batch [1950], G_Loss[0.103], D_Real_Loss[0.415], D_Fake_Loss[0.870]
Progress[  8%], ETA[ 183m], Batch [1960], G_Loss[0.128], D_Real_Loss[0.932], D_Fake_Loss[0.642]
Progress[  8%], ETA[ 183m], Batch [1970], G_Loss[0.117], D_Real_Loss[0.568], D_Fake_Loss[0.660]
Progress[  8%], ETA[ 183m], Batch [1980], G_Loss[0.130], D_Real_Loss[0.630], D_Fake_Loss[0.544]
Progress[  8%], ETA[ 183m], Batch [1990], G_Loss[0.141], D_Real_Loss[0.612], D_Fake_Loss[0.492]
Progress[  8%], ETA[ 183m], Batch [2000], G_Loss[0.143], D_Real_Loss[0.715], D_Fake_Loss[0.449]
    Saved train/batch002000_out.png
Progress[  8%], ETA[ 183m], Batch [2010], G_Loss[0.138], D_Real_Loss[0.476], D_Fake_Loss[0.518]
Progress[  8%], ETA[ 183m], Batch [2020], G_Loss[0.126], D_Real_Loss[0.413], D_Fake_Loss[0.589]
Progress[  8%], ETA[ 183m], Batch [2030], G_Loss[0.136], D_Real_Loss[0.573], D_Fake_Loss[0.716]
Progress[  8%], ETA[ 182m], Batch [2040], G_Loss[0.131], D_Real_Loss[0.593], D_Fake_Loss[0.528]
Progress[  8%], ETA[ 182m], Batch [2050], G_Loss[0.117], D_Real_Loss[0.452], D_Fake_Loss[0.684]
Progress[  8%], ETA[ 182m], Batch [2060], G_Loss[0.157], D_Real_Loss[0.749], D_Fake_Loss[0.375]
Progress[  8%], ETA[ 182m], Batch [2070], G_Loss[0.126], D_Real_Loss[0.824], D_Fake_Loss[0.524]
Progress[  8%], ETA[ 182m], Batch [2080], G_Loss[0.110], D_Real_Loss[0.528], D_Fake_Loss[0.887]
Progress[  8%], ETA[ 182m], Batch [2090], G_Loss[0.129], D_Real_Loss[0.706], D_Fake_Loss[0.585]
Progress[  8%], ETA[ 182m], Batch [2100], G_Loss[0.141], D_Real_Loss[0.599], D_Fake_Loss[0.528]
Progress[  8%], ETA[ 182m], Batch [2110], G_Loss[0.122], D_Real_Loss[0.644], D_Fake_Loss[0.702]
Progress[  8%], ETA[ 182m], Batch [2120], G_Loss[0.090], D_Real_Loss[0.393], D_Fake_Loss[0.923]
Progress[  8%], ETA[ 182m], Batch [2130], G_Loss[0.108], D_Real_Loss[0.576], D_Fake_Loss[0.683]
Progress[  8%], ETA[ 182m], Batch [2140], G_Loss[0.129], D_Real_Loss[0.458], D_Fake_Loss[0.691]
Progress[  9%], ETA[ 182m], Batch [2150], G_Loss[0.106], D_Real_Loss[0.471], D_Fake_Loss[1.034]
Progress[  9%], ETA[ 181m], Batch [2160], G_Loss[0.103], D_Real_Loss[0.629], D_Fake_Loss[0.748]
Progress[  9%], ETA[ 181m], Batch [2170], G_Loss[0.082], D_Real_Loss[0.511], D_Fake_Loss[1.067]
Progress[  9%], ETA[ 181m], Batch [2180], G_Loss[0.099], D_Real_Loss[0.472], D_Fake_Loss[0.748]
Progress[  9%], ETA[ 181m], Batch [2190], G_Loss[0.140], D_Real_Loss[0.915], D_Fake_Loss[0.512]
Progress[  9%], ETA[ 181m], Batch [2200], G_Loss[0.123], D_Real_Loss[0.446], D_Fake_Loss[0.718]
    Saved train/batch002200_out.png
Progress[  9%], ETA[ 181m], Batch [2210], G_Loss[0.158], D_Real_Loss[0.641], D_Fake_Loss[0.365]
Progress[  9%], ETA[ 181m], Batch [2220], G_Loss[0.113], D_Real_Loss[0.681], D_Fake_Loss[0.674]
Progress[  9%], ETA[ 181m], Batch [2230], G_Loss[0.100], D_Real_Loss[0.536], D_Fake_Loss[1.066]
Progress[  9%], ETA[ 181m], Batch [2240], G_Loss[0.130], D_Real_Loss[0.709], D_Fake_Loss[0.551]
Progress[  9%], ETA[ 181m], Batch [2250], G_Loss[0.124], D_Real_Loss[0.431], D_Fake_Loss[0.750]
Progress[  9%], ETA[ 181m], Batch [2260], G_Loss[0.122], D_Real_Loss[0.836], D_Fake_Loss[0.568]
Progress[  9%], ETA[ 181m], Batch [2270], G_Loss[0.129], D_Real_Loss[0.558], D_Fake_Loss[0.501]
Progress[  9%], ETA[ 180m], Batch [2280], G_Loss[0.141], D_Real_Loss[0.653], D_Fake_Loss[0.464]
Progress[  9%], ETA[ 180m], Batch [2290], G_Loss[0.118], D_Real_Loss[0.487], D_Fake_Loss[0.907]
Progress[  9%], ETA[ 180m], Batch [2300], G_Loss[0.143], D_Real_Loss[0.708], D_Fake_Loss[0.459]
Progress[  9%], ETA[ 180m], Batch [2310], G_Loss[0.104], D_Real_Loss[0.478], D_Fake_Loss[0.746]
Progress[  9%], ETA[ 180m], Batch [2320], G_Loss[0.152], D_Real_Loss[0.857], D_Fake_Loss[0.503]
Progress[  9%], ETA[ 180m], Batch [2330], G_Loss[0.120], D_Real_Loss[0.854], D_Fake_Loss[0.576]
Progress[  9%], ETA[ 180m], Batch [2340], G_Loss[0.107], D_Real_Loss[0.556], D_Fake_Loss[0.695]
Progress[  9%], ETA[ 180m], Batch [2350], G_Loss[0.149], D_Real_Loss[0.729], D_Fake_Loss[0.413]
Progress[  9%], ETA[ 180m], Batch [2360], G_Loss[0.115], D_Real_Loss[0.544], D_Fake_Loss[0.646]
Progress[  9%], ETA[ 180m], Batch [2370], G_Loss[0.123], D_Real_Loss[0.570], D_Fake_Loss[0.652]
Progress[  9%], ETA[ 180m], Batch [2380], G_Loss[0.129], D_Real_Loss[0.746], D_Fake_Loss[0.544]
Progress[  9%], ETA[ 180m], Batch [2390], G_Loss[0.110], D_Real_Loss[0.833], D_Fake_Loss[0.723]
Progress[ 10%], ETA[ 179m], Batch [2400], G_Loss[0.156], D_Real_Loss[0.677], D_Fake_Loss[0.471]
    Saved train/batch002400_out.png
Progress[ 10%], ETA[ 179m], Batch [2410], G_Loss[0.135], D_Real_Loss[0.791], D_Fake_Loss[0.504]
Progress[ 10%], ETA[ 179m], Batch [2420], G_Loss[0.125], D_Real_Loss[0.793], D_Fake_Loss[0.562]
Progress[ 10%], ETA[ 179m], Batch [2430], G_Loss[0.092], D_Real_Loss[0.508], D_Fake_Loss[0.917]
Progress[ 10%], ETA[ 179m], Batch [2440], G_Loss[0.127], D_Real_Loss[0.679], D_Fake_Loss[0.522]
Progress[ 10%], ETA[ 179m], Batch [2450], G_Loss[0.167], D_Real_Loss[1.028], D_Fake_Loss[0.332]
Progress[ 10%], ETA[ 179m], Batch [2460], G_Loss[0.127], D_Real_Loss[0.523], D_Fake_Loss[0.612]
Progress[ 10%], ETA[ 179m], Batch [2470], G_Loss[0.122], D_Real_Loss[0.611], D_Fake_Loss[0.610]
Progress[ 10%], ETA[ 179m], Batch [2480], G_Loss[0.112], D_Real_Loss[0.560], D_Fake_Loss[0.639]
Progress[ 10%], ETA[ 179m], Batch [2490], G_Loss[0.125], D_Real_Loss[0.468], D_Fake_Loss[0.625]
Progress[ 10%], ETA[ 179m], Batch [2500], G_Loss[0.169], D_Real_Loss[0.914], D_Fake_Loss[0.346]
Progress[ 10%], ETA[ 179m], Batch [2510], G_Loss[0.139], D_Real_Loss[0.717], D_Fake_Loss[0.458]
Progress[ 10%], ETA[ 178m], Batch [2520], G_Loss[0.068], D_Real_Loss[0.388], D_Fake_Loss[1.329]
Progress[ 10%], ETA[ 178m], Batch [2530], G_Loss[0.102], D_Real_Loss[0.562], D_Fake_Loss[0.803]
Progress[ 10%], ETA[ 178m], Batch [2540], G_Loss[0.137], D_Real_Loss[0.856], D_Fake_Loss[0.489]
Progress[ 10%], ETA[ 178m], Batch [2550], G_Loss[0.120], D_Real_Loss[0.610], D_Fake_Loss[0.649]
Progress[ 10%], ETA[ 178m], Batch [2560], G_Loss[0.089], D_Real_Loss[0.517], D_Fake_Loss[1.022]
Progress[ 10%], ETA[ 178m], Batch [2570], G_Loss[0.114], D_Real_Loss[0.700], D_Fake_Loss[0.684]
Progress[ 10%], ETA[ 178m], Batch [2580], G_Loss[0.122], D_Real_Loss[0.864], D_Fake_Loss[0.571]
Progress[ 10%], ETA[ 178m], Batch [2590], G_Loss[0.126], D_Real_Loss[0.880], D_Fake_Loss[0.515]
Progress[ 10%], ETA[ 178m], Batch [2600], G_Loss[0.170], D_Real_Loss[0.928], D_Fake_Loss[0.313]
    Saved train/batch002600_out.png
Progress[ 10%], ETA[ 178m], Batch [2610], G_Loss[0.107], D_Real_Loss[0.373], D_Fake_Loss[0.935]
Progress[ 10%], ETA[ 178m], Batch [2620], G_Loss[0.167], D_Real_Loss[1.028], D_Fake_Loss[0.319]
Progress[ 11%], ETA[ 178m], Batch [2630], G_Loss[0.137], D_Real_Loss[0.683], D_Fake_Loss[0.448]
Progress[ 11%], ETA[ 177m], Batch [2640], G_Loss[0.113], D_Real_Loss[0.514], D_Fake_Loss[0.657]
Progress[ 11%], ETA[ 177m], Batch [2650], G_Loss[0.154], D_Real_Loss[0.557], D_Fake_Loss[0.587]
Progress[ 11%], ETA[ 177m], Batch [2660], G_Loss[0.100], D_Real_Loss[0.447], D_Fake_Loss[0.834]
Progress[ 11%], ETA[ 177m], Batch [2670], G_Loss[0.162], D_Real_Loss[1.051], D_Fake_Loss[0.356]
Progress[ 11%], ETA[ 177m], Batch [2680], G_Loss[0.153], D_Real_Loss[0.482], D_Fake_Loss[0.617]
Progress[ 11%], ETA[ 177m], Batch [2690], G_Loss[0.116], D_Real_Loss[0.555], D_Fake_Loss[0.703]
Progress[ 11%], ETA[ 177m], Batch [2700], G_Loss[0.111], D_Real_Loss[0.445], D_Fake_Loss[0.688]
Progress[ 11%], ETA[ 177m], Batch [2710], G_Loss[0.129], D_Real_Loss[0.948], D_Fake_Loss[0.506]
Progress[ 11%], ETA[ 177m], Batch [2720], G_Loss[0.122], D_Real_Loss[0.641], D_Fake_Loss[0.582]
Progress[ 11%], ETA[ 177m], Batch [2730], G_Loss[0.159], D_Real_Loss[0.980], D_Fake_Loss[0.367]
Progress[ 11%], ETA[ 177m], Batch [2740], G_Loss[0.094], D_Real_Loss[0.425], D_Fake_Loss[0.896]
Progress[ 11%], ETA[ 177m], Batch [2750], G_Loss[0.087], D_Real_Loss[0.546], D_Fake_Loss[0.947]
Progress[ 11%], ETA[ 176m], Batch [2760], G_Loss[0.140], D_Real_Loss[0.773], D_Fake_Loss[0.536]
Progress[ 11%], ETA[ 176m], Batch [2770], G_Loss[0.149], D_Real_Loss[0.732], D_Fake_Loss[0.461]
Progress[ 11%], ETA[ 176m], Batch [2780], G_Loss[0.134], D_Real_Loss[0.647], D_Fake_Loss[0.530]
Progress[ 11%], ETA[ 176m], Batch [2790], G_Loss[0.128], D_Real_Loss[0.480], D_Fake_Loss[0.530]
Progress[ 11%], ETA[ 176m], Batch [2800], G_Loss[0.134], D_Real_Loss[0.603], D_Fake_Loss[0.496]
    Saved train/batch002800_out.png
Progress[ 11%], ETA[ 176m], Batch [2810], G_Loss[0.112], D_Real_Loss[0.269], D_Fake_Loss[0.894]
Progress[ 11%], ETA[ 176m], Batch [2820], G_Loss[0.170], D_Real_Loss[0.869], D_Fake_Loss[0.367]
Progress[ 11%], ETA[ 176m], Batch [2830], G_Loss[0.124], D_Real_Loss[0.689], D_Fake_Loss[0.627]
Progress[ 11%], ETA[ 176m], Batch [2840], G_Loss[0.151], D_Real_Loss[0.745], D_Fake_Loss[0.396]
Progress[ 11%], ETA[ 176m], Batch [2850], G_Loss[0.141], D_Real_Loss[0.513], D_Fake_Loss[0.457]
Progress[ 11%], ETA[ 176m], Batch [2860], G_Loss[0.155], D_Real_Loss[0.597], D_Fake_Loss[0.399]
Progress[ 12%], ETA[ 176m], Batch [2870], G_Loss[0.175], D_Real_Loss[0.898], D_Fake_Loss[0.433]
Progress[ 12%], ETA[ 175m], Batch [2880], G_Loss[0.127], D_Real_Loss[0.817], D_Fake_Loss[0.597]
Progress[ 12%], ETA[ 175m], Batch [2890], G_Loss[0.137], D_Real_Loss[0.615], D_Fake_Loss[0.584]
Progress[ 12%], ETA[ 175m], Batch [2900], G_Loss[0.112], D_Real_Loss[0.363], D_Fake_Loss[0.741]
Progress[ 12%], ETA[ 175m], Batch [2910], G_Loss[0.151], D_Real_Loss[0.697], D_Fake_Loss[0.415]
Progress[ 12%], ETA[ 175m], Batch [2920], G_Loss[0.132], D_Real_Loss[0.586], D_Fake_Loss[0.517]
Progress[ 12%], ETA[ 175m], Batch [2930], G_Loss[0.118], D_Real_Loss[0.403], D_Fake_Loss[0.620]
Progress[ 12%], ETA[ 175m], Batch [2940], G_Loss[0.185], D_Real_Loss[0.879], D_Fake_Loss[0.301]
Progress[ 12%], ETA[ 175m], Batch [2950], G_Loss[0.166], D_Real_Loss[0.539], D_Fake_Loss[0.528]
Progress[ 12%], ETA[ 175m], Batch [2960], G_Loss[0.120], D_Real_Loss[0.434], D_Fake_Loss[0.636]
Progress[ 12%], ETA[ 175m], Batch [2970], G_Loss[0.159], D_Real_Loss[0.796], D_Fake_Loss[0.429]
Progress[ 12%], ETA[ 175m], Batch [2980], G_Loss[0.154], D_Real_Loss[0.703], D_Fake_Loss[0.540]
Progress[ 12%], ETA[ 175m], Batch [2990], G_Loss[0.191], D_Real_Loss[0.920], D_Fake_Loss[0.267]
Progress[ 12%], ETA[ 174m], Batch [3000], G_Loss[0.077], D_Real_Loss[0.316], D_Fake_Loss[1.162]
    Saved train/batch003000_out.png
Progress[ 12%], ETA[ 174m], Batch [3010], G_Loss[0.147], D_Real_Loss[0.740], D_Fake_Loss[0.440]
Progress[ 12%], ETA[ 174m], Batch [3020], G_Loss[0.183], D_Real_Loss[0.633], D_Fake_Loss[0.296]
Progress[ 12%], ETA[ 174m], Batch [3030], G_Loss[0.099], D_Real_Loss[0.372], D_Fake_Loss[0.811]
Progress[ 12%], ETA[ 174m], Batch [3040], G_Loss[0.141], D_Real_Loss[0.521], D_Fake_Loss[0.464]
Progress[ 12%], ETA[ 174m], Batch [3050], G_Loss[0.124], D_Real_Loss[0.644], D_Fake_Loss[0.581]
Progress[ 12%], ETA[ 174m], Batch [3060], G_Loss[0.111], D_Real_Loss[0.427], D_Fake_Loss[0.678]
Progress[ 12%], ETA[ 174m], Batch [3070], G_Loss[0.145], D_Real_Loss[0.559], D_Fake_Loss[0.517]
Progress[ 12%], ETA[ 174m], Batch [3080], G_Loss[0.157], D_Real_Loss[0.553], D_Fake_Loss[0.402]
Progress[ 12%], ETA[ 174m], Batch [3090], G_Loss[0.173], D_Real_Loss[1.104], D_Fake_Loss[0.315]
Progress[ 12%], ETA[ 174m], Batch [3100], G_Loss[0.160], D_Real_Loss[0.650], D_Fake_Loss[0.403]
Progress[ 12%], ETA[ 174m], Batch [3110], G_Loss[0.166], D_Real_Loss[0.646], D_Fake_Loss[0.402]
Progress[ 13%], ETA[ 173m], Batch [3120], G_Loss[0.115], D_Real_Loss[0.475], D_Fake_Loss[0.724]
Progress[ 13%], ETA[ 173m], Batch [3130], G_Loss[0.118], D_Real_Loss[0.668], D_Fake_Loss[0.792]
Progress[ 13%], ETA[ 173m], Batch [3140], G_Loss[0.124], D_Real_Loss[0.771], D_Fake_Loss[0.692]
Progress[ 13%], ETA[ 173m], Batch [3150], G_Loss[0.099], D_Real_Loss[0.420], D_Fake_Loss[0.829]
Progress[ 13%], ETA[ 173m], Batch [3160], G_Loss[0.136], D_Real_Loss[0.700], D_Fake_Loss[0.507]
Progress[ 13%], ETA[ 173m], Batch [3170], G_Loss[0.127], D_Real_Loss[0.484], D_Fake_Loss[0.612]
Progress[ 13%], ETA[ 173m], Batch [3180], G_Loss[0.086], D_Real_Loss[0.265], D_Fake_Loss[0.993]
Progress[ 13%], ETA[ 173m], Batch [3190], G_Loss[0.125], D_Real_Loss[0.441], D_Fake_Loss[0.572]
Progress[ 13%], ETA[ 173m], Batch [3200], G_Loss[0.119], D_Real_Loss[0.389], D_Fake_Loss[0.634]
    Saved train/batch003200_out.png
Progress[ 13%], ETA[ 173m], Batch [3210], G_Loss[0.165], D_Real_Loss[0.802], D_Fake_Loss[0.356]
Progress[ 13%], ETA[ 173m], Batch [3220], G_Loss[0.159], D_Real_Loss[0.642], D_Fake_Loss[0.426]
Progress[ 13%], ETA[ 173m], Batch [3230], G_Loss[0.204], D_Real_Loss[0.648], D_Fake_Loss[0.290]
Progress[ 13%], ETA[ 172m], Batch [3240], G_Loss[0.151], D_Real_Loss[0.564], D_Fake_Loss[0.457]
Progress[ 13%], ETA[ 172m], Batch [3250], G_Loss[0.124], D_Real_Loss[0.335], D_Fake_Loss[0.603]
Progress[ 13%], ETA[ 172m], Batch [3260], G_Loss[0.150], D_Real_Loss[0.508], D_Fake_Loss[0.452]
Progress[ 13%], ETA[ 172m], Batch [3270], G_Loss[0.164], D_Real_Loss[0.368], D_Fake_Loss[0.451]
Progress[ 13%], ETA[ 172m], Batch [3280], G_Loss[0.080], D_Real_Loss[0.283], D_Fake_Loss[1.336]
Progress[ 13%], ETA[ 172m], Batch [3290], G_Loss[0.175], D_Real_Loss[0.830], D_Fake_Loss[0.328]
Progress[ 13%], ETA[ 172m], Batch [3300], G_Loss[0.070], D_Real_Loss[0.150], D_Fake_Loss[1.462]
Progress[ 13%], ETA[ 172m], Batch [3310], G_Loss[0.104], D_Real_Loss[0.334], D_Fake_Loss[0.932]
Progress[ 13%], ETA[ 172m], Batch [3320], G_Loss[0.126], D_Real_Loss[0.428], D_Fake_Loss[0.748]
Progress[ 13%], ETA[ 172m], Batch [3330], G_Loss[0.118], D_Real_Loss[0.463], D_Fake_Loss[0.698]
Progress[ 13%], ETA[ 172m], Batch [3340], G_Loss[0.104], D_Real_Loss[0.398], D_Fake_Loss[0.779]
Progress[ 14%], ETA[ 172m], Batch [3350], G_Loss[0.179], D_Real_Loss[0.760], D_Fake_Loss[0.300]
Progress[ 14%], ETA[ 171m], Batch [3360], G_Loss[0.169], D_Real_Loss[0.639], D_Fake_Loss[0.356]
Progress[ 14%], ETA[ 171m], Batch [3370], G_Loss[0.154], D_Real_Loss[0.669], D_Fake_Loss[0.432]
Progress[ 14%], ETA[ 171m], Batch [3380], G_Loss[0.127], D_Real_Loss[0.587], D_Fake_Loss[0.613]
Progress[ 14%], ETA[ 171m], Batch [3390], G_Loss[0.079], D_Real_Loss[0.281], D_Fake_Loss[1.187]
Progress[ 14%], ETA[ 171m], Batch [3400], G_Loss[0.196], D_Real_Loss[1.040], D_Fake_Loss[0.266]
    Saved train/batch003400_out.png
Progress[ 14%], ETA[ 171m], Batch [3410], G_Loss[0.142], D_Real_Loss[0.596], D_Fake_Loss[0.473]
Progress[ 14%], ETA[ 171m], Batch [3420], G_Loss[0.204], D_Real_Loss[0.781], D_Fake_Loss[0.258]
Progress[ 14%], ETA[ 171m], Batch [3430], G_Loss[0.136], D_Real_Loss[0.489], D_Fake_Loss[0.613]
Progress[ 14%], ETA[ 171m], Batch [3440], G_Loss[0.171], D_Real_Loss[0.420], D_Fake_Loss[0.364]
Progress[ 14%], ETA[ 171m], Batch [3450], G_Loss[0.150], D_Real_Loss[0.848], D_Fake_Loss[0.416]
Progress[ 14%], ETA[ 171m], Batch [3460], G_Loss[0.161], D_Real_Loss[0.401], D_Fake_Loss[0.405]
Progress[ 14%], ETA[ 170m], Batch [3470], G_Loss[0.093], D_Real_Loss[0.232], D_Fake_Loss[1.043]
Progress[ 14%], ETA[ 170m], Batch [3480], G_Loss[0.132], D_Real_Loss[0.692], D_Fake_Loss[0.513]
Progress[ 14%], ETA[ 170m], Batch [3490], G_Loss[0.153], D_Real_Loss[0.854], D_Fake_Loss[0.392]
Progress[ 14%], ETA[ 170m], Batch [3500], G_Loss[0.098], D_Real_Loss[0.277], D_Fake_Loss[0.830]
Progress[ 14%], ETA[ 170m], Batch [3510], G_Loss[0.121], D_Real_Loss[0.377], D_Fake_Loss[0.780]
Progress[ 14%], ETA[ 170m], Batch [3520], G_Loss[0.146], D_Real_Loss[0.370], D_Fake_Loss[0.456]
Progress[ 14%], ETA[ 170m], Batch [3530], G_Loss[0.131], D_Real_Loss[0.535], D_Fake_Loss[0.521]
Progress[ 14%], ETA[ 170m], Batch [3540], G_Loss[0.208], D_Real_Loss[1.002], D_Fake_Loss[0.227]
Progress[ 14%], ETA[ 170m], Batch [3550], G_Loss[0.110], D_Real_Loss[0.345], D_Fake_Loss[0.702]
Progress[ 14%], ETA[ 170m], Batch [3560], G_Loss[0.155], D_Real_Loss[0.869], D_Fake_Loss[0.458]
Progress[ 14%], ETA[ 170m], Batch [3570], G_Loss[0.140], D_Real_Loss[0.471], D_Fake_Loss[0.501]
Progress[ 14%], ETA[ 170m], Batch [3580], G_Loss[0.075], D_Real_Loss[0.168], D_Fake_Loss[1.347]
Progress[ 15%], ETA[ 170m], Batch [3590], G_Loss[0.257], D_Real_Loss[1.174], D_Fake_Loss[0.143]
Progress[ 15%], ETA[ 169m], Batch [3600], G_Loss[0.156], D_Real_Loss[0.476], D_Fake_Loss[0.491]
    Saved train/batch003600_out.png
Progress[ 15%], ETA[ 169m], Batch [3610], G_Loss[0.130], D_Real_Loss[0.503], D_Fake_Loss[0.566]
Progress[ 15%], ETA[ 169m], Batch [3620], G_Loss[0.101], D_Real_Loss[0.490], D_Fake_Loss[0.797]
Progress[ 15%], ETA[ 169m], Batch [3630], G_Loss[0.108], D_Real_Loss[0.436], D_Fake_Loss[0.963]
Progress[ 15%], ETA[ 169m], Batch [3640], G_Loss[0.210], D_Real_Loss[0.703], D_Fake_Loss[0.248]
Progress[ 15%], ETA[ 169m], Batch [3650], G_Loss[0.140], D_Real_Loss[0.585], D_Fake_Loss[0.511]
Progress[ 15%], ETA[ 169m], Batch [3660], G_Loss[0.122], D_Real_Loss[0.383], D_Fake_Loss[0.734]
Progress[ 15%], ETA[ 169m], Batch [3670], G_Loss[0.186], D_Real_Loss[0.966], D_Fake_Loss[0.324]
Progress[ 15%], ETA[ 169m], Batch [3680], G_Loss[0.134], D_Real_Loss[0.745], D_Fake_Loss[0.543]
Progress[ 15%], ETA[ 169m], Batch [3690], G_Loss[0.148], D_Real_Loss[0.516], D_Fake_Loss[0.438]
Progress[ 15%], ETA[ 169m], Batch [3700], G_Loss[0.189], D_Real_Loss[0.705], D_Fake_Loss[0.317]
Progress[ 15%], ETA[ 169m], Batch [3710], G_Loss[0.151], D_Real_Loss[0.270], D_Fake_Loss[0.515]
Progress[ 15%], ETA[ 168m], Batch [3720], G_Loss[0.167], D_Real_Loss[0.513], D_Fake_Loss[0.445]
Progress[ 15%], ETA[ 168m], Batch [3730], G_Loss[0.095], D_Real_Loss[0.117], D_Fake_Loss[1.186]
Progress[ 15%], ETA[ 168m], Batch [3740], G_Loss[0.137], D_Real_Loss[0.625], D_Fake_Loss[0.638]
Progress[ 15%], ETA[ 168m], Batch [3750], G_Loss[0.102], D_Real_Loss[0.367], D_Fake_Loss[0.864]
Progress[ 15%], ETA[ 168m], Batch [3760], G_Loss[0.085], D_Real_Loss[0.204], D_Fake_Loss[1.017]
Progress[ 15%], ETA[ 168m], Batch [3770], G_Loss[0.240], D_Real_Loss[0.452], D_Fake_Loss[0.166]
Progress[ 15%], ETA[ 168m], Batch [3780], G_Loss[0.216], D_Real_Loss[0.792], D_Fake_Loss[0.203]
Progress[ 15%], ETA[ 168m], Batch [3790], G_Loss[0.148], D_Real_Loss[0.715], D_Fake_Loss[0.433]
Progress[ 15%], ETA[ 168m], Batch [3800], G_Loss[0.168], D_Real_Loss[0.798], D_Fake_Loss[0.349]
    Saved train/batch003800_out.png
Progress[ 15%], ETA[ 168m], Batch [3810], G_Loss[0.124], D_Real_Loss[0.550], D_Fake_Loss[0.607]
Progress[ 15%], ETA[ 168m], Batch [3820], G_Loss[0.183], D_Real_Loss[0.741], D_Fake_Loss[0.343]
Progress[ 16%], ETA[ 167m], Batch [3830], G_Loss[0.251], D_Real_Loss[1.229], D_Fake_Loss[0.144]
Progress[ 16%], ETA[ 167m], Batch [3840], G_Loss[0.204], D_Real_Loss[0.448], D_Fake_Loss[0.252]
Progress[ 16%], ETA[ 167m], Batch [3850], G_Loss[0.128], D_Real_Loss[0.259], D_Fake_Loss[0.593]
Progress[ 16%], ETA[ 167m], Batch [3860], G_Loss[0.178], D_Real_Loss[0.408], D_Fake_Loss[0.339]
Progress[ 16%], ETA[ 167m], Batch [3870], G_Loss[0.173], D_Real_Loss[0.410], D_Fake_Loss[0.423]
Progress[ 16%], ETA[ 167m], Batch [3880], G_Loss[0.174], D_Real_Loss[0.370], D_Fake_Loss[0.372]
Progress[ 16%], ETA[ 167m], Batch [3890], G_Loss[0.139], D_Real_Loss[0.250], D_Fake_Loss[0.528]
Progress[ 16%], ETA[ 167m], Batch [3900], G_Loss[0.179], D_Real_Loss[0.810], D_Fake_Loss[0.313]
Progress[ 16%], ETA[ 167m], Batch [3910], G_Loss[0.163], D_Real_Loss[0.610], D_Fake_Loss[0.433]
Progress[ 16%], ETA[ 167m], Batch [3920], G_Loss[0.244], D_Real_Loss[1.124], D_Fake_Loss[0.170]
Progress[ 16%], ETA[ 167m], Batch [3930], G_Loss[0.192], D_Real_Loss[0.556], D_Fake_Loss[0.285]
Progress[ 16%], ETA[ 167m], Batch [3940], G_Loss[0.120], D_Real_Loss[0.399], D_Fake_Loss[0.734]
Progress[ 16%], ETA[ 166m], Batch [3950], G_Loss[0.192], D_Real_Loss[0.702], D_Fake_Loss[0.296]
Progress[ 16%], ETA[ 166m], Batch [3960], G_Loss[0.148], D_Real_Loss[0.396], D_Fake_Loss[0.416]
Progress[ 16%], ETA[ 166m], Batch [3970], G_Loss[0.141], D_Real_Loss[0.462], D_Fake_Loss[0.558]
Progress[ 16%], ETA[ 166m], Batch [3980], G_Loss[0.170], D_Real_Loss[0.548], D_Fake_Loss[0.450]
Progress[ 16%], ETA[ 166m], Batch [3990], G_Loss[0.092], D_Real_Loss[0.210], D_Fake_Loss[0.907]
Progress[ 16%], ETA[ 166m], Batch [4000], G_Loss[0.179], D_Real_Loss[0.696], D_Fake_Loss[0.312]
    Saved train/batch004000_out.png
Progress[ 16%], ETA[ 166m], Batch [4010], G_Loss[0.174], D_Real_Loss[0.664], D_Fake_Loss[0.327]
Progress[ 16%], ETA[ 166m], Batch [4020], G_Loss[0.208], D_Real_Loss[0.908], D_Fake_Loss[0.246]
Progress[ 16%], ETA[ 166m], Batch [4030], G_Loss[0.180], D_Real_Loss[0.364], D_Fake_Loss[0.316]
Progress[ 16%], ETA[ 166m], Batch [4040], G_Loss[0.149], D_Real_Loss[0.698], D_Fake_Loss[0.455]
Progress[ 16%], ETA[ 166m], Batch [4050], G_Loss[0.156], D_Real_Loss[0.651], D_Fake_Loss[0.397]
Progress[ 16%], ETA[ 166m], Batch [4060], G_Loss[0.122], D_Real_Loss[0.500], D_Fake_Loss[0.637]
Progress[ 17%], ETA[ 165m], Batch [4070], G_Loss[0.150], D_Real_Loss[0.516], D_Fake_Loss[0.453]
Progress[ 17%], ETA[ 165m], Batch [4080], G_Loss[0.232], D_Real_Loss[1.014], D_Fake_Loss[0.209]
Progress[ 17%], ETA[ 165m], Batch [4090], G_Loss[0.164], D_Real_Loss[0.365], D_Fake_Loss[0.390]
Progress[ 17%], ETA[ 165m], Batch [4100], G_Loss[0.071], D_Real_Loss[0.140], D_Fake_Loss[1.423]
Progress[ 17%], ETA[ 165m], Batch [4110], G_Loss[0.227], D_Real_Loss[0.403], D_Fake_Loss[0.259]
Progress[ 17%], ETA[ 165m], Batch [4120], G_Loss[0.156], D_Real_Loss[0.551], D_Fake_Loss[0.383]
Progress[ 17%], ETA[ 165m], Batch [4130], G_Loss[0.091], D_Real_Loss[0.268], D_Fake_Loss[0.978]
Progress[ 17%], ETA[ 165m], Batch [4140], G_Loss[0.153], D_Real_Loss[0.519], D_Fake_Loss[0.429]
Progress[ 17%], ETA[ 165m], Batch [4150], G_Loss[0.113], D_Real_Loss[0.434], D_Fake_Loss[0.754]
Progress[ 17%], ETA[ 165m], Batch [4160], G_Loss[0.153], D_Real_Loss[0.778], D_Fake_Loss[0.416]
Progress[ 17%], ETA[ 165m], Batch [4170], G_Loss[0.153], D_Real_Loss[0.405], D_Fake_Loss[0.407]
Progress[ 17%], ETA[ 165m], Batch [4180], G_Loss[0.155], D_Real_Loss[0.613], D_Fake_Loss[0.451]
Progress[ 17%], ETA[ 164m], Batch [4190], G_Loss[0.080], D_Real_Loss[0.154], D_Fake_Loss[1.143]
Progress[ 17%], ETA[ 164m], Batch [4200], G_Loss[0.094], D_Real_Loss[0.185], D_Fake_Loss[1.123]
    Saved train/batch004200_out.png
Progress[ 17%], ETA[ 164m], Batch [4210], G_Loss[0.147], D_Real_Loss[0.522], D_Fake_Loss[0.440]
Progress[ 17%], ETA[ 164m], Batch [4220], G_Loss[0.222], D_Real_Loss[1.088], D_Fake_Loss[0.196]
Progress[ 17%], ETA[ 164m], Batch [4230], G_Loss[0.219], D_Real_Loss[0.786], D_Fake_Loss[0.261]
Progress[ 17%], ETA[ 164m], Batch [4240], G_Loss[0.089], D_Real_Loss[0.296], D_Fake_Loss[1.247]
Progress[ 17%], ETA[ 164m], Batch [4250], G_Loss[0.083], D_Real_Loss[0.270], D_Fake_Loss[1.187]
Progress[ 17%], ETA[ 164m], Batch [4260], G_Loss[0.130], D_Real_Loss[0.325], D_Fake_Loss[0.551]
Progress[ 17%], ETA[ 164m], Batch [4270], G_Loss[0.184], D_Real_Loss[0.559], D_Fake_Loss[0.359]
Progress[ 17%], ETA[ 164m], Batch [4280], G_Loss[0.116], D_Real_Loss[0.401], D_Fake_Loss[0.653]
Progress[ 17%], ETA[ 164m], Batch [4290], G_Loss[0.158], D_Real_Loss[0.362], D_Fake_Loss[0.415]
Progress[ 17%], ETA[ 164m], Batch [4300], G_Loss[0.222], D_Real_Loss[0.350], D_Fake_Loss[0.184]
Progress[ 18%], ETA[ 163m], Batch [4310], G_Loss[0.100], D_Real_Loss[0.215], D_Fake_Loss[0.960]
Progress[ 18%], ETA[ 163m], Batch [4320], G_Loss[0.069], D_Real_Loss[0.114], D_Fake_Loss[1.789]
Progress[ 18%], ETA[ 163m], Batch [4330], G_Loss[0.177], D_Real_Loss[0.960], D_Fake_Loss[0.324]
Progress[ 18%], ETA[ 163m], Batch [4340], G_Loss[0.179], D_Real_Loss[0.167], D_Fake_Loss[0.662]
Progress[ 18%], ETA[ 163m], Batch [4350], G_Loss[0.188], D_Real_Loss[0.654], D_Fake_Loss[0.288]
Progress[ 18%], ETA[ 163m], Batch [4360], G_Loss[0.182], D_Real_Loss[0.590], D_Fake_Loss[0.307]
Progress[ 18%], ETA[ 163m], Batch [4370], G_Loss[0.110], D_Real_Loss[0.446], D_Fake_Loss[0.771]
Progress[ 18%], ETA[ 163m], Batch [4380], G_Loss[0.325], D_Real_Loss[1.289], D_Fake_Loss[0.067]
Progress[ 18%], ETA[ 163m], Batch [4390], G_Loss[0.157], D_Real_Loss[0.338], D_Fake_Loss[0.490]
Progress[ 18%], ETA[ 163m], Batch [4400], G_Loss[0.142], D_Real_Loss[0.244], D_Fake_Loss[0.500]
    Saved train/batch004400_out.png
Progress[ 18%], ETA[ 163m], Batch [4410], G_Loss[0.127], D_Real_Loss[0.230], D_Fake_Loss[0.762]
Progress[ 18%], ETA[ 163m], Batch [4420], G_Loss[0.153], D_Real_Loss[0.491], D_Fake_Loss[0.530]
Progress[ 18%], ETA[ 162m], Batch [4430], G_Loss[0.109], D_Real_Loss[0.223], D_Fake_Loss[0.838]
Progress[ 18%], ETA[ 162m], Batch [4440], G_Loss[0.237], D_Real_Loss[0.620], D_Fake_Loss[0.168]
Progress[ 18%], ETA[ 162m], Batch [4450], G_Loss[0.204], D_Real_Loss[0.814], D_Fake_Loss[0.242]
Progress[ 18%], ETA[ 162m], Batch [4460], G_Loss[0.183], D_Real_Loss[0.401], D_Fake_Loss[0.301]
Progress[ 18%], ETA[ 162m], Batch [4470], G_Loss[0.261], D_Real_Loss[0.664], D_Fake_Loss[0.121]
Progress[ 18%], ETA[ 162m], Batch [4480], G_Loss[0.194], D_Real_Loss[0.266], D_Fake_Loss[0.265]
Progress[ 18%], ETA[ 162m], Batch [4490], G_Loss[0.211], D_Real_Loss[0.685], D_Fake_Loss[0.243]
Progress[ 18%], ETA[ 162m], Batch [4500], G_Loss[0.107], D_Real_Loss[0.428], D_Fake_Loss[0.859]
Progress[ 18%], ETA[ 162m], Batch [4510], G_Loss[0.153], D_Real_Loss[0.668], D_Fake_Loss[0.456]
Progress[ 18%], ETA[ 162m], Batch [4520], G_Loss[0.117], D_Real_Loss[0.287], D_Fake_Loss[0.746]
Progress[ 18%], ETA[ 162m], Batch [4530], G_Loss[0.248], D_Real_Loss[0.782], D_Fake_Loss[0.159]
Progress[ 18%], ETA[ 162m], Batch [4540], G_Loss[0.181], D_Real_Loss[0.358], D_Fake_Loss[0.361]
Progress[ 19%], ETA[ 161m], Batch [4550], G_Loss[0.147], D_Real_Loss[0.223], D_Fake_Loss[0.476]
Progress[ 19%], ETA[ 161m], Batch [4560], G_Loss[0.249], D_Real_Loss[0.462], D_Fake_Loss[0.160]
Progress[ 19%], ETA[ 161m], Batch [4570], G_Loss[0.153], D_Real_Loss[0.459], D_Fake_Loss[0.439]
Progress[ 19%], ETA[ 161m], Batch [4580], G_Loss[0.139], D_Real_Loss[0.212], D_Fake_Loss[0.488]
Progress[ 19%], ETA[ 161m], Batch [4590], G_Loss[0.146], D_Real_Loss[0.283], D_Fake_Loss[0.535]
Progress[ 19%], ETA[ 161m], Batch [4600], G_Loss[0.167], D_Real_Loss[0.482], D_Fake_Loss[0.378]
    Saved train/batch004600_out.png
Progress[ 19%], ETA[ 161m], Batch [4610], G_Loss[0.080], D_Real_Loss[0.284], D_Fake_Loss[1.134]
Progress[ 19%], ETA[ 161m], Batch [4620], G_Loss[0.128], D_Real_Loss[0.317], D_Fake_Loss[0.607]
Progress[ 19%], ETA[ 161m], Batch [4630], G_Loss[0.249], D_Real_Loss[0.512], D_Fake_Loss[0.150]
Progress[ 19%], ETA[ 161m], Batch [4640], G_Loss[0.113], D_Real_Loss[0.300], D_Fake_Loss[0.793]
Progress[ 19%], ETA[ 161m], Batch [4650], G_Loss[0.114], D_Real_Loss[0.356], D_Fake_Loss[0.841]
Progress[ 19%], ETA[ 161m], Batch [4660], G_Loss[0.164], D_Real_Loss[0.774], D_Fake_Loss[0.470]
Progress[ 19%], ETA[ 160m], Batch [4670], G_Loss[0.113], D_Real_Loss[0.180], D_Fake_Loss[0.826]
Progress[ 19%], ETA[ 160m], Batch [4680], G_Loss[0.260], D_Real_Loss[0.922], D_Fake_Loss[0.139]
Progress[ 19%], ETA[ 160m], Batch [4690], G_Loss[0.095], D_Real_Loss[0.199], D_Fake_Loss[0.892]
Progress[ 19%], ETA[ 160m], Batch [4700], G_Loss[0.192], D_Real_Loss[0.689], D_Fake_Loss[0.272]
Progress[ 19%], ETA[ 160m], Batch [4710], G_Loss[0.160], D_Real_Loss[0.464], D_Fake_Loss[0.391]
Progress[ 19%], ETA[ 160m], Batch [4720], G_Loss[0.239], D_Real_Loss[0.812], D_Fake_Loss[0.168]
Progress[ 19%], ETA[ 160m], Batch [4730], G_Loss[0.176], D_Real_Loss[0.406], D_Fake_Loss[0.337]
Progress[ 19%], ETA[ 160m], Batch [4740], G_Loss[0.153], D_Real_Loss[0.335], D_Fake_Loss[0.477]
Progress[ 19%], ETA[ 160m], Batch [4750], G_Loss[0.178], D_Real_Loss[0.400], D_Fake_Loss[0.364]
Progress[ 19%], ETA[ 160m], Batch [4760], G_Loss[0.113], D_Real_Loss[0.166], D_Fake_Loss[0.800]
Progress[ 19%], ETA[ 160m], Batch [4770], G_Loss[0.169], D_Real_Loss[0.302], D_Fake_Loss[0.386]
Progress[ 20%], ETA[ 160m], Batch [4780], G_Loss[0.107], D_Real_Loss[0.194], D_Fake_Loss[0.840]
Progress[ 20%], ETA[ 159m], Batch [4790], G_Loss[0.202], D_Real_Loss[0.809], D_Fake_Loss[0.265]
Progress[ 20%], ETA[ 159m], Batch [4800], G_Loss[0.169], D_Real_Loss[0.403], D_Fake_Loss[0.382]
    Saved train/batch004800_out.png
Progress[ 20%], ETA[ 159m], Batch [4810], G_Loss[0.085], D_Real_Loss[0.305], D_Fake_Loss[1.103]
Progress[ 20%], ETA[ 159m], Batch [4820], G_Loss[0.173], D_Real_Loss[0.617], D_Fake_Loss[0.349]
Progress[ 20%], ETA[ 159m], Batch [4830], G_Loss[0.206], D_Real_Loss[0.777], D_Fake_Loss[0.237]
Progress[ 20%], ETA[ 159m], Batch [4840], G_Loss[0.112], D_Real_Loss[0.307], D_Fake_Loss[0.924]
Progress[ 20%], ETA[ 159m], Batch [4850], G_Loss[0.215], D_Real_Loss[0.389], D_Fake_Loss[0.292]
Progress[ 20%], ETA[ 159m], Batch [4860], G_Loss[0.165], D_Real_Loss[0.310], D_Fake_Loss[0.415]
Progress[ 20%], ETA[ 159m], Batch [4870], G_Loss[0.156], D_Real_Loss[0.430], D_Fake_Loss[0.475]
Progress[ 20%], ETA[ 159m], Batch [4880], G_Loss[0.201], D_Real_Loss[0.622], D_Fake_Loss[0.240]
Progress[ 20%], ETA[ 159m], Batch [4890], G_Loss[0.100], D_Real_Loss[0.277], D_Fake_Loss[0.907]
Progress[ 20%], ETA[ 158m], Batch [4900], G_Loss[0.165], D_Real_Loss[0.191], D_Fake_Loss[0.434]
Progress[ 20%], ETA[ 158m], Batch [4910], G_Loss[0.215], D_Real_Loss[0.614], D_Fake_Loss[0.214]
Progress[ 20%], ETA[ 158m], Batch [4920], G_Loss[0.103], D_Real_Loss[0.235], D_Fake_Loss[0.965]
Progress[ 20%], ETA[ 158m], Batch [4930], G_Loss[0.158], D_Real_Loss[0.374], D_Fake_Loss[0.382]
Progress[ 20%], ETA[ 158m], Batch [4940], G_Loss[0.145], D_Real_Loss[0.300], D_Fake_Loss[0.582]
Progress[ 20%], ETA[ 158m], Batch [4950], G_Loss[0.121], D_Real_Loss[0.227], D_Fake_Loss[0.700]
Progress[ 20%], ETA[ 158m], Batch [4960], G_Loss[0.145], D_Real_Loss[0.211], D_Fake_Loss[0.471]
Progress[ 20%], ETA[ 158m], Batch [4970], G_Loss[0.195], D_Real_Loss[1.437], D_Fake_Loss[0.269]
Progress[ 20%], ETA[ 158m], Batch [4980], G_Loss[0.105], D_Real_Loss[0.090], D_Fake_Loss[0.901]
Progress[ 20%], ETA[ 158m], Batch [4990], G_Loss[0.160], D_Real_Loss[0.461], D_Fake_Loss[0.501]
Progress[ 20%], ETA[ 158m], Batch [5000], G_Loss[0.092], D_Real_Loss[0.253], D_Fake_Loss[1.360]
    Saved train/batch005000_out.png
Progress[ 20%], ETA[ 158m], Batch [5010], G_Loss[0.178], D_Real_Loss[0.367], D_Fake_Loss[0.355]
Progress[ 21%], ETA[ 157m], Batch [5020], G_Loss[0.127], D_Real_Loss[0.192], D_Fake_Loss[0.667]
Progress[ 21%], ETA[ 157m], Batch [5030], G_Loss[0.190], D_Real_Loss[0.481], D_Fake_Loss[0.268]
Progress[ 21%], ETA[ 157m], Batch [5040], G_Loss[0.131], D_Real_Loss[0.369], D_Fake_Loss[0.883]
Progress[ 21%], ETA[ 157m], Batch [5050], G_Loss[0.143], D_Real_Loss[0.189], D_Fake_Loss[0.581]
Progress[ 21%], ETA[ 157m], Batch [5060], G_Loss[0.130], D_Real_Loss[0.125], D_Fake_Loss[0.593]
Progress[ 21%], ETA[ 157m], Batch [5070], G_Loss[0.132], D_Real_Loss[0.445], D_Fake_Loss[0.543]
Progress[ 21%], ETA[ 157m], Batch [5080], G_Loss[0.115], D_Real_Loss[0.173], D_Fake_Loss[0.637]
Progress[ 21%], ETA[ 157m], Batch [5090], G_Loss[0.194], D_Real_Loss[0.824], D_Fake_Loss[0.270]
Progress[ 21%], ETA[ 157m], Batch [5100], G_Loss[0.122], D_Real_Loss[0.463], D_Fake_Loss[0.753]
Progress[ 21%], ETA[ 157m], Batch [5110], G_Loss[0.102], D_Real_Loss[0.222], D_Fake_Loss[0.812]
Progress[ 21%], ETA[ 157m], Batch [5120], G_Loss[0.186], D_Real_Loss[0.173], D_Fake_Loss[0.317]
Progress[ 21%], ETA[ 157m], Batch [5130], G_Loss[0.100], D_Real_Loss[0.285], D_Fake_Loss[0.983]
Progress[ 21%], ETA[ 156m], Batch [5140], G_Loss[0.137], D_Real_Loss[0.247], D_Fake_Loss[0.529]
Progress[ 21%], ETA[ 156m], Batch [5150], G_Loss[0.130], D_Real_Loss[0.280], D_Fake_Loss[0.588]
Progress[ 21%], ETA[ 156m], Batch [5160], G_Loss[0.101], D_Real_Loss[0.170], D_Fake_Loss[0.808]
Progress[ 21%], ETA[ 156m], Batch [5170], G_Loss[0.136], D_Real_Loss[0.686], D_Fake_Loss[0.515]
Progress[ 21%], ETA[ 156m], Batch [5180], G_Loss[0.188], D_Real_Loss[0.410], D_Fake_Loss[0.277]
Progress[ 21%], ETA[ 156m], Batch [5190], G_Loss[0.179], D_Real_Loss[0.374], D_Fake_Loss[0.285]
Progress[ 21%], ETA[ 156m], Batch [5200], G_Loss[0.126], D_Real_Loss[0.432], D_Fake_Loss[0.616]
    Saved train/batch005200_out.png
Progress[ 21%], ETA[ 156m], Batch [5210], G_Loss[0.126], D_Real_Loss[0.266], D_Fake_Loss[0.561]
Progress[ 21%], ETA[ 156m], Batch [5220], G_Loss[0.163], D_Real_Loss[0.602], D_Fake_Loss[0.373]
Progress[ 21%], ETA[ 156m], Batch [5230], G_Loss[0.216], D_Real_Loss[0.791], D_Fake_Loss[0.221]
Progress[ 21%], ETA[ 156m], Batch [5240], G_Loss[0.112], D_Real_Loss[0.430], D_Fake_Loss[0.700]
Progress[ 21%], ETA[ 156m], Batch [5250], G_Loss[0.138], D_Real_Loss[0.328], D_Fake_Loss[0.517]
Progress[ 22%], ETA[ 155m], Batch [5260], G_Loss[0.177], D_Real_Loss[0.451], D_Fake_Loss[0.353]
Progress[ 22%], ETA[ 155m], Batch [5270], G_Loss[0.117], D_Real_Loss[0.086], D_Fake_Loss[0.746]
Progress[ 22%], ETA[ 155m], Batch [5280], G_Loss[0.165], D_Real_Loss[0.406], D_Fake_Loss[0.383]
Progress[ 22%], ETA[ 155m], Batch [5290], G_Loss[0.144], D_Real_Loss[0.174], D_Fake_Loss[0.523]
Progress[ 22%], ETA[ 155m], Batch [5300], G_Loss[0.136], D_Real_Loss[0.876], D_Fake_Loss[0.620]
Progress[ 22%], ETA[ 155m], Batch [5310], G_Loss[0.173], D_Real_Loss[0.925], D_Fake_Loss[0.482]
Progress[ 22%], ETA[ 155m], Batch [5320], G_Loss[0.142], D_Real_Loss[0.736], D_Fake_Loss[0.563]
Progress[ 22%], ETA[ 155m], Batch [5330], G_Loss[0.228], D_Real_Loss[0.729], D_Fake_Loss[0.239]
Progress[ 22%], ETA[ 155m], Batch [5340], G_Loss[0.220], D_Real_Loss[0.471], D_Fake_Loss[0.225]
Progress[ 22%], ETA[ 155m], Batch [5350], G_Loss[0.165], D_Real_Loss[0.442], D_Fake_Loss[0.398]
Progress[ 22%], ETA[ 155m], Batch [5360], G_Loss[0.142], D_Real_Loss[0.266], D_Fake_Loss[0.574]
Progress[ 22%], ETA[ 155m], Batch [5370], G_Loss[0.179], D_Real_Loss[0.338], D_Fake_Loss[0.368]
Progress[ 22%], ETA[ 154m], Batch [5380], G_Loss[0.140], D_Real_Loss[0.303], D_Fake_Loss[0.552]
Progress[ 22%], ETA[ 154m], Batch [5390], G_Loss[0.129], D_Real_Loss[0.545], D_Fake_Loss[0.651]
Progress[ 22%], ETA[ 154m], Batch [5400], G_Loss[0.141], D_Real_Loss[0.471], D_Fake_Loss[0.587]
    Saved train/batch005400_out.png
Progress[ 22%], ETA[ 154m], Batch [5410], G_Loss[0.132], D_Real_Loss[0.710], D_Fake_Loss[0.667]
Progress[ 22%], ETA[ 154m], Batch [5420], G_Loss[0.150], D_Real_Loss[0.413], D_Fake_Loss[0.554]
Progress[ 22%], ETA[ 154m], Batch [5430], G_Loss[0.157], D_Real_Loss[0.392], D_Fake_Loss[0.546]
Progress[ 22%], ETA[ 154m], Batch [5440], G_Loss[0.117], D_Real_Loss[0.405], D_Fake_Loss[0.704]
Progress[ 22%], ETA[ 154m], Batch [5450], G_Loss[0.151], D_Real_Loss[0.600], D_Fake_Loss[0.457]
Progress[ 22%], ETA[ 154m], Batch [5460], G_Loss[0.154], D_Real_Loss[0.557], D_Fake_Loss[0.429]
Progress[ 22%], ETA[ 154m], Batch [5470], G_Loss[0.205], D_Real_Loss[0.486], D_Fake_Loss[0.265]
Progress[ 22%], ETA[ 154m], Batch [5480], G_Loss[0.165], D_Real_Loss[0.565], D_Fake_Loss[0.469]
Progress[ 22%], ETA[ 154m], Batch [5490], G_Loss[0.181], D_Real_Loss[0.681], D_Fake_Loss[0.323]
Progress[ 23%], ETA[ 153m], Batch [5500], G_Loss[0.157], D_Real_Loss[0.808], D_Fake_Loss[0.462]
Progress[ 23%], ETA[ 153m], Batch [5510], G_Loss[0.096], D_Real_Loss[0.465], D_Fake_Loss[0.973]
Progress[ 23%], ETA[ 153m], Batch [5520], G_Loss[0.122], D_Real_Loss[0.275], D_Fake_Loss[0.759]
Progress[ 23%], ETA[ 153m], Batch [5530], G_Loss[0.237], D_Real_Loss[0.896], D_Fake_Loss[0.197]
Progress[ 23%], ETA[ 153m], Batch [5540], G_Loss[0.127], D_Real_Loss[0.382], D_Fake_Loss[0.718]
Progress[ 23%], ETA[ 153m], Batch [5550], G_Loss[0.223], D_Real_Loss[1.225], D_Fake_Loss[0.223]
Progress[ 23%], ETA[ 153m], Batch [5560], G_Loss[0.198], D_Real_Loss[0.643], D_Fake_Loss[0.275]
Progress[ 23%], ETA[ 153m], Batch [5570], G_Loss[0.199], D_Real_Loss[0.339], D_Fake_Loss[0.281]
Progress[ 23%], ETA[ 153m], Batch [5580], G_Loss[0.158], D_Real_Loss[0.895], D_Fake_Loss[0.478]
Progress[ 23%], ETA[ 153m], Batch [5590], G_Loss[0.132], D_Real_Loss[0.394], D_Fake_Loss[0.605]
Progress[ 23%], ETA[ 153m], Batch [5600], G_Loss[0.177], D_Real_Loss[0.497], D_Fake_Loss[0.372]
    Saved train/batch005600_out.png
Progress[ 23%], ETA[ 153m], Batch [5610], G_Loss[0.156], D_Real_Loss[0.367], D_Fake_Loss[0.438]
Progress[ 23%], ETA[ 152m], Batch [5620], G_Loss[0.215], D_Real_Loss[0.784], D_Fake_Loss[0.212]
Progress[ 23%], ETA[ 152m], Batch [5630], G_Loss[0.141], D_Real_Loss[0.464], D_Fake_Loss[0.599]
Progress[ 23%], ETA[ 152m], Batch [5640], G_Loss[0.130], D_Real_Loss[0.351], D_Fake_Loss[0.617]
Progress[ 23%], ETA[ 152m], Batch [5650], G_Loss[0.156], D_Real_Loss[0.271], D_Fake_Loss[0.508]
Progress[ 23%], ETA[ 152m], Batch [5660], G_Loss[0.209], D_Real_Loss[0.494], D_Fake_Loss[0.263]
Progress[ 23%], ETA[ 152m], Batch [5670], G_Loss[0.117], D_Real_Loss[0.172], D_Fake_Loss[0.832]
Progress[ 23%], ETA[ 152m], Batch [5680], G_Loss[0.189], D_Real_Loss[0.674], D_Fake_Loss[0.307]
Progress[ 23%], ETA[ 152m], Batch [5690], G_Loss[0.158], D_Real_Loss[0.686], D_Fake_Loss[0.451]
Progress[ 23%], ETA[ 152m], Batch [5700], G_Loss[0.124], D_Real_Loss[0.274], D_Fake_Loss[0.630]
Progress[ 23%], ETA[ 152m], Batch [5710], G_Loss[0.182], D_Real_Loss[0.239], D_Fake_Loss[0.396]
Progress[ 23%], ETA[ 152m], Batch [5720], G_Loss[0.122], D_Real_Loss[0.400], D_Fake_Loss[0.663]
Progress[ 24%], ETA[ 151m], Batch [5730], G_Loss[0.138], D_Real_Loss[0.287], D_Fake_Loss[0.544]
Progress[ 24%], ETA[ 151m], Batch [5740], G_Loss[0.134], D_Real_Loss[0.422], D_Fake_Loss[0.585]
Progress[ 24%], ETA[ 151m], Batch [5750], G_Loss[0.236], D_Real_Loss[1.465], D_Fake_Loss[0.179]
Progress[ 24%], ETA[ 151m], Batch [5760], G_Loss[0.185], D_Real_Loss[0.602], D_Fake_Loss[0.293]
Progress[ 24%], ETA[ 151m], Batch [5770], G_Loss[0.220], D_Real_Loss[1.139], D_Fake_Loss[0.228]
Progress[ 24%], ETA[ 151m], Batch [5780], G_Loss[0.104], D_Real_Loss[0.271], D_Fake_Loss[0.973]
Progress[ 24%], ETA[ 151m], Batch [5790], G_Loss[0.158], D_Real_Loss[0.470], D_Fake_Loss[0.434]
Progress[ 24%], ETA[ 151m], Batch [5800], G_Loss[0.158], D_Real_Loss[0.584], D_Fake_Loss[0.470]
    Saved train/batch005800_out.png
Progress[ 24%], ETA[ 151m], Batch [5810], G_Loss[0.187], D_Real_Loss[0.859], D_Fake_Loss[0.309]
Progress[ 24%], ETA[ 151m], Batch [5820], G_Loss[0.129], D_Real_Loss[0.159], D_Fake_Loss[0.613]
Progress[ 24%], ETA[ 151m], Batch [5830], G_Loss[0.176], D_Real_Loss[0.378], D_Fake_Loss[0.492]
Progress[ 24%], ETA[ 151m], Batch [5840], G_Loss[0.145], D_Real_Loss[0.468], D_Fake_Loss[0.467]
Progress[ 24%], ETA[ 150m], Batch [5850], G_Loss[0.092], D_Real_Loss[0.163], D_Fake_Loss[1.061]
Progress[ 24%], ETA[ 150m], Batch [5860], G_Loss[0.119], D_Real_Loss[0.379], D_Fake_Loss[0.648]
Progress[ 24%], ETA[ 150m], Batch [5870], G_Loss[0.136], D_Real_Loss[0.327], D_Fake_Loss[0.531]
Progress[ 24%], ETA[ 150m], Batch [5880], G_Loss[0.243], D_Real_Loss[0.849], D_Fake_Loss[0.152]
Progress[ 24%], ETA[ 150m], Batch [5890], G_Loss[0.112], D_Real_Loss[0.214], D_Fake_Loss[0.701]
Progress[ 24%], ETA[ 150m], Batch [5900], G_Loss[0.168], D_Real_Loss[1.210], D_Fake_Loss[0.371]
Progress[ 24%], ETA[ 150m], Batch [5910], G_Loss[0.121], D_Real_Loss[0.435], D_Fake_Loss[0.643]
Progress[ 24%], ETA[ 150m], Batch [5920], G_Loss[0.092], D_Real_Loss[0.229], D_Fake_Loss[1.143]
Progress[ 24%], ETA[ 150m], Batch [5930], G_Loss[0.142], D_Real_Loss[0.625], D_Fake_Loss[0.504]
Progress[ 24%], ETA[ 150m], Batch [5940], G_Loss[0.129], D_Real_Loss[0.637], D_Fake_Loss[0.561]
Progress[ 24%], ETA[ 150m], Batch [5950], G_Loss[0.086], D_Real_Loss[0.213], D_Fake_Loss[1.016]
Progress[ 24%], ETA[ 150m], Batch [5960], G_Loss[0.200], D_Real_Loss[1.503], D_Fake_Loss[0.269]
Progress[ 25%], ETA[ 149m], Batch [5970], G_Loss[0.145], D_Real_Loss[0.568], D_Fake_Loss[0.454]
Progress[ 25%], ETA[ 149m], Batch [5980], G_Loss[0.149], D_Real_Loss[0.320], D_Fake_Loss[0.509]
Progress[ 25%], ETA[ 149m], Batch [5990], G_Loss[0.135], D_Real_Loss[0.753], D_Fake_Loss[0.534]
Progress[ 25%], ETA[ 149m], Batch [6000], G_Loss[0.111], D_Real_Loss[0.443], D_Fake_Loss[0.707]
    Saved train/batch006000_out.png
Progress[ 25%], ETA[ 149m], Batch [6010], G_Loss[0.156], D_Real_Loss[0.494], D_Fake_Loss[0.443]
Progress[ 25%], ETA[ 149m], Batch [6020], G_Loss[0.105], D_Real_Loss[0.340], D_Fake_Loss[0.778]
Progress[ 25%], ETA[ 149m], Batch [6030], G_Loss[0.221], D_Real_Loss[0.727], D_Fake_Loss[0.193]
Progress[ 25%], ETA[ 149m], Batch [6040], G_Loss[0.184], D_Real_Loss[0.757], D_Fake_Loss[0.284]
Progress[ 25%], ETA[ 149m], Batch [6050], G_Loss[0.108], D_Real_Loss[0.333], D_Fake_Loss[0.764]
Progress[ 25%], ETA[ 149m], Batch [6060], G_Loss[0.158], D_Real_Loss[1.192], D_Fake_Loss[0.394]
Progress[ 25%], ETA[ 149m], Batch [6070], G_Loss[0.137], D_Real_Loss[0.502], D_Fake_Loss[0.524]
Progress[ 25%], ETA[ 149m], Batch [6080], G_Loss[0.144], D_Real_Loss[0.365], D_Fake_Loss[0.449]
Progress[ 25%], ETA[ 148m], Batch [6090], G_Loss[0.130], D_Real_Loss[0.443], D_Fake_Loss[0.549]
Progress[ 25%], ETA[ 148m], Batch [6100], G_Loss[0.161], D_Real_Loss[0.423], D_Fake_Loss[0.524]
Progress[ 25%], ETA[ 148m], Batch [6110], G_Loss[0.146], D_Real_Loss[0.556], D_Fake_Loss[0.473]
Progress[ 25%], ETA[ 148m], Batch [6120], G_Loss[0.080], D_Real_Loss[0.293], D_Fake_Loss[1.339]
Progress[ 25%], ETA[ 148m], Batch [6130], G_Loss[0.156], D_Real_Loss[0.616], D_Fake_Loss[0.447]
Progress[ 25%], ETA[ 148m], Batch [6140], G_Loss[0.109], D_Real_Loss[0.104], D_Fake_Loss[0.699]
Progress[ 25%], ETA[ 148m], Batch [6150], G_Loss[0.204], D_Real_Loss[1.277], D_Fake_Loss[0.232]
Progress[ 25%], ETA[ 148m], Batch [6160], G_Loss[0.136], D_Real_Loss[0.516], D_Fake_Loss[0.547]
Progress[ 25%], ETA[ 148m], Batch [6170], G_Loss[0.156], D_Real_Loss[0.590], D_Fake_Loss[0.413]
Progress[ 25%], ETA[ 148m], Batch [6180], G_Loss[0.105], D_Real_Loss[0.523], D_Fake_Loss[0.759]
Progress[ 25%], ETA[ 148m], Batch [6190], G_Loss[0.201], D_Real_Loss[0.825], D_Fake_Loss[0.247]
Progress[ 25%], ETA[ 148m], Batch [6200], G_Loss[0.140], D_Real_Loss[0.545], D_Fake_Loss[0.500]
    Saved train/batch006200_out.png
Progress[ 26%], ETA[ 147m], Batch [6210], G_Loss[0.131], D_Real_Loss[0.577], D_Fake_Loss[0.559]
Progress[ 26%], ETA[ 147m], Batch [6220], G_Loss[0.199], D_Real_Loss[0.628], D_Fake_Loss[0.310]
Progress[ 26%], ETA[ 147m], Batch [6230], G_Loss[0.154], D_Real_Loss[0.624], D_Fake_Loss[0.438]
Progress[ 26%], ETA[ 147m], Batch [6240], G_Loss[0.178], D_Real_Loss[0.381], D_Fake_Loss[0.328]
Progress[ 26%], ETA[ 147m], Batch [6250], G_Loss[0.098], D_Real_Loss[0.113], D_Fake_Loss[0.790]
Progress[ 26%], ETA[ 147m], Batch [6260], G_Loss[0.146], D_Real_Loss[0.949], D_Fake_Loss[0.449]
Progress[ 26%], ETA[ 147m], Batch [6270], G_Loss[0.173], D_Real_Loss[0.340], D_Fake_Loss[0.316]
Progress[ 26%], ETA[ 147m], Batch [6280], G_Loss[0.169], D_Real_Loss[0.488], D_Fake_Loss[0.339]
Progress[ 26%], ETA[ 147m], Batch [6290], G_Loss[0.137], D_Real_Loss[0.382], D_Fake_Loss[0.548]
Progress[ 26%], ETA[ 147m], Batch [6300], G_Loss[0.112], D_Real_Loss[0.444], D_Fake_Loss[0.665]
Progress[ 26%], ETA[ 147m], Batch [6310], G_Loss[0.213], D_Real_Loss[0.422], D_Fake_Loss[0.234]
Progress[ 26%], ETA[ 147m], Batch [6320], G_Loss[0.146], D_Real_Loss[0.627], D_Fake_Loss[0.510]
Progress[ 26%], ETA[ 146m], Batch [6330], G_Loss[0.115], D_Real_Loss[0.141], D_Fake_Loss[0.751]
Progress[ 26%], ETA[ 146m], Batch [6340], G_Loss[0.130], D_Real_Loss[0.240], D_Fake_Loss[0.540]
Progress[ 26%], ETA[ 146m], Batch [6350], G_Loss[0.129], D_Real_Loss[0.535], D_Fake_Loss[0.575]
Progress[ 26%], ETA[ 146m], Batch [6360], G_Loss[0.184], D_Real_Loss[0.525], D_Fake_Loss[0.285]
Progress[ 26%], ETA[ 146m], Batch [6370], G_Loss[0.201], D_Real_Loss[0.360], D_Fake_Loss[0.248]
Progress[ 26%], ETA[ 146m], Batch [6380], G_Loss[0.159], D_Real_Loss[0.540], D_Fake_Loss[0.443]
Progress[ 26%], ETA[ 146m], Batch [6390], G_Loss[0.163], D_Real_Loss[0.462], D_Fake_Loss[0.370]
Progress[ 26%], ETA[ 146m], Batch [6400], G_Loss[0.114], D_Real_Loss[0.430], D_Fake_Loss[0.688]
    Saved train/batch006400_out.png
Progress[ 26%], ETA[ 146m], Batch [6410], G_Loss[0.184], D_Real_Loss[0.205], D_Fake_Loss[0.404]
Progress[ 26%], ETA[ 146m], Batch [6420], G_Loss[0.136], D_Real_Loss[0.460], D_Fake_Loss[0.558]
Progress[ 26%], ETA[ 146m], Batch [6430], G_Loss[0.173], D_Real_Loss[0.704], D_Fake_Loss[0.389]
Progress[ 27%], ETA[ 146m], Batch [6440], G_Loss[0.133], D_Real_Loss[0.293], D_Fake_Loss[0.542]
Progress[ 27%], ETA[ 145m], Batch [6450], G_Loss[0.096], D_Real_Loss[0.113], D_Fake_Loss[0.890]
Progress[ 27%], ETA[ 145m], Batch [6460], G_Loss[0.141], D_Real_Loss[0.152], D_Fake_Loss[0.482]
Progress[ 27%], ETA[ 145m], Batch [6470], G_Loss[0.166], D_Real_Loss[0.437], D_Fake_Loss[0.411]
Progress[ 27%], ETA[ 145m], Batch [6480], G_Loss[0.136], D_Real_Loss[0.282], D_Fake_Loss[0.555]
Progress[ 27%], ETA[ 145m], Batch [6490], G_Loss[0.180], D_Real_Loss[0.333], D_Fake_Loss[0.294]
Progress[ 27%], ETA[ 145m], Batch [6500], G_Loss[0.132], D_Real_Loss[0.298], D_Fake_Loss[0.600]
Progress[ 27%], ETA[ 145m], Batch [6510], G_Loss[0.143], D_Real_Loss[0.199], D_Fake_Loss[0.485]
Progress[ 27%], ETA[ 145m], Batch [6520], G_Loss[0.123], D_Real_Loss[0.412], D_Fake_Loss[0.631]
Progress[ 27%], ETA[ 145m], Batch [6530], G_Loss[0.238], D_Real_Loss[0.098], D_Fake_Loss[0.183]
Progress[ 27%], ETA[ 145m], Batch [6540], G_Loss[0.180], D_Real_Loss[0.436], D_Fake_Loss[0.343]
Progress[ 27%], ETA[ 145m], Batch [6550], G_Loss[0.080], D_Real_Loss[0.273], D_Fake_Loss[1.683]
Progress[ 27%], ETA[ 144m], Batch [6560], G_Loss[0.202], D_Real_Loss[0.805], D_Fake_Loss[0.244]
Progress[ 27%], ETA[ 144m], Batch [6570], G_Loss[0.233], D_Real_Loss[1.107], D_Fake_Loss[0.203]
Progress[ 27%], ETA[ 144m], Batch [6580], G_Loss[0.167], D_Real_Loss[0.676], D_Fake_Loss[0.346]
Progress[ 27%], ETA[ 144m], Batch [6590], G_Loss[0.096], D_Real_Loss[0.331], D_Fake_Loss[0.929]
Progress[ 27%], ETA[ 144m], Batch [6600], G_Loss[0.137], D_Real_Loss[1.136], D_Fake_Loss[0.526]
    Saved train/batch006600_out.png
Progress[ 27%], ETA[ 144m], Batch [6610], G_Loss[0.151], D_Real_Loss[0.146], D_Fake_Loss[0.437]
Progress[ 27%], ETA[ 144m], Batch [6620], G_Loss[0.161], D_Real_Loss[0.806], D_Fake_Loss[0.371]
Progress[ 27%], ETA[ 144m], Batch [6630], G_Loss[0.115], D_Real_Loss[0.346], D_Fake_Loss[0.794]
Progress[ 27%], ETA[ 144m], Batch [6640], G_Loss[0.139], D_Real_Loss[0.248], D_Fake_Loss[0.512]
Progress[ 27%], ETA[ 144m], Batch [6650], G_Loss[0.245], D_Real_Loss[1.005], D_Fake_Loss[0.147]
Progress[ 27%], ETA[ 144m], Batch [6660], G_Loss[0.163], D_Real_Loss[0.199], D_Fake_Loss[0.424]
Progress[ 27%], ETA[ 144m], Batch [6670], G_Loss[0.129], D_Real_Loss[0.331], D_Fake_Loss[0.539]
Progress[ 28%], ETA[ 143m], Batch [6680], G_Loss[0.112], D_Real_Loss[0.511], D_Fake_Loss[0.837]
Progress[ 28%], ETA[ 143m], Batch [6690], G_Loss[0.149], D_Real_Loss[0.579], D_Fake_Loss[0.507]
Progress[ 28%], ETA[ 143m], Batch [6700], G_Loss[0.106], D_Real_Loss[0.136], D_Fake_Loss[0.754]
Progress[ 28%], ETA[ 143m], Batch [6710], G_Loss[0.148], D_Real_Loss[0.390], D_Fake_Loss[0.465]
Progress[ 28%], ETA[ 143m], Batch [6720], G_Loss[0.259], D_Real_Loss[1.269], D_Fake_Loss[0.136]
Progress[ 28%], ETA[ 143m], Batch [6730], G_Loss[0.198], D_Real_Loss[0.738], D_Fake_Loss[0.316]
Progress[ 28%], ETA[ 143m], Batch [6740], G_Loss[0.228], D_Real_Loss[0.787], D_Fake_Loss[0.187]
Progress[ 28%], ETA[ 143m], Batch [6750], G_Loss[0.180], D_Real_Loss[0.140], D_Fake_Loss[0.300]
Progress[ 28%], ETA[ 143m], Batch [6760], G_Loss[0.160], D_Real_Loss[0.634], D_Fake_Loss[0.464]
Progress[ 28%], ETA[ 143m], Batch [6770], G_Loss[0.165], D_Real_Loss[0.517], D_Fake_Loss[0.390]
Progress[ 28%], ETA[ 143m], Batch [6780], G_Loss[0.158], D_Real_Loss[0.454], D_Fake_Loss[0.430]
Progress[ 28%], ETA[ 143m], Batch [6790], G_Loss[0.216], D_Real_Loss[0.818], D_Fake_Loss[0.201]
Progress[ 28%], ETA[ 142m], Batch [6800], G_Loss[0.097], D_Real_Loss[0.194], D_Fake_Loss[0.867]
    Saved train/batch006800_out.png
Progress[ 28%], ETA[ 142m], Batch [6810], G_Loss[0.219], D_Real_Loss[0.388], D_Fake_Loss[0.224]
Progress[ 28%], ETA[ 142m], Batch [6820], G_Loss[0.155], D_Real_Loss[0.296], D_Fake_Loss[0.524]
Progress[ 28%], ETA[ 142m], Batch [6830], G_Loss[0.161], D_Real_Loss[0.286], D_Fake_Loss[0.382]
Progress[ 28%], ETA[ 142m], Batch [6840], G_Loss[0.151], D_Real_Loss[0.493], D_Fake_Loss[0.431]
Progress[ 28%], ETA[ 142m], Batch [6850], G_Loss[0.113], D_Real_Loss[0.192], D_Fake_Loss[0.793]
Progress[ 28%], ETA[ 142m], Batch [6860], G_Loss[0.144], D_Real_Loss[0.279], D_Fake_Loss[0.502]
Progress[ 28%], ETA[ 142m], Batch [6870], G_Loss[0.187], D_Real_Loss[0.431], D_Fake_Loss[0.320]
Progress[ 28%], ETA[ 142m], Batch [6880], G_Loss[0.145], D_Real_Loss[0.664], D_Fake_Loss[0.498]
Progress[ 28%], ETA[ 142m], Batch [6890], G_Loss[0.146], D_Real_Loss[0.337], D_Fake_Loss[0.482]
Progress[ 28%], ETA[ 142m], Batch [6900], G_Loss[0.106], D_Real_Loss[0.163], D_Fake_Loss[0.839]
Progress[ 28%], ETA[ 142m], Batch [6910], G_Loss[0.183], D_Real_Loss[0.602], D_Fake_Loss[0.309]
Progress[ 29%], ETA[ 141m], Batch [6920], G_Loss[0.180], D_Real_Loss[0.511], D_Fake_Loss[0.333]
Progress[ 29%], ETA[ 141m], Batch [6930], G_Loss[0.174], D_Real_Loss[0.283], D_Fake_Loss[0.427]
Progress[ 29%], ETA[ 141m], Batch [6940], G_Loss[0.099], D_Real_Loss[0.348], D_Fake_Loss[0.829]
Progress[ 29%], ETA[ 141m], Batch [6950], G_Loss[0.144], D_Real_Loss[0.094], D_Fake_Loss[0.451]
Progress[ 29%], ETA[ 141m], Batch [6960], G_Loss[0.122], D_Real_Loss[0.571], D_Fake_Loss[0.588]
Progress[ 29%], ETA[ 141m], Batch [6970], G_Loss[0.115], D_Real_Loss[0.517], D_Fake_Loss[0.719]
Progress[ 29%], ETA[ 141m], Batch [6980], G_Loss[0.125], D_Real_Loss[0.182], D_Fake_Loss[0.646]
Progress[ 29%], ETA[ 141m], Batch [6990], G_Loss[0.187], D_Real_Loss[0.566], D_Fake_Loss[0.289]
Progress[ 29%], ETA[ 141m], Batch [7000], G_Loss[0.157], D_Real_Loss[0.422], D_Fake_Loss[0.443]
    Saved train/batch007000_out.png
Progress[ 29%], ETA[ 141m], Batch [7010], G_Loss[0.170], D_Real_Loss[0.380], D_Fake_Loss[0.383]
Progress[ 29%], ETA[ 141m], Batch [7020], G_Loss[0.178], D_Real_Loss[0.337], D_Fake_Loss[0.312]
Progress[ 29%], ETA[ 141m], Batch [7030], G_Loss[0.210], D_Real_Loss[0.970], D_Fake_Loss[0.223]
Progress[ 29%], ETA[ 140m], Batch [7040], G_Loss[0.172], D_Real_Loss[0.236], D_Fake_Loss[0.343]
Progress[ 29%], ETA[ 140m], Batch [7050], G_Loss[0.128], D_Real_Loss[0.510], D_Fake_Loss[0.628]
Progress[ 29%], ETA[ 140m], Batch [7060], G_Loss[0.191], D_Real_Loss[0.300], D_Fake_Loss[0.284]
Progress[ 29%], ETA[ 140m], Batch [7070], G_Loss[0.194], D_Real_Loss[1.064], D_Fake_Loss[0.259]
Progress[ 29%], ETA[ 140m], Batch [7080], G_Loss[0.215], D_Real_Loss[0.784], D_Fake_Loss[0.197]
Progress[ 29%], ETA[ 140m], Batch [7090], G_Loss[0.125], D_Real_Loss[0.089], D_Fake_Loss[0.628]
Progress[ 29%], ETA[ 140m], Batch [7100], G_Loss[0.154], D_Real_Loss[0.416], D_Fake_Loss[0.493]
Progress[ 29%], ETA[ 140m], Batch [7110], G_Loss[0.207], D_Real_Loss[0.184], D_Fake_Loss[0.302]
Progress[ 29%], ETA[ 140m], Batch [7120], G_Loss[0.128], D_Real_Loss[0.169], D_Fake_Loss[0.672]
Progress[ 29%], ETA[ 140m], Batch [7130], G_Loss[0.237], D_Real_Loss[0.443], D_Fake_Loss[0.208]
Progress[ 29%], ETA[ 140m], Batch [7140], G_Loss[0.183], D_Real_Loss[0.317], D_Fake_Loss[0.391]
Progress[ 29%], ETA[ 140m], Batch [7150], G_Loss[0.150], D_Real_Loss[0.434], D_Fake_Loss[0.498]
Progress[ 30%], ETA[ 139m], Batch [7160], G_Loss[0.216], D_Real_Loss[0.325], D_Fake_Loss[0.282]
Progress[ 30%], ETA[ 139m], Batch [7170], G_Loss[0.211], D_Real_Loss[0.918], D_Fake_Loss[0.241]
Progress[ 30%], ETA[ 139m], Batch [7180], G_Loss[0.337], D_Real_Loss[0.680], D_Fake_Loss[0.075]
Progress[ 30%], ETA[ 139m], Batch [7190], G_Loss[0.150], D_Real_Loss[0.180], D_Fake_Loss[0.602]
Progress[ 30%], ETA[ 139m], Batch [7200], G_Loss[0.113], D_Real_Loss[0.236], D_Fake_Loss[0.735]
    Saved train/batch007200_out.png
Progress[ 30%], ETA[ 139m], Batch [7210], G_Loss[0.248], D_Real_Loss[0.301], D_Fake_Loss[0.211]
Progress[ 30%], ETA[ 139m], Batch [7220], G_Loss[0.137], D_Real_Loss[0.478], D_Fake_Loss[0.594]
Progress[ 30%], ETA[ 139m], Batch [7230], G_Loss[0.134], D_Real_Loss[0.877], D_Fake_Loss[0.629]
Progress[ 30%], ETA[ 139m], Batch [7240], G_Loss[0.220], D_Real_Loss[0.790], D_Fake_Loss[0.232]
Progress[ 30%], ETA[ 139m], Batch [7250], G_Loss[0.161], D_Real_Loss[1.219], D_Fake_Loss[0.418]
Progress[ 30%], ETA[ 139m], Batch [7260], G_Loss[0.193], D_Real_Loss[0.560], D_Fake_Loss[0.339]
Progress[ 30%], ETA[ 139m], Batch [7270], G_Loss[0.216], D_Real_Loss[0.768], D_Fake_Loss[0.309]
Progress[ 30%], ETA[ 138m], Batch [7280], G_Loss[0.172], D_Real_Loss[0.277], D_Fake_Loss[0.384]
Progress[ 30%], ETA[ 138m], Batch [7290], G_Loss[0.154], D_Real_Loss[0.245], D_Fake_Loss[0.480]
Progress[ 30%], ETA[ 138m], Batch [7300], G_Loss[0.120], D_Real_Loss[0.156], D_Fake_Loss[0.796]
Progress[ 30%], ETA[ 138m], Batch [7310], G_Loss[0.176], D_Real_Loss[0.134], D_Fake_Loss[0.354]
Progress[ 30%], ETA[ 138m], Batch [7320], G_Loss[0.141], D_Real_Loss[0.217], D_Fake_Loss[0.626]
Progress[ 30%], ETA[ 138m], Batch [7330], G_Loss[0.208], D_Real_Loss[0.267], D_Fake_Loss[0.290]
Progress[ 30%], ETA[ 138m], Batch [7340], G_Loss[0.135], D_Real_Loss[0.856], D_Fake_Loss[0.676]
Progress[ 30%], ETA[ 138m], Batch [7350], G_Loss[0.183], D_Real_Loss[0.890], D_Fake_Loss[0.376]
Progress[ 30%], ETA[ 138m], Batch [7360], G_Loss[0.130], D_Real_Loss[0.419], D_Fake_Loss[0.580]
Progress[ 30%], ETA[ 138m], Batch [7370], G_Loss[0.254], D_Real_Loss[0.618], D_Fake_Loss[0.164]
Progress[ 30%], ETA[ 138m], Batch [7380], G_Loss[0.196], D_Real_Loss[0.586], D_Fake_Loss[0.282]
Progress[ 30%], ETA[ 138m], Batch [7390], G_Loss[0.237], D_Real_Loss[1.219], D_Fake_Loss[0.190]
Progress[ 31%], ETA[ 137m], Batch [7400], G_Loss[0.234], D_Real_Loss[0.769], D_Fake_Loss[0.205]
    Saved train/batch007400_out.png
Progress[ 31%], ETA[ 137m], Batch [7410], G_Loss[0.186], D_Real_Loss[0.337], D_Fake_Loss[0.322]
Progress[ 31%], ETA[ 137m], Batch [7420], G_Loss[0.126], D_Real_Loss[0.247], D_Fake_Loss[0.674]
Progress[ 31%], ETA[ 137m], Batch [7430], G_Loss[0.156], D_Real_Loss[0.295], D_Fake_Loss[0.459]
Progress[ 31%], ETA[ 137m], Batch [7440], G_Loss[0.165], D_Real_Loss[0.375], D_Fake_Loss[0.445]
Progress[ 31%], ETA[ 137m], Batch [7450], G_Loss[0.321], D_Real_Loss[0.771], D_Fake_Loss[0.074]
Progress[ 31%], ETA[ 137m], Batch [7460], G_Loss[0.258], D_Real_Loss[0.321], D_Fake_Loss[0.157]
Progress[ 31%], ETA[ 137m], Batch [7470], G_Loss[0.247], D_Real_Loss[1.089], D_Fake_Loss[0.181]
Progress[ 31%], ETA[ 137m], Batch [7480], G_Loss[0.197], D_Real_Loss[0.831], D_Fake_Loss[0.311]
Progress[ 31%], ETA[ 137m], Batch [7490], G_Loss[0.098], D_Real_Loss[0.217], D_Fake_Loss[1.107]
Progress[ 31%], ETA[ 137m], Batch [7500], G_Loss[0.163], D_Real_Loss[0.134], D_Fake_Loss[0.490]
Progress[ 31%], ETA[ 137m], Batch [7510], G_Loss[0.133], D_Real_Loss[0.654], D_Fake_Loss[0.605]
Progress[ 31%], ETA[ 136m], Batch [7520], G_Loss[0.186], D_Real_Loss[0.381], D_Fake_Loss[0.310]
Progress[ 31%], ETA[ 136m], Batch [7530], G_Loss[0.084], D_Real_Loss[0.270], D_Fake_Loss[1.157]
Progress[ 31%], ETA[ 136m], Batch [7540], G_Loss[0.240], D_Real_Loss[0.315], D_Fake_Loss[0.204]
Progress[ 31%], ETA[ 136m], Batch [7550], G_Loss[0.214], D_Real_Loss[0.437], D_Fake_Loss[0.225]
Progress[ 31%], ETA[ 136m], Batch [7560], G_Loss[0.174], D_Real_Loss[1.225], D_Fake_Loss[0.353]
Progress[ 31%], ETA[ 136m], Batch [7570], G_Loss[0.125], D_Real_Loss[0.342], D_Fake_Loss[0.657]
Progress[ 31%], ETA[ 136m], Batch [7580], G_Loss[0.113], D_Real_Loss[0.141], D_Fake_Loss[0.764]
Progress[ 31%], ETA[ 136m], Batch [7590], G_Loss[0.159], D_Real_Loss[0.510], D_Fake_Loss[0.439]
Progress[ 31%], ETA[ 136m], Batch [7600], G_Loss[0.178], D_Real_Loss[0.517], D_Fake_Loss[0.355]
    Saved train/batch007600_out.png
Progress[ 31%], ETA[ 136m], Batch [7610], G_Loss[0.127], D_Real_Loss[0.396], D_Fake_Loss[0.713]
Progress[ 31%], ETA[ 136m], Batch [7620], G_Loss[0.200], D_Real_Loss[0.215], D_Fake_Loss[0.260]
Progress[ 31%], ETA[ 136m], Batch [7630], G_Loss[0.112], D_Real_Loss[0.257], D_Fake_Loss[0.816]
Progress[ 32%], ETA[ 135m], Batch [7640], G_Loss[0.204], D_Real_Loss[0.974], D_Fake_Loss[0.260]
Progress[ 32%], ETA[ 135m], Batch [7650], G_Loss[0.162], D_Real_Loss[0.490], D_Fake_Loss[0.361]
Progress[ 32%], ETA[ 135m], Batch [7660], G_Loss[0.253], D_Real_Loss[1.620], D_Fake_Loss[0.148]
Progress[ 32%], ETA[ 135m], Batch [7670], G_Loss[0.165], D_Real_Loss[0.636], D_Fake_Loss[0.349]
Progress[ 32%], ETA[ 135m], Batch [7680], G_Loss[0.189], D_Real_Loss[0.406], D_Fake_Loss[0.276]
Progress[ 32%], ETA[ 135m], Batch [7690], G_Loss[0.133], D_Real_Loss[0.478], D_Fake_Loss[0.554]
Progress[ 32%], ETA[ 135m], Batch [7700], G_Loss[0.358], D_Real_Loss[1.594], D_Fake_Loss[0.047]
Progress[ 32%], ETA[ 135m], Batch [7710], G_Loss[0.105], D_Real_Loss[0.304], D_Fake_Loss[0.806]
Progress[ 32%], ETA[ 135m], Batch [7720], G_Loss[0.156], D_Real_Loss[0.269], D_Fake_Loss[0.466]
Progress[ 32%], ETA[ 135m], Batch [7730], G_Loss[0.202], D_Real_Loss[0.658], D_Fake_Loss[0.240]
Progress[ 32%], ETA[ 135m], Batch [7740], G_Loss[0.135], D_Real_Loss[0.247], D_Fake_Loss[0.501]
Progress[ 32%], ETA[ 135m], Batch [7750], G_Loss[0.178], D_Real_Loss[0.411], D_Fake_Loss[0.295]
Progress[ 32%], ETA[ 134m], Batch [7760], G_Loss[0.201], D_Real_Loss[1.228], D_Fake_Loss[0.243]
Progress[ 32%], ETA[ 134m], Batch [7770], G_Loss[0.234], D_Real_Loss[1.334], D_Fake_Loss[0.158]
Progress[ 32%], ETA[ 134m], Batch [7780], G_Loss[0.169], D_Real_Loss[0.268], D_Fake_Loss[0.354]
Progress[ 32%], ETA[ 134m], Batch [7790], G_Loss[0.220], D_Real_Loss[1.068], D_Fake_Loss[0.193]
Progress[ 32%], ETA[ 134m], Batch [7800], G_Loss[0.160], D_Real_Loss[0.367], D_Fake_Loss[0.384]
    Saved train/batch007800_out.png
Progress[ 32%], ETA[ 134m], Batch [7810], G_Loss[0.180], D_Real_Loss[0.661], D_Fake_Loss[0.361]
Progress[ 32%], ETA[ 134m], Batch [7820], G_Loss[0.239], D_Real_Loss[0.432], D_Fake_Loss[0.164]
Progress[ 32%], ETA[ 134m], Batch [7830], G_Loss[0.099], D_Real_Loss[0.136], D_Fake_Loss[0.813]
Progress[ 32%], ETA[ 134m], Batch [7840], G_Loss[0.078], D_Real_Loss[0.135], D_Fake_Loss[1.133]
Progress[ 32%], ETA[ 134m], Batch [7850], G_Loss[0.191], D_Real_Loss[0.401], D_Fake_Loss[0.269]
Progress[ 32%], ETA[ 134m], Batch [7860], G_Loss[0.118], D_Real_Loss[0.185], D_Fake_Loss[0.644]
Progress[ 32%], ETA[ 134m], Batch [7870], G_Loss[0.134], D_Real_Loss[0.220], D_Fake_Loss[0.708]
Progress[ 33%], ETA[ 133m], Batch [7880], G_Loss[0.169], D_Real_Loss[0.272], D_Fake_Loss[0.421]
Progress[ 33%], ETA[ 133m], Batch [7890], G_Loss[0.197], D_Real_Loss[0.265], D_Fake_Loss[0.266]
Progress[ 33%], ETA[ 133m], Batch [7900], G_Loss[0.212], D_Real_Loss[0.744], D_Fake_Loss[0.211]
Progress[ 33%], ETA[ 133m], Batch [7910], G_Loss[0.097], D_Real_Loss[0.117], D_Fake_Loss[0.854]
Progress[ 33%], ETA[ 133m], Batch [7920], G_Loss[0.150], D_Real_Loss[0.509], D_Fake_Loss[0.443]
Progress[ 33%], ETA[ 133m], Batch [7930], G_Loss[0.226], D_Real_Loss[0.748], D_Fake_Loss[0.195]
Progress[ 33%], ETA[ 133m], Batch [7940], G_Loss[0.116], D_Real_Loss[0.468], D_Fake_Loss[0.645]
Progress[ 33%], ETA[ 133m], Batch [7950], G_Loss[0.119], D_Real_Loss[0.302], D_Fake_Loss[0.686]
Progress[ 33%], ETA[ 133m], Batch [7960], G_Loss[0.139], D_Real_Loss[0.442], D_Fake_Loss[0.497]
Progress[ 33%], ETA[ 133m], Batch [7970], G_Loss[0.233], D_Real_Loss[0.511], D_Fake_Loss[0.184]
Progress[ 33%], ETA[ 133m], Batch [7980], G_Loss[0.191], D_Real_Loss[0.844], D_Fake_Loss[0.293]
Progress[ 33%], ETA[ 133m], Batch [7990], G_Loss[0.222], D_Real_Loss[0.732], D_Fake_Loss[0.189]
Progress[ 33%], ETA[ 132m], Batch [8000], G_Loss[0.153], D_Real_Loss[0.182], D_Fake_Loss[0.394]
    Saved train/batch008000_out.png
Progress[ 33%], ETA[ 132m], Batch [8010], G_Loss[0.173], D_Real_Loss[0.538], D_Fake_Loss[0.412]
Progress[ 33%], ETA[ 132m], Batch [8020], G_Loss[0.118], D_Real_Loss[0.310], D_Fake_Loss[0.666]
Progress[ 33%], ETA[ 132m], Batch [8030], G_Loss[0.173], D_Real_Loss[0.557], D_Fake_Loss[0.438]
Progress[ 33%], ETA[ 132m], Batch [8040], G_Loss[0.194], D_Real_Loss[0.379], D_Fake_Loss[0.293]
Progress[ 33%], ETA[ 132m], Batch [8050], G_Loss[0.180], D_Real_Loss[0.757], D_Fake_Loss[0.338]
Progress[ 33%], ETA[ 132m], Batch [8060], G_Loss[0.161], D_Real_Loss[0.765], D_Fake_Loss[0.399]
Progress[ 33%], ETA[ 132m], Batch [8070], G_Loss[0.138], D_Real_Loss[0.121], D_Fake_Loss[0.512]
Progress[ 33%], ETA[ 132m], Batch [8080], G_Loss[0.206], D_Real_Loss[0.307], D_Fake_Loss[0.239]
Progress[ 33%], ETA[ 132m], Batch [8090], G_Loss[0.101], D_Real_Loss[0.245], D_Fake_Loss[0.994]
Progress[ 33%], ETA[ 132m], Batch [8100], G_Loss[0.146], D_Real_Loss[0.152], D_Fake_Loss[0.591]
Progress[ 34%], ETA[ 132m], Batch [8110], G_Loss[0.217], D_Real_Loss[0.352], D_Fake_Loss[0.267]
Progress[ 34%], ETA[ 131m], Batch [8120], G_Loss[0.222], D_Real_Loss[0.423], D_Fake_Loss[0.267]
Progress[ 34%], ETA[ 131m], Batch [8130], G_Loss[0.185], D_Real_Loss[0.432], D_Fake_Loss[0.489]
Progress[ 34%], ETA[ 131m], Batch [8140], G_Loss[0.093], D_Real_Loss[0.166], D_Fake_Loss[1.501]
Progress[ 34%], ETA[ 131m], Batch [8150], G_Loss[0.152], D_Real_Loss[0.195], D_Fake_Loss[0.508]
Progress[ 34%], ETA[ 131m], Batch [8160], G_Loss[0.150], D_Real_Loss[0.177], D_Fake_Loss[0.620]
Progress[ 34%], ETA[ 131m], Batch [8170], G_Loss[0.155], D_Real_Loss[0.668], D_Fake_Loss[0.486]
Progress[ 34%], ETA[ 131m], Batch [8180], G_Loss[0.204], D_Real_Loss[0.651], D_Fake_Loss[0.268]
Progress[ 34%], ETA[ 131m], Batch [8190], G_Loss[0.189], D_Real_Loss[0.299], D_Fake_Loss[0.320]
Progress[ 34%], ETA[ 131m], Batch [8200], G_Loss[0.261], D_Real_Loss[0.713], D_Fake_Loss[0.141]
    Saved train/batch008200_out.png
Progress[ 34%], ETA[ 131m], Batch [8210], G_Loss[0.229], D_Real_Loss[0.375], D_Fake_Loss[0.230]
Progress[ 34%], ETA[ 131m], Batch [8220], G_Loss[0.096], D_Real_Loss[0.438], D_Fake_Loss[1.092]
Progress[ 34%], ETA[ 130m], Batch [8230], G_Loss[0.277], D_Real_Loss[1.357], D_Fake_Loss[0.131]
Progress[ 34%], ETA[ 130m], Batch [8240], G_Loss[0.182], D_Real_Loss[0.148], D_Fake_Loss[0.359]
Progress[ 34%], ETA[ 130m], Batch [8250], G_Loss[0.198], D_Real_Loss[0.268], D_Fake_Loss[0.272]
Progress[ 34%], ETA[ 130m], Batch [8260], G_Loss[0.200], D_Real_Loss[0.737], D_Fake_Loss[0.295]
Progress[ 34%], ETA[ 130m], Batch [8270], G_Loss[0.092], D_Real_Loss[0.071], D_Fake_Loss[1.305]
Progress[ 34%], ETA[ 130m], Batch [8280], G_Loss[0.205], D_Real_Loss[0.375], D_Fake_Loss[0.252]
Progress[ 34%], ETA[ 130m], Batch [8290], G_Loss[0.267], D_Real_Loss[0.539], D_Fake_Loss[0.124]
Progress[ 34%], ETA[ 130m], Batch [8300], G_Loss[0.226], D_Real_Loss[0.261], D_Fake_Loss[0.188]
Progress[ 34%], ETA[ 130m], Batch [8310], G_Loss[0.217], D_Real_Loss[0.203], D_Fake_Loss[0.210]
Progress[ 34%], ETA[ 130m], Batch [8320], G_Loss[0.218], D_Real_Loss[0.967], D_Fake_Loss[0.211]
Progress[ 34%], ETA[ 130m], Batch [8330], G_Loss[0.172], D_Real_Loss[0.262], D_Fake_Loss[0.408]
Progress[ 34%], ETA[ 130m], Batch [8340], G_Loss[0.278], D_Real_Loss[0.392], D_Fake_Loss[0.118]
Progress[ 35%], ETA[ 129m], Batch [8350], G_Loss[0.207], D_Real_Loss[0.467], D_Fake_Loss[0.279]
Progress[ 35%], ETA[ 129m], Batch [8360], G_Loss[0.152], D_Real_Loss[0.142], D_Fake_Loss[0.468]
Progress[ 35%], ETA[ 129m], Batch [8370], G_Loss[0.168], D_Real_Loss[0.249], D_Fake_Loss[0.420]
Progress[ 35%], ETA[ 129m], Batch [8380], G_Loss[0.069], D_Real_Loss[0.061], D_Fake_Loss[1.699]
Progress[ 35%], ETA[ 129m], Batch [8390], G_Loss[0.129], D_Real_Loss[0.110], D_Fake_Loss[0.666]
Progress[ 35%], ETA[ 129m], Batch [8400], G_Loss[0.157], D_Real_Loss[0.210], D_Fake_Loss[0.473]
    Saved train/batch008400_out.png
Progress[ 35%], ETA[ 129m], Batch [8410], G_Loss[0.211], D_Real_Loss[0.502], D_Fake_Loss[0.226]
Progress[ 35%], ETA[ 129m], Batch [8420], G_Loss[0.141], D_Real_Loss[0.395], D_Fake_Loss[0.521]
Progress[ 35%], ETA[ 129m], Batch [8430], G_Loss[0.194], D_Real_Loss[0.283], D_Fake_Loss[0.288]
Progress[ 35%], ETA[ 129m], Batch [8440], G_Loss[0.169], D_Real_Loss[0.320], D_Fake_Loss[0.394]
Progress[ 35%], ETA[ 129m], Batch [8450], G_Loss[0.170], D_Real_Loss[0.389], D_Fake_Loss[0.413]
Progress[ 35%], ETA[ 129m], Batch [8460], G_Loss[0.146], D_Real_Loss[0.234], D_Fake_Loss[0.485]
Progress[ 35%], ETA[ 128m], Batch [8470], G_Loss[0.198], D_Real_Loss[0.640], D_Fake_Loss[0.308]
Progress[ 35%], ETA[ 128m], Batch [8480], G_Loss[0.383], D_Real_Loss[0.680], D_Fake_Loss[0.037]
Progress[ 35%], ETA[ 128m], Batch [8490], G_Loss[0.205], D_Real_Loss[0.422], D_Fake_Loss[0.245]
Progress[ 35%], ETA[ 128m], Batch [8500], G_Loss[0.170], D_Real_Loss[0.293], D_Fake_Loss[0.374]
Progress[ 35%], ETA[ 128m], Batch [8510], G_Loss[0.162], D_Real_Loss[0.572], D_Fake_Loss[0.373]
Progress[ 35%], ETA[ 128m], Batch [8520], G_Loss[0.143], D_Real_Loss[0.311], D_Fake_Loss[0.486]
Progress[ 35%], ETA[ 128m], Batch [8530], G_Loss[0.239], D_Real_Loss[0.501], D_Fake_Loss[0.162]
Progress[ 35%], ETA[ 128m], Batch [8540], G_Loss[0.105], D_Real_Loss[0.232], D_Fake_Loss[0.808]
Progress[ 35%], ETA[ 128m], Batch [8550], G_Loss[0.106], D_Real_Loss[0.250], D_Fake_Loss[0.879]
Progress[ 35%], ETA[ 128m], Batch [8560], G_Loss[0.312], D_Real_Loss[0.638], D_Fake_Loss[0.075]
Progress[ 35%], ETA[ 128m], Batch [8570], G_Loss[0.195], D_Real_Loss[0.673], D_Fake_Loss[0.285]
Progress[ 35%], ETA[ 128m], Batch [8580], G_Loss[0.250], D_Real_Loss[0.824], D_Fake_Loss[0.155]
Progress[ 36%], ETA[ 127m], Batch [8590], G_Loss[0.114], D_Real_Loss[0.515], D_Fake_Loss[0.736]
Progress[ 36%], ETA[ 127m], Batch [8600], G_Loss[0.213], D_Real_Loss[0.405], D_Fake_Loss[0.212]
    Saved train/batch008600_out.png
Progress[ 36%], ETA[ 127m], Batch [8610], G_Loss[0.135], D_Real_Loss[0.578], D_Fake_Loss[0.529]
Progress[ 36%], ETA[ 127m], Batch [8620], G_Loss[0.084], D_Real_Loss[0.145], D_Fake_Loss[1.258]
Progress[ 36%], ETA[ 127m], Batch [8630], G_Loss[0.233], D_Real_Loss[0.508], D_Fake_Loss[0.179]
Progress[ 36%], ETA[ 127m], Batch [8640], G_Loss[0.187], D_Real_Loss[0.441], D_Fake_Loss[0.285]
Progress[ 36%], ETA[ 127m], Batch [8650], G_Loss[0.112], D_Real_Loss[0.167], D_Fake_Loss[0.860]
Progress[ 36%], ETA[ 127m], Batch [8660], G_Loss[0.260], D_Real_Loss[0.456], D_Fake_Loss[0.138]
Progress[ 36%], ETA[ 127m], Batch [8670], G_Loss[0.176], D_Real_Loss[0.556], D_Fake_Loss[0.424]
Progress[ 36%], ETA[ 127m], Batch [8680], G_Loss[0.141], D_Real_Loss[0.175], D_Fake_Loss[0.554]
Progress[ 36%], ETA[ 127m], Batch [8690], G_Loss[0.199], D_Real_Loss[0.584], D_Fake_Loss[0.290]
Progress[ 36%], ETA[ 127m], Batch [8700], G_Loss[0.154], D_Real_Loss[0.360], D_Fake_Loss[0.449]
Progress[ 36%], ETA[ 126m], Batch [8710], G_Loss[0.260], D_Real_Loss[0.366], D_Fake_Loss[0.152]
Progress[ 36%], ETA[ 126m], Batch [8720], G_Loss[0.097], D_Real_Loss[0.162], D_Fake_Loss[0.977]
Progress[ 36%], ETA[ 126m], Batch [8730], G_Loss[0.161], D_Real_Loss[0.358], D_Fake_Loss[0.392]
Progress[ 36%], ETA[ 126m], Batch [8740], G_Loss[0.361], D_Real_Loss[1.137], D_Fake_Loss[0.055]
Progress[ 36%], ETA[ 126m], Batch [8750], G_Loss[0.212], D_Real_Loss[0.325], D_Fake_Loss[0.225]
Progress[ 36%], ETA[ 126m], Batch [8760], G_Loss[0.143], D_Real_Loss[0.444], D_Fake_Loss[0.485]
Progress[ 36%], ETA[ 126m], Batch [8770], G_Loss[0.216], D_Real_Loss[0.866], D_Fake_Loss[0.235]
Progress[ 36%], ETA[ 126m], Batch [8780], G_Loss[0.198], D_Real_Loss[0.390], D_Fake_Loss[0.285]
Progress[ 36%], ETA[ 126m], Batch [8790], G_Loss[0.176], D_Real_Loss[1.063], D_Fake_Loss[0.323]
Progress[ 36%], ETA[ 126m], Batch [8800], G_Loss[0.181], D_Real_Loss[0.544], D_Fake_Loss[0.355]
    Saved train/batch008800_out.png
Progress[ 36%], ETA[ 126m], Batch [8810], G_Loss[0.315], D_Real_Loss[0.991], D_Fake_Loss[0.082]
Progress[ 36%], ETA[ 126m], Batch [8820], G_Loss[0.109], D_Real_Loss[0.316], D_Fake_Loss[0.721]
Progress[ 37%], ETA[ 125m], Batch [8830], G_Loss[0.218], D_Real_Loss[0.331], D_Fake_Loss[0.198]
Progress[ 37%], ETA[ 125m], Batch [8840], G_Loss[0.138], D_Real_Loss[0.097], D_Fake_Loss[0.556]
Progress[ 37%], ETA[ 125m], Batch [8850], G_Loss[0.121], D_Real_Loss[0.333], D_Fake_Loss[0.650]
Progress[ 37%], ETA[ 125m], Batch [8860], G_Loss[0.217], D_Real_Loss[0.968], D_Fake_Loss[0.214]
Progress[ 37%], ETA[ 125m], Batch [8870], G_Loss[0.139], D_Real_Loss[0.141], D_Fake_Loss[0.531]
Progress[ 37%], ETA[ 125m], Batch [8880], G_Loss[0.177], D_Real_Loss[0.503], D_Fake_Loss[0.332]
Progress[ 37%], ETA[ 125m], Batch [8890], G_Loss[0.108], D_Real_Loss[0.239], D_Fake_Loss[0.720]
Progress[ 37%], ETA[ 125m], Batch [8900], G_Loss[0.126], D_Real_Loss[0.191], D_Fake_Loss[0.615]
Progress[ 37%], ETA[ 125m], Batch [8910], G_Loss[0.220], D_Real_Loss[0.582], D_Fake_Loss[0.215]
Progress[ 37%], ETA[ 125m], Batch [8920], G_Loss[0.057], D_Real_Loss[0.164], D_Fake_Loss[1.870]
Progress[ 37%], ETA[ 125m], Batch [8930], G_Loss[0.203], D_Real_Loss[0.770], D_Fake_Loss[0.232]
Progress[ 37%], ETA[ 125m], Batch [8940], G_Loss[0.190], D_Real_Loss[0.935], D_Fake_Loss[0.311]
Progress[ 37%], ETA[ 124m], Batch [8950], G_Loss[0.154], D_Real_Loss[0.191], D_Fake_Loss[0.416]
Progress[ 37%], ETA[ 124m], Batch [8960], G_Loss[0.163], D_Real_Loss[0.211], D_Fake_Loss[0.368]
Progress[ 37%], ETA[ 124m], Batch [8970], G_Loss[0.390], D_Real_Loss[0.576], D_Fake_Loss[0.033]
Progress[ 37%], ETA[ 124m], Batch [8980], G_Loss[0.100], D_Real_Loss[0.336], D_Fake_Loss[0.967]
Progress[ 37%], ETA[ 124m], Batch [8990], G_Loss[0.296], D_Real_Loss[0.536], D_Fake_Loss[0.095]
Progress[ 37%], ETA[ 124m], Batch [9000], G_Loss[0.180], D_Real_Loss[0.505], D_Fake_Loss[0.324]
    Saved train/batch009000_out.png
Progress[ 37%], ETA[ 124m], Batch [9010], G_Loss[0.146], D_Real_Loss[0.485], D_Fake_Loss[0.502]
Progress[ 37%], ETA[ 124m], Batch [9020], G_Loss[0.144], D_Real_Loss[0.168], D_Fake_Loss[0.469]
Progress[ 37%], ETA[ 124m], Batch [9030], G_Loss[0.144], D_Real_Loss[0.213], D_Fake_Loss[0.545]
Progress[ 37%], ETA[ 124m], Batch [9040], G_Loss[0.158], D_Real_Loss[0.753], D_Fake_Loss[0.429]
Progress[ 37%], ETA[ 124m], Batch [9050], G_Loss[0.276], D_Real_Loss[0.459], D_Fake_Loss[0.109]
Progress[ 37%], ETA[ 124m], Batch [9060], G_Loss[0.268], D_Real_Loss[0.688], D_Fake_Loss[0.127]
Progress[ 38%], ETA[ 123m], Batch [9070], G_Loss[0.172], D_Real_Loss[0.651], D_Fake_Loss[0.384]
Progress[ 38%], ETA[ 123m], Batch [9080], G_Loss[0.264], D_Real_Loss[0.450], D_Fake_Loss[0.135]
Progress[ 38%], ETA[ 123m], Batch [9090], G_Loss[0.157], D_Real_Loss[0.086], D_Fake_Loss[0.665]
Progress[ 38%], ETA[ 123m], Batch [9100], G_Loss[0.088], D_Real_Loss[0.103], D_Fake_Loss[1.271]
Progress[ 38%], ETA[ 123m], Batch [9110], G_Loss[0.124], D_Real_Loss[0.158], D_Fake_Loss[0.605]
Progress[ 38%], ETA[ 123m], Batch [9120], G_Loss[0.292], D_Real_Loss[1.321], D_Fake_Loss[0.091]
Progress[ 38%], ETA[ 123m], Batch [9130], G_Loss[0.143], D_Real_Loss[0.221], D_Fake_Loss[0.540]
Progress[ 38%], ETA[ 123m], Batch [9140], G_Loss[0.203], D_Real_Loss[0.443], D_Fake_Loss[0.255]
Progress[ 38%], ETA[ 123m], Batch [9150], G_Loss[0.154], D_Real_Loss[0.273], D_Fake_Loss[0.437]
Progress[ 38%], ETA[ 123m], Batch [9160], G_Loss[0.210], D_Real_Loss[0.649], D_Fake_Loss[0.229]
Progress[ 38%], ETA[ 123m], Batch [9170], G_Loss[0.151], D_Real_Loss[0.114], D_Fake_Loss[0.496]
Progress[ 38%], ETA[ 123m], Batch [9180], G_Loss[0.192], D_Real_Loss[0.190], D_Fake_Loss[0.284]
Progress[ 38%], ETA[ 122m], Batch [9190], G_Loss[0.173], D_Real_Loss[0.333], D_Fake_Loss[0.430]
Progress[ 38%], ETA[ 122m], Batch [9200], G_Loss[0.132], D_Real_Loss[0.381], D_Fake_Loss[0.726]
    Saved train/batch009200_out.png
Progress[ 38%], ETA[ 122m], Batch [9210], G_Loss[0.140], D_Real_Loss[0.443], D_Fake_Loss[0.522]
Progress[ 38%], ETA[ 122m], Batch [9220], G_Loss[0.299], D_Real_Loss[1.515], D_Fake_Loss[0.091]
Progress[ 38%], ETA[ 122m], Batch [9230], G_Loss[0.176], D_Real_Loss[0.276], D_Fake_Loss[0.315]
Progress[ 38%], ETA[ 122m], Batch [9240], G_Loss[0.176], D_Real_Loss[0.217], D_Fake_Loss[0.344]
Progress[ 38%], ETA[ 122m], Batch [9250], G_Loss[0.122], D_Real_Loss[0.153], D_Fake_Loss[0.711]
Progress[ 38%], ETA[ 122m], Batch [9260], G_Loss[0.134], D_Real_Loss[0.177], D_Fake_Loss[0.529]
Progress[ 38%], ETA[ 122m], Batch [9270], G_Loss[0.166], D_Real_Loss[0.404], D_Fake_Loss[0.366]
Progress[ 38%], ETA[ 122m], Batch [9280], G_Loss[0.113], D_Real_Loss[0.301], D_Fake_Loss[0.710]
Progress[ 38%], ETA[ 122m], Batch [9290], G_Loss[0.121], D_Real_Loss[0.115], D_Fake_Loss[0.670]
Progress[ 39%], ETA[ 122m], Batch [9300], G_Loss[0.274], D_Real_Loss[0.370], D_Fake_Loss[0.128]
Progress[ 39%], ETA[ 121m], Batch [9310], G_Loss[0.174], D_Real_Loss[0.268], D_Fake_Loss[0.313]
Progress[ 39%], ETA[ 121m], Batch [9320], G_Loss[0.124], D_Real_Loss[0.160], D_Fake_Loss[0.625]
Progress[ 39%], ETA[ 121m], Batch [9330], G_Loss[0.161], D_Real_Loss[0.241], D_Fake_Loss[0.383]
Progress[ 39%], ETA[ 121m], Batch [9340], G_Loss[0.117], D_Real_Loss[0.599], D_Fake_Loss[0.632]
Progress[ 39%], ETA[ 121m], Batch [9350], G_Loss[0.234], D_Real_Loss[0.273], D_Fake_Loss[0.209]
Progress[ 39%], ETA[ 121m], Batch [9360], G_Loss[0.159], D_Real_Loss[0.282], D_Fake_Loss[0.378]
Progress[ 39%], ETA[ 121m], Batch [9370], G_Loss[0.184], D_Real_Loss[0.274], D_Fake_Loss[0.314]
Progress[ 39%], ETA[ 121m], Batch [9380], G_Loss[0.183], D_Real_Loss[0.423], D_Fake_Loss[0.284]
Progress[ 39%], ETA[ 121m], Batch [9390], G_Loss[0.136], D_Real_Loss[0.895], D_Fake_Loss[0.513]
Progress[ 39%], ETA[ 121m], Batch [9400], G_Loss[0.205], D_Real_Loss[0.496], D_Fake_Loss[0.218]
    Saved train/batch009400_out.png
Progress[ 39%], ETA[ 121m], Batch [9410], G_Loss[0.204], D_Real_Loss[0.712], D_Fake_Loss[0.231]
Progress[ 39%], ETA[ 120m], Batch [9420], G_Loss[0.255], D_Real_Loss[0.814], D_Fake_Loss[0.145]
Progress[ 39%], ETA[ 120m], Batch [9430], G_Loss[0.157], D_Real_Loss[0.325], D_Fake_Loss[0.409]
Progress[ 39%], ETA[ 120m], Batch [9440], G_Loss[0.158], D_Real_Loss[0.342], D_Fake_Loss[0.463]
Progress[ 39%], ETA[ 120m], Batch [9450], G_Loss[0.103], D_Real_Loss[0.217], D_Fake_Loss[0.833]
Progress[ 39%], ETA[ 120m], Batch [9460], G_Loss[0.155], D_Real_Loss[0.375], D_Fake_Loss[0.425]
Progress[ 39%], ETA[ 120m], Batch [9470], G_Loss[0.139], D_Real_Loss[0.644], D_Fake_Loss[0.536]
Progress[ 39%], ETA[ 120m], Batch [9480], G_Loss[0.095], D_Real_Loss[0.402], D_Fake_Loss[1.007]
Progress[ 39%], ETA[ 120m], Batch [9490], G_Loss[0.188], D_Real_Loss[0.087], D_Fake_Loss[0.318]
Progress[ 39%], ETA[ 120m], Batch [9500], G_Loss[0.268], D_Real_Loss[1.029], D_Fake_Loss[0.126]
Progress[ 39%], ETA[ 120m], Batch [9510], G_Loss[0.074], D_Real_Loss[0.158], D_Fake_Loss[1.303]
Progress[ 39%], ETA[ 120m], Batch [9520], G_Loss[0.174], D_Real_Loss[0.284], D_Fake_Loss[0.365]
Progress[ 39%], ETA[ 120m], Batch [9530], G_Loss[0.127], D_Real_Loss[0.107], D_Fake_Loss[0.587]
Progress[ 40%], ETA[ 119m], Batch [9540], G_Loss[0.157], D_Real_Loss[0.083], D_Fake_Loss[0.459]
Progress[ 40%], ETA[ 119m], Batch [9550], G_Loss[0.209], D_Real_Loss[0.221], D_Fake_Loss[0.244]
Progress[ 40%], ETA[ 119m], Batch [9560], G_Loss[0.272], D_Real_Loss[0.559], D_Fake_Loss[0.115]
Progress[ 40%], ETA[ 119m], Batch [9570], G_Loss[0.221], D_Real_Loss[0.310], D_Fake_Loss[0.244]
Progress[ 40%], ETA[ 119m], Batch [9580], G_Loss[0.178], D_Real_Loss[1.194], D_Fake_Loss[0.381]
Progress[ 40%], ETA[ 119m], Batch [9590], G_Loss[0.245], D_Real_Loss[0.396], D_Fake_Loss[0.236]
Progress[ 40%], ETA[ 119m], Batch [9600], G_Loss[0.106], D_Real_Loss[0.400], D_Fake_Loss[1.018]
    Saved train/batch009600_out.png
Progress[ 40%], ETA[ 119m], Batch [9610], G_Loss[0.294], D_Real_Loss[1.004], D_Fake_Loss[0.112]
Progress[ 40%], ETA[ 119m], Batch [9620], G_Loss[0.111], D_Real_Loss[0.191], D_Fake_Loss[0.879]
Progress[ 40%], ETA[ 119m], Batch [9630], G_Loss[0.140], D_Real_Loss[0.500], D_Fake_Loss[0.590]
Progress[ 40%], ETA[ 119m], Batch [9640], G_Loss[0.154], D_Real_Loss[0.102], D_Fake_Loss[0.476]
Progress[ 40%], ETA[ 119m], Batch [9650], G_Loss[0.243], D_Real_Loss[1.256], D_Fake_Loss[0.179]
Progress[ 40%], ETA[ 118m], Batch [9660], G_Loss[0.211], D_Real_Loss[0.846], D_Fake_Loss[0.261]
Progress[ 40%], ETA[ 118m], Batch [9670], G_Loss[0.179], D_Real_Loss[0.573], D_Fake_Loss[0.387]
Progress[ 40%], ETA[ 118m], Batch [9680], G_Loss[0.242], D_Real_Loss[0.503], D_Fake_Loss[0.195]
Progress[ 40%], ETA[ 118m], Batch [9690], G_Loss[0.103], D_Real_Loss[0.369], D_Fake_Loss[0.937]
Progress[ 40%], ETA[ 118m], Batch [9700], G_Loss[0.165], D_Real_Loss[0.452], D_Fake_Loss[0.416]
Progress[ 40%], ETA[ 118m], Batch [9710], G_Loss[0.107], D_Real_Loss[0.167], D_Fake_Loss[0.897]
Progress[ 40%], ETA[ 118m], Batch [9720], G_Loss[0.146], D_Real_Loss[0.380], D_Fake_Loss[0.513]
Progress[ 40%], ETA[ 118m], Batch [9730], G_Loss[0.189], D_Real_Loss[0.795], D_Fake_Loss[0.296]
Progress[ 40%], ETA[ 118m], Batch [9740], G_Loss[0.119], D_Real_Loss[0.194], D_Fake_Loss[0.644]
Progress[ 40%], ETA[ 118m], Batch [9750], G_Loss[0.174], D_Real_Loss[0.362], D_Fake_Loss[0.352]
Progress[ 40%], ETA[ 118m], Batch [9760], G_Loss[0.075], D_Real_Loss[0.159], D_Fake_Loss[1.361]
Progress[ 40%], ETA[ 118m], Batch [9770], G_Loss[0.141], D_Real_Loss[0.256], D_Fake_Loss[0.540]
Progress[ 41%], ETA[ 117m], Batch [9780], G_Loss[0.166], D_Real_Loss[0.201], D_Fake_Loss[0.408]
Progress[ 41%], ETA[ 117m], Batch [9790], G_Loss[0.245], D_Real_Loss[0.650], D_Fake_Loss[0.161]
Progress[ 41%], ETA[ 117m], Batch [9800], G_Loss[0.194], D_Real_Loss[0.725], D_Fake_Loss[0.264]
    Saved train/batch009800_out.png
Progress[ 41%], ETA[ 117m], Batch [9810], G_Loss[0.089], D_Real_Loss[0.235], D_Fake_Loss[1.117]
Progress[ 41%], ETA[ 117m], Batch [9820], G_Loss[0.239], D_Real_Loss[0.846], D_Fake_Loss[0.173]
Progress[ 41%], ETA[ 117m], Batch [9830], G_Loss[0.227], D_Real_Loss[0.569], D_Fake_Loss[0.211]
Progress[ 41%], ETA[ 117m], Batch [9840], G_Loss[0.184], D_Real_Loss[0.211], D_Fake_Loss[0.337]
Progress[ 41%], ETA[ 117m], Batch [9850], G_Loss[0.230], D_Real_Loss[0.727], D_Fake_Loss[0.194]
Progress[ 41%], ETA[ 117m], Batch [9860], G_Loss[0.119], D_Real_Loss[0.209], D_Fake_Loss[0.748]
Progress[ 41%], ETA[ 117m], Batch [9870], G_Loss[0.079], D_Real_Loss[0.090], D_Fake_Loss[1.558]
Progress[ 41%], ETA[ 117m], Batch [9880], G_Loss[0.157], D_Real_Loss[0.630], D_Fake_Loss[0.452]
Progress[ 41%], ETA[ 117m], Batch [9890], G_Loss[0.132], D_Real_Loss[0.352], D_Fake_Loss[0.590]
Progress[ 41%], ETA[ 116m], Batch [9900], G_Loss[0.187], D_Real_Loss[0.612], D_Fake_Loss[0.323]
Progress[ 41%], ETA[ 116m], Batch [9910], G_Loss[0.154], D_Real_Loss[1.348], D_Fake_Loss[0.485]
Progress[ 41%], ETA[ 116m], Batch [9920], G_Loss[0.119], D_Real_Loss[0.310], D_Fake_Loss[0.729]
Progress[ 41%], ETA[ 116m], Batch [9930], G_Loss[0.195], D_Real_Loss[0.964], D_Fake_Loss[0.291]
Progress[ 41%], ETA[ 116m], Batch [9940], G_Loss[0.119], D_Real_Loss[0.153], D_Fake_Loss[0.729]
Progress[ 41%], ETA[ 116m], Batch [9950], G_Loss[0.178], D_Real_Loss[0.262], D_Fake_Loss[0.320]
Progress[ 41%], ETA[ 116m], Batch [9960], G_Loss[0.116], D_Real_Loss[0.339], D_Fake_Loss[0.755]
Progress[ 41%], ETA[ 116m], Batch [9970], G_Loss[0.163], D_Real_Loss[0.531], D_Fake_Loss[0.386]
Progress[ 41%], ETA[ 116m], Batch [9980], G_Loss[0.158], D_Real_Loss[0.216], D_Fake_Loss[0.432]
Progress[ 41%], ETA[ 116m], Batch [9990], G_Loss[0.134], D_Real_Loss[0.205], D_Fake_Loss[0.620]
Progress[ 41%], ETA[ 116m], Batch [10000], G_Loss[0.143], D_Real_Loss[0.579], D_Fake_Loss[0.458]
    Saved train/batch010000_out.png
    Checkpoint saved
Progress[ 42%], ETA[ 115m], Batch [10010], G_Loss[0.233], D_Real_Loss[0.254], D_Fake_Loss[0.168]
Progress[ 42%], ETA[ 115m], Batch [10020], G_Loss[0.203], D_Real_Loss[0.268], D_Fake_Loss[0.257]
Progress[ 42%], ETA[ 115m], Batch [10030], G_Loss[0.236], D_Real_Loss[1.351], D_Fake_Loss[0.193]
Progress[ 42%], ETA[ 115m], Batch [10040], G_Loss[0.148], D_Real_Loss[0.194], D_Fake_Loss[0.476]
Progress[ 42%], ETA[ 115m], Batch [10050], G_Loss[0.183], D_Real_Loss[0.447], D_Fake_Loss[0.328]
Progress[ 42%], ETA[ 115m], Batch [10060], G_Loss[0.128], D_Real_Loss[0.602], D_Fake_Loss[0.545]
Progress[ 42%], ETA[ 115m], Batch [10070], G_Loss[0.129], D_Real_Loss[0.364], D_Fake_Loss[0.568]
Progress[ 42%], ETA[ 115m], Batch [10080], G_Loss[0.209], D_Real_Loss[1.050], D_Fake_Loss[0.269]
Progress[ 42%], ETA[ 115m], Batch [10090], G_Loss[0.122], D_Real_Loss[0.244], D_Fake_Loss[0.602]
Progress[ 42%], ETA[ 115m], Batch [10100], G_Loss[0.193], D_Real_Loss[0.587], D_Fake_Loss[0.284]
Progress[ 42%], ETA[ 115m], Batch [10110], G_Loss[0.092], D_Real_Loss[0.237], D_Fake_Loss[1.032]
Progress[ 42%], ETA[ 115m], Batch [10120], G_Loss[0.218], D_Real_Loss[1.096], D_Fake_Loss[0.205]
Progress[ 42%], ETA[ 114m], Batch [10130], G_Loss[0.152], D_Real_Loss[0.402], D_Fake_Loss[0.433]
Progress[ 42%], ETA[ 114m], Batch [10140], G_Loss[0.180], D_Real_Loss[0.571], D_Fake_Loss[0.312]
Progress[ 42%], ETA[ 114m], Batch [10150], G_Loss[0.085], D_Real_Loss[0.298], D_Fake_Loss[1.140]
Progress[ 42%], ETA[ 114m], Batch [10160], G_Loss[0.221], D_Real_Loss[0.576], D_Fake_Loss[0.201]
Progress[ 42%], ETA[ 114m], Batch [10170], G_Loss[0.110], D_Real_Loss[0.113], D_Fake_Loss[0.748]
Progress[ 42%], ETA[ 114m], Batch [10180], G_Loss[0.244], D_Real_Loss[0.388], D_Fake_Loss[0.177]
Progress[ 42%], ETA[ 114m], Batch [10190], G_Loss[0.105], D_Real_Loss[0.338], D_Fake_Loss[0.914]
Progress[ 42%], ETA[ 114m], Batch [10200], G_Loss[0.141], D_Real_Loss[0.375], D_Fake_Loss[0.475]
    Saved train/batch010200_out.png
Progress[ 42%], ETA[ 114m], Batch [10210], G_Loss[0.210], D_Real_Loss[0.763], D_Fake_Loss[0.211]
Progress[ 42%], ETA[ 114m], Batch [10220], G_Loss[0.275], D_Real_Loss[0.908], D_Fake_Loss[0.108]
Progress[ 42%], ETA[ 114m], Batch [10230], G_Loss[0.164], D_Real_Loss[0.257], D_Fake_Loss[0.382]
Progress[ 43%], ETA[ 114m], Batch [10240], G_Loss[0.119], D_Real_Loss[0.313], D_Fake_Loss[0.629]
Progress[ 43%], ETA[ 113m], Batch [10250], G_Loss[0.161], D_Real_Loss[0.929], D_Fake_Loss[0.380]
Progress[ 43%], ETA[ 113m], Batch [10260], G_Loss[0.273], D_Real_Loss[0.596], D_Fake_Loss[0.114]
Progress[ 43%], ETA[ 113m], Batch [10270], G_Loss[0.183], D_Real_Loss[0.312], D_Fake_Loss[0.297]
Progress[ 43%], ETA[ 113m], Batch [10280], G_Loss[0.164], D_Real_Loss[0.628], D_Fake_Loss[0.423]
Progress[ 43%], ETA[ 113m], Batch [10290], G_Loss[0.102], D_Real_Loss[0.168], D_Fake_Loss[0.776]
Progress[ 43%], ETA[ 113m], Batch [10300], G_Loss[0.144], D_Real_Loss[0.179], D_Fake_Loss[0.447]
Progress[ 43%], ETA[ 113m], Batch [10310], G_Loss[0.168], D_Real_Loss[0.304], D_Fake_Loss[0.337]
Progress[ 43%], ETA[ 113m], Batch [10320], G_Loss[0.113], D_Real_Loss[0.734], D_Fake_Loss[0.625]
Progress[ 43%], ETA[ 113m], Batch [10330], G_Loss[0.162], D_Real_Loss[0.481], D_Fake_Loss[0.423]
Progress[ 43%], ETA[ 113m], Batch [10340], G_Loss[0.133], D_Real_Loss[0.373], D_Fake_Loss[0.554]
Progress[ 43%], ETA[ 113m], Batch [10350], G_Loss[0.131], D_Real_Loss[0.720], D_Fake_Loss[0.541]
Progress[ 43%], ETA[ 112m], Batch [10360], G_Loss[0.118], D_Real_Loss[0.410], D_Fake_Loss[0.629]
Progress[ 43%], ETA[ 112m], Batch [10370], G_Loss[0.237], D_Real_Loss[1.692], D_Fake_Loss[0.186]
Progress[ 43%], ETA[ 112m], Batch [10380], G_Loss[0.237], D_Real_Loss[0.429], D_Fake_Loss[0.181]
Progress[ 43%], ETA[ 112m], Batch [10390], G_Loss[0.149], D_Real_Loss[0.285], D_Fake_Loss[0.591]
Progress[ 43%], ETA[ 112m], Batch [10400], G_Loss[0.170], D_Real_Loss[0.642], D_Fake_Loss[0.365]
    Saved train/batch010400_out.png
Progress[ 43%], ETA[ 112m], Batch [10410], G_Loss[0.181], D_Real_Loss[0.212], D_Fake_Loss[0.276]
Progress[ 43%], ETA[ 112m], Batch [10420], G_Loss[0.119], D_Real_Loss[0.326], D_Fake_Loss[0.611]
Progress[ 43%], ETA[ 112m], Batch [10430], G_Loss[0.178], D_Real_Loss[0.158], D_Fake_Loss[0.295]
Progress[ 43%], ETA[ 112m], Batch [10440], G_Loss[0.202], D_Real_Loss[0.736], D_Fake_Loss[0.258]
Progress[ 43%], ETA[ 112m], Batch [10450], G_Loss[0.223], D_Real_Loss[1.162], D_Fake_Loss[0.222]
Progress[ 43%], ETA[ 112m], Batch [10460], G_Loss[0.170], D_Real_Loss[0.643], D_Fake_Loss[0.360]
Progress[ 43%], ETA[ 112m], Batch [10470], G_Loss[0.177], D_Real_Loss[0.562], D_Fake_Loss[0.294]
Progress[ 44%], ETA[ 111m], Batch [10480], G_Loss[0.175], D_Real_Loss[0.538], D_Fake_Loss[0.298]
Progress[ 44%], ETA[ 111m], Batch [10490], G_Loss[0.192], D_Real_Loss[0.595], D_Fake_Loss[0.254]
Progress[ 44%], ETA[ 111m], Batch [10500], G_Loss[0.171], D_Real_Loss[0.197], D_Fake_Loss[0.332]
Progress[ 44%], ETA[ 111m], Batch [10510], G_Loss[0.266], D_Real_Loss[0.580], D_Fake_Loss[0.134]
Progress[ 44%], ETA[ 111m], Batch [10520], G_Loss[0.100], D_Real_Loss[0.158], D_Fake_Loss[0.873]
Progress[ 44%], ETA[ 111m], Batch [10530], G_Loss[0.112], D_Real_Loss[0.453], D_Fake_Loss[0.669]
Progress[ 44%], ETA[ 111m], Batch [10540], G_Loss[0.202], D_Real_Loss[0.262], D_Fake_Loss[0.249]
Progress[ 44%], ETA[ 111m], Batch [10550], G_Loss[0.152], D_Real_Loss[0.276], D_Fake_Loss[0.414]
Progress[ 44%], ETA[ 111m], Batch [10560], G_Loss[0.225], D_Real_Loss[0.324], D_Fake_Loss[0.192]
Progress[ 44%], ETA[ 111m], Batch [10570], G_Loss[0.123], D_Real_Loss[0.213], D_Fake_Loss[0.625]
Progress[ 44%], ETA[ 111m], Batch [10580], G_Loss[0.121], D_Real_Loss[0.244], D_Fake_Loss[0.643]
Progress[ 44%], ETA[ 111m], Batch [10590], G_Loss[0.143], D_Real_Loss[0.529], D_Fake_Loss[0.575]
Progress[ 44%], ETA[ 110m], Batch [10600], G_Loss[0.181], D_Real_Loss[0.199], D_Fake_Loss[0.340]
    Saved train/batch010600_out.png
Progress[ 44%], ETA[ 110m], Batch [10610], G_Loss[0.090], D_Real_Loss[0.170], D_Fake_Loss[0.920]
Progress[ 44%], ETA[ 110m], Batch [10620], G_Loss[0.134], D_Real_Loss[0.141], D_Fake_Loss[0.568]
Progress[ 44%], ETA[ 110m], Batch [10630], G_Loss[0.207], D_Real_Loss[0.513], D_Fake_Loss[0.243]
Progress[ 44%], ETA[ 110m], Batch [10640], G_Loss[0.145], D_Real_Loss[0.226], D_Fake_Loss[0.430]
Progress[ 44%], ETA[ 110m], Batch [10650], G_Loss[0.133], D_Real_Loss[0.199], D_Fake_Loss[0.526]
Progress[ 44%], ETA[ 110m], Batch [10660], G_Loss[0.180], D_Real_Loss[0.427], D_Fake_Loss[0.315]
Progress[ 44%], ETA[ 110m], Batch [10670], G_Loss[0.121], D_Real_Loss[0.181], D_Fake_Loss[0.635]
Progress[ 44%], ETA[ 110m], Batch [10680], G_Loss[0.201], D_Real_Loss[0.556], D_Fake_Loss[0.240]
Progress[ 44%], ETA[ 110m], Batch [10690], G_Loss[0.144], D_Real_Loss[0.672], D_Fake_Loss[0.450]
Progress[ 44%], ETA[ 110m], Batch [10700], G_Loss[0.178], D_Real_Loss[0.172], D_Fake_Loss[0.303]
Progress[ 44%], ETA[ 110m], Batch [10710], G_Loss[0.233], D_Real_Loss[0.891], D_Fake_Loss[0.168]
Progress[ 45%], ETA[ 109m], Batch [10720], G_Loss[0.165], D_Real_Loss[0.277], D_Fake_Loss[0.377]
Progress[ 45%], ETA[ 109m], Batch [10730], G_Loss[0.071], D_Real_Loss[0.125], D_Fake_Loss[1.256]
Progress[ 45%], ETA[ 109m], Batch [10740], G_Loss[0.159], D_Real_Loss[0.750], D_Fake_Loss[0.408]
Progress[ 45%], ETA[ 109m], Batch [10750], G_Loss[0.168], D_Real_Loss[0.302], D_Fake_Loss[0.344]
Progress[ 45%], ETA[ 109m], Batch [10760], G_Loss[0.155], D_Real_Loss[0.306], D_Fake_Loss[0.392]
Progress[ 45%], ETA[ 109m], Batch [10770], G_Loss[0.161], D_Real_Loss[0.142], D_Fake_Loss[0.387]
Progress[ 45%], ETA[ 109m], Batch [10780], G_Loss[0.201], D_Real_Loss[0.586], D_Fake_Loss[0.228]
Progress[ 45%], ETA[ 109m], Batch [10790], G_Loss[0.101], D_Real_Loss[0.151], D_Fake_Loss[0.868]
Progress[ 45%], ETA[ 109m], Batch [10800], G_Loss[0.221], D_Real_Loss[0.653], D_Fake_Loss[0.210]
    Saved train/batch010800_out.png
Progress[ 45%], ETA[ 109m], Batch [10810], G_Loss[0.119], D_Real_Loss[0.145], D_Fake_Loss[0.610]
Progress[ 45%], ETA[ 109m], Batch [10820], G_Loss[0.135], D_Real_Loss[0.234], D_Fake_Loss[0.532]
Progress[ 45%], ETA[ 109m], Batch [10830], G_Loss[0.140], D_Real_Loss[0.181], D_Fake_Loss[0.457]
Progress[ 45%], ETA[ 108m], Batch [10840], G_Loss[0.149], D_Real_Loss[0.789], D_Fake_Loss[0.431]
Progress[ 45%], ETA[ 108m], Batch [10850], G_Loss[0.153], D_Real_Loss[0.249], D_Fake_Loss[0.425]
Progress[ 45%], ETA[ 108m], Batch [10860], G_Loss[0.119], D_Real_Loss[0.241], D_Fake_Loss[0.740]
Progress[ 45%], ETA[ 108m], Batch [10870], G_Loss[0.176], D_Real_Loss[0.652], D_Fake_Loss[0.343]
Progress[ 45%], ETA[ 108m], Batch [10880], G_Loss[0.126], D_Real_Loss[0.433], D_Fake_Loss[0.599]
Progress[ 45%], ETA[ 108m], Batch [10890], G_Loss[0.138], D_Real_Loss[0.314], D_Fake_Loss[0.499]
Progress[ 45%], ETA[ 108m], Batch [10900], G_Loss[0.111], D_Real_Loss[0.385], D_Fake_Loss[0.700]
Progress[ 45%], ETA[ 108m], Batch [10910], G_Loss[0.246], D_Real_Loss[0.959], D_Fake_Loss[0.161]
Progress[ 45%], ETA[ 108m], Batch [10920], G_Loss[0.083], D_Real_Loss[0.512], D_Fake_Loss[1.191]
Progress[ 45%], ETA[ 108m], Batch [10930], G_Loss[0.090], D_Real_Loss[0.257], D_Fake_Loss[0.968]
Progress[ 45%], ETA[ 108m], Batch [10940], G_Loss[0.120], D_Real_Loss[0.310], D_Fake_Loss[0.723]
Progress[ 45%], ETA[ 108m], Batch [10950], G_Loss[0.112], D_Real_Loss[0.247], D_Fake_Loss[0.700]
Progress[ 46%], ETA[ 107m], Batch [10960], G_Loss[0.151], D_Real_Loss[0.265], D_Fake_Loss[0.490]
Progress[ 46%], ETA[ 107m], Batch [10970], G_Loss[0.162], D_Real_Loss[0.556], D_Fake_Loss[0.383]
Progress[ 46%], ETA[ 107m], Batch [10980], G_Loss[0.125], D_Real_Loss[0.243], D_Fake_Loss[0.579]
Progress[ 46%], ETA[ 107m], Batch [10990], G_Loss[0.138], D_Real_Loss[0.320], D_Fake_Loss[0.546]
Progress[ 46%], ETA[ 107m], Batch [11000], G_Loss[0.160], D_Real_Loss[0.610], D_Fake_Loss[0.365]
    Saved train/batch011000_out.png
Progress[ 46%], ETA[ 107m], Batch [11010], G_Loss[0.198], D_Real_Loss[0.538], D_Fake_Loss[0.258]
Progress[ 46%], ETA[ 107m], Batch [11020], G_Loss[0.175], D_Real_Loss[0.143], D_Fake_Loss[0.335]
Progress[ 46%], ETA[ 107m], Batch [11030], G_Loss[0.203], D_Real_Loss[0.282], D_Fake_Loss[0.246]
Progress[ 46%], ETA[ 107m], Batch [11040], G_Loss[0.154], D_Real_Loss[0.179], D_Fake_Loss[0.473]
Progress[ 46%], ETA[ 107m], Batch [11050], G_Loss[0.128], D_Real_Loss[0.480], D_Fake_Loss[0.651]
Progress[ 46%], ETA[ 107m], Batch [11060], G_Loss[0.155], D_Real_Loss[0.155], D_Fake_Loss[0.443]
Progress[ 46%], ETA[ 107m], Batch [11070], G_Loss[0.143], D_Real_Loss[0.538], D_Fake_Loss[0.618]
Progress[ 46%], ETA[ 106m], Batch [11080], G_Loss[0.210], D_Real_Loss[0.719], D_Fake_Loss[0.306]
Progress[ 46%], ETA[ 106m], Batch [11090], G_Loss[0.146], D_Real_Loss[0.512], D_Fake_Loss[0.592]
Progress[ 46%], ETA[ 106m], Batch [11100], G_Loss[0.159], D_Real_Loss[0.561], D_Fake_Loss[0.416]
Progress[ 46%], ETA[ 106m], Batch [11110], G_Loss[0.231], D_Real_Loss[0.522], D_Fake_Loss[0.195]
Progress[ 46%], ETA[ 106m], Batch [11120], G_Loss[0.093], D_Real_Loss[0.238], D_Fake_Loss[1.096]
Progress[ 46%], ETA[ 106m], Batch [11130], G_Loss[0.164], D_Real_Loss[0.192], D_Fake_Loss[0.428]
Progress[ 46%], ETA[ 106m], Batch [11140], G_Loss[0.134], D_Real_Loss[0.650], D_Fake_Loss[0.634]
Progress[ 46%], ETA[ 106m], Batch [11150], G_Loss[0.104], D_Real_Loss[0.259], D_Fake_Loss[0.995]
Progress[ 46%], ETA[ 106m], Batch [11160], G_Loss[0.188], D_Real_Loss[0.410], D_Fake_Loss[0.327]
Progress[ 46%], ETA[ 106m], Batch [11170], G_Loss[0.092], D_Real_Loss[0.101], D_Fake_Loss[1.215]
Progress[ 46%], ETA[ 106m], Batch [11180], G_Loss[0.146], D_Real_Loss[0.786], D_Fake_Loss[0.514]
Progress[ 46%], ETA[ 106m], Batch [11190], G_Loss[0.117], D_Real_Loss[0.230], D_Fake_Loss[0.793]
Progress[ 47%], ETA[ 105m], Batch [11200], G_Loss[0.139], D_Real_Loss[0.349], D_Fake_Loss[0.559]
    Saved train/batch011200_out.png
Progress[ 47%], ETA[ 105m], Batch [11210], G_Loss[0.102], D_Real_Loss[0.184], D_Fake_Loss[1.022]
Progress[ 47%], ETA[ 105m], Batch [11220], G_Loss[0.213], D_Real_Loss[0.274], D_Fake_Loss[0.251]
Progress[ 47%], ETA[ 105m], Batch [11230], G_Loss[0.128], D_Real_Loss[0.398], D_Fake_Loss[0.703]
Progress[ 47%], ETA[ 105m], Batch [11240], G_Loss[0.209], D_Real_Loss[0.469], D_Fake_Loss[0.266]
Progress[ 47%], ETA[ 105m], Batch [11250], G_Loss[0.156], D_Real_Loss[0.408], D_Fake_Loss[0.487]
Progress[ 47%], ETA[ 105m], Batch [11260], G_Loss[0.161], D_Real_Loss[0.375], D_Fake_Loss[0.421]
Progress[ 47%], ETA[ 105m], Batch [11270], G_Loss[0.152], D_Real_Loss[0.626], D_Fake_Loss[0.521]
Progress[ 47%], ETA[ 105m], Batch [11280], G_Loss[0.252], D_Real_Loss[0.379], D_Fake_Loss[0.153]
Progress[ 47%], ETA[ 105m], Batch [11290], G_Loss[0.154], D_Real_Loss[0.290], D_Fake_Loss[0.491]
Progress[ 47%], ETA[ 105m], Batch [11300], G_Loss[0.169], D_Real_Loss[0.200], D_Fake_Loss[0.400]
Progress[ 47%], ETA[ 105m], Batch [11310], G_Loss[0.188], D_Real_Loss[0.710], D_Fake_Loss[0.320]
Progress[ 47%], ETA[ 104m], Batch [11320], G_Loss[0.379], D_Real_Loss[1.300], D_Fake_Loss[0.046]
Progress[ 47%], ETA[ 104m], Batch [11330], G_Loss[0.076], D_Real_Loss[0.253], D_Fake_Loss[1.299]
Progress[ 47%], ETA[ 104m], Batch [11340], G_Loss[0.172], D_Real_Loss[0.697], D_Fake_Loss[0.344]
Progress[ 47%], ETA[ 104m], Batch [11350], G_Loss[0.183], D_Real_Loss[0.387], D_Fake_Loss[0.379]
Progress[ 47%], ETA[ 104m], Batch [11360], G_Loss[0.193], D_Real_Loss[0.318], D_Fake_Loss[0.269]
Progress[ 47%], ETA[ 104m], Batch [11370], G_Loss[0.225], D_Real_Loss[0.811], D_Fake_Loss[0.197]
Progress[ 47%], ETA[ 104m], Batch [11380], G_Loss[0.280], D_Real_Loss[0.778], D_Fake_Loss[0.119]
Progress[ 47%], ETA[ 104m], Batch [11390], G_Loss[0.275], D_Real_Loss[0.433], D_Fake_Loss[0.118]
Progress[ 47%], ETA[ 104m], Batch [11400], G_Loss[0.150], D_Real_Loss[0.181], D_Fake_Loss[0.493]
    Saved train/batch011400_out.png
Progress[ 47%], ETA[ 104m], Batch [11410], G_Loss[0.169], D_Real_Loss[0.806], D_Fake_Loss[0.386]
Progress[ 47%], ETA[ 104m], Batch [11420], G_Loss[0.216], D_Real_Loss[0.432], D_Fake_Loss[0.280]
Progress[ 48%], ETA[ 103m], Batch [11430], G_Loss[0.249], D_Real_Loss[0.350], D_Fake_Loss[0.148]
Progress[ 48%], ETA[ 103m], Batch [11440], G_Loss[0.194], D_Real_Loss[0.539], D_Fake_Loss[0.284]
Progress[ 48%], ETA[ 103m], Batch [11450], G_Loss[0.160], D_Real_Loss[0.304], D_Fake_Loss[0.414]
Progress[ 48%], ETA[ 103m], Batch [11460], G_Loss[0.133], D_Real_Loss[0.389], D_Fake_Loss[0.586]
Progress[ 48%], ETA[ 103m], Batch [11470], G_Loss[0.130], D_Real_Loss[0.442], D_Fake_Loss[0.614]
Progress[ 48%], ETA[ 103m], Batch [11480], G_Loss[0.113], D_Real_Loss[0.154], D_Fake_Loss[0.790]
Progress[ 48%], ETA[ 103m], Batch [11490], G_Loss[0.168], D_Real_Loss[0.164], D_Fake_Loss[0.474]
Progress[ 48%], ETA[ 103m], Batch [11500], G_Loss[0.219], D_Real_Loss[0.386], D_Fake_Loss[0.208]
Progress[ 48%], ETA[ 103m], Batch [11510], G_Loss[0.188], D_Real_Loss[0.426], D_Fake_Loss[0.313]
Progress[ 48%], ETA[ 103m], Batch [11520], G_Loss[0.208], D_Real_Loss[0.208], D_Fake_Loss[0.251]
Progress[ 48%], ETA[ 103m], Batch [11530], G_Loss[0.269], D_Real_Loss[1.111], D_Fake_Loss[0.148]
Progress[ 48%], ETA[ 103m], Batch [11540], G_Loss[0.183], D_Real_Loss[0.757], D_Fake_Loss[0.414]
Progress[ 48%], ETA[ 102m], Batch [11550], G_Loss[0.134], D_Real_Loss[0.635], D_Fake_Loss[0.585]
Progress[ 48%], ETA[ 102m], Batch [11560], G_Loss[0.247], D_Real_Loss[0.941], D_Fake_Loss[0.154]
Progress[ 48%], ETA[ 102m], Batch [11570], G_Loss[0.246], D_Real_Loss[0.996], D_Fake_Loss[0.170]
Progress[ 48%], ETA[ 102m], Batch [11580], G_Loss[0.157], D_Real_Loss[0.336], D_Fake_Loss[0.522]
Progress[ 48%], ETA[ 102m], Batch [11590], G_Loss[0.192], D_Real_Loss[0.775], D_Fake_Loss[0.294]
Progress[ 48%], ETA[ 102m], Batch [11600], G_Loss[0.122], D_Real_Loss[0.282], D_Fake_Loss[0.628]
    Saved train/batch011600_out.png
Progress[ 48%], ETA[ 102m], Batch [11610], G_Loss[0.118], D_Real_Loss[0.146], D_Fake_Loss[0.692]
Progress[ 48%], ETA[ 102m], Batch [11620], G_Loss[0.103], D_Real_Loss[0.200], D_Fake_Loss[0.811]
Progress[ 48%], ETA[ 102m], Batch [11630], G_Loss[0.148], D_Real_Loss[0.731], D_Fake_Loss[0.469]
Progress[ 48%], ETA[ 102m], Batch [11640], G_Loss[0.136], D_Real_Loss[0.323], D_Fake_Loss[0.549]
Progress[ 48%], ETA[ 102m], Batch [11650], G_Loss[0.257], D_Real_Loss[1.538], D_Fake_Loss[0.130]
Progress[ 49%], ETA[ 102m], Batch [11660], G_Loss[0.238], D_Real_Loss[0.196], D_Fake_Loss[0.177]
Progress[ 49%], ETA[ 101m], Batch [11670], G_Loss[0.205], D_Real_Loss[0.429], D_Fake_Loss[0.229]
Progress[ 49%], ETA[ 101m], Batch [11680], G_Loss[0.124], D_Real_Loss[0.165], D_Fake_Loss[0.651]
Progress[ 49%], ETA[ 101m], Batch [11690], G_Loss[0.138], D_Real_Loss[0.463], D_Fake_Loss[0.535]
Progress[ 49%], ETA[ 101m], Batch [11700], G_Loss[0.199], D_Real_Loss[1.137], D_Fake_Loss[0.240]
Progress[ 49%], ETA[ 101m], Batch [11710], G_Loss[0.138], D_Real_Loss[0.313], D_Fake_Loss[0.525]
Progress[ 49%], ETA[ 101m], Batch [11720], G_Loss[0.196], D_Real_Loss[0.596], D_Fake_Loss[0.289]
Progress[ 49%], ETA[ 101m], Batch [11730], G_Loss[0.188], D_Real_Loss[0.373], D_Fake_Loss[0.269]
Progress[ 49%], ETA[ 101m], Batch [11740], G_Loss[0.162], D_Real_Loss[0.394], D_Fake_Loss[0.393]
Progress[ 49%], ETA[ 101m], Batch [11750], G_Loss[0.232], D_Real_Loss[0.425], D_Fake_Loss[0.231]
Progress[ 49%], ETA[ 101m], Batch [11760], G_Loss[0.147], D_Real_Loss[0.304], D_Fake_Loss[0.447]
Progress[ 49%], ETA[ 101m], Batch [11770], G_Loss[0.116], D_Real_Loss[0.560], D_Fake_Loss[0.696]
Progress[ 49%], ETA[ 101m], Batch [11780], G_Loss[0.198], D_Real_Loss[0.239], D_Fake_Loss[0.331]
Progress[ 49%], ETA[ 100m], Batch [11790], G_Loss[0.165], D_Real_Loss[0.508], D_Fake_Loss[0.380]
Progress[ 49%], ETA[ 100m], Batch [11800], G_Loss[0.192], D_Real_Loss[0.219], D_Fake_Loss[0.274]
    Saved train/batch011800_out.png
Progress[ 49%], ETA[ 100m], Batch [11810], G_Loss[0.172], D_Real_Loss[0.614], D_Fake_Loss[0.346]
Progress[ 49%], ETA[ 100m], Batch [11820], G_Loss[0.180], D_Real_Loss[0.407], D_Fake_Loss[0.313]
Progress[ 49%], ETA[ 100m], Batch [11830], G_Loss[0.123], D_Real_Loss[0.201], D_Fake_Loss[0.692]
Progress[ 49%], ETA[ 100m], Batch [11840], G_Loss[0.126], D_Real_Loss[0.370], D_Fake_Loss[0.582]
Progress[ 49%], ETA[ 100m], Batch [11850], G_Loss[0.165], D_Real_Loss[0.854], D_Fake_Loss[0.398]
Progress[ 49%], ETA[ 100m], Batch [11860], G_Loss[0.188], D_Real_Loss[0.491], D_Fake_Loss[0.272]
Progress[ 49%], ETA[ 100m], Batch [11870], G_Loss[0.220], D_Real_Loss[0.523], D_Fake_Loss[0.194]
Progress[ 49%], ETA[ 100m], Batch [11880], G_Loss[0.261], D_Real_Loss[0.519], D_Fake_Loss[0.146]
Progress[ 49%], ETA[ 100m], Batch [11890], G_Loss[0.218], D_Real_Loss[0.144], D_Fake_Loss[0.217]
Progress[ 50%], ETA[  99m], Batch [11900], G_Loss[0.258], D_Real_Loss[1.261], D_Fake_Loss[0.143]
Progress[ 50%], ETA[  99m], Batch [11910], G_Loss[0.077], D_Real_Loss[0.176], D_Fake_Loss[1.633]
Progress[ 50%], ETA[  99m], Batch [11920], G_Loss[0.141], D_Real_Loss[0.270], D_Fake_Loss[0.617]
Progress[ 50%], ETA[  99m], Batch [11930], G_Loss[0.248], D_Real_Loss[0.560], D_Fake_Loss[0.148]
Progress[ 50%], ETA[  99m], Batch [11940], G_Loss[0.136], D_Real_Loss[0.297], D_Fake_Loss[0.529]
Progress[ 50%], ETA[  99m], Batch [11950], G_Loss[0.171], D_Real_Loss[0.632], D_Fake_Loss[0.342]
Progress[ 50%], ETA[  99m], Batch [11960], G_Loss[0.108], D_Real_Loss[0.459], D_Fake_Loss[0.904]
Progress[ 50%], ETA[  99m], Batch [11970], G_Loss[0.219], D_Real_Loss[1.303], D_Fake_Loss[0.235]
Progress[ 50%], ETA[  99m], Batch [11980], G_Loss[0.132], D_Real_Loss[0.590], D_Fake_Loss[0.656]
Progress[ 50%], ETA[  99m], Batch [11990], G_Loss[0.204], D_Real_Loss[0.264], D_Fake_Loss[0.267]
Progress[ 50%], ETA[  99m], Batch [12000], G_Loss[0.162], D_Real_Loss[0.850], D_Fake_Loss[0.381]
    Saved train/batch012000_out.png
Progress[ 50%], ETA[  99m], Batch [12010], G_Loss[0.133], D_Real_Loss[0.326], D_Fake_Loss[0.549]
Progress[ 50%], ETA[  98m], Batch [12020], G_Loss[0.113], D_Real_Loss[0.934], D_Fake_Loss[0.716]
Progress[ 50%], ETA[  98m], Batch [12030], G_Loss[0.151], D_Real_Loss[0.764], D_Fake_Loss[0.521]
Progress[ 50%], ETA[  98m], Batch [12040], G_Loss[0.275], D_Real_Loss[0.817], D_Fake_Loss[0.117]
Progress[ 50%], ETA[  98m], Batch [12050], G_Loss[0.105], D_Real_Loss[0.110], D_Fake_Loss[0.952]
Progress[ 50%], ETA[  98m], Batch [12060], G_Loss[0.119], D_Real_Loss[0.157], D_Fake_Loss[0.710]
Progress[ 50%], ETA[  98m], Batch [12070], G_Loss[0.233], D_Real_Loss[0.711], D_Fake_Loss[0.198]
Progress[ 50%], ETA[  98m], Batch [12080], G_Loss[0.170], D_Real_Loss[0.502], D_Fake_Loss[0.441]
Progress[ 50%], ETA[  98m], Batch [12090], G_Loss[0.191], D_Real_Loss[0.380], D_Fake_Loss[0.318]
Progress[ 50%], ETA[  98m], Batch [12100], G_Loss[0.289], D_Real_Loss[0.684], D_Fake_Loss[0.106]
Progress[ 50%], ETA[  98m], Batch [12110], G_Loss[0.122], D_Real_Loss[0.279], D_Fake_Loss[0.774]
Progress[ 50%], ETA[  98m], Batch [12120], G_Loss[0.157], D_Real_Loss[0.497], D_Fake_Loss[0.482]
Progress[ 51%], ETA[  97m], Batch [12130], G_Loss[0.141], D_Real_Loss[0.712], D_Fake_Loss[0.496]
Progress[ 51%], ETA[  97m], Batch [12140], G_Loss[0.137], D_Real_Loss[0.064], D_Fake_Loss[0.541]
Progress[ 51%], ETA[  97m], Batch [12150], G_Loss[0.220], D_Real_Loss[0.450], D_Fake_Loss[0.206]
Progress[ 51%], ETA[  97m], Batch [12160], G_Loss[0.188], D_Real_Loss[0.243], D_Fake_Loss[0.385]
Progress[ 51%], ETA[  97m], Batch [12170], G_Loss[0.126], D_Real_Loss[0.294], D_Fake_Loss[0.640]
Progress[ 51%], ETA[  97m], Batch [12180], G_Loss[0.158], D_Real_Loss[0.551], D_Fake_Loss[0.391]
Progress[ 51%], ETA[  97m], Batch [12190], G_Loss[0.214], D_Real_Loss[0.274], D_Fake_Loss[0.230]
Progress[ 51%], ETA[  97m], Batch [12200], G_Loss[0.174], D_Real_Loss[0.175], D_Fake_Loss[0.369]
    Saved train/batch012200_out.png
Progress[ 51%], ETA[  97m], Batch [12210], G_Loss[0.075], D_Real_Loss[0.093], D_Fake_Loss[1.455]
Progress[ 51%], ETA[  97m], Batch [12220], G_Loss[0.189], D_Real_Loss[0.366], D_Fake_Loss[0.304]
Progress[ 51%], ETA[  97m], Batch [12230], G_Loss[0.185], D_Real_Loss[0.813], D_Fake_Loss[0.311]
Progress[ 51%], ETA[  97m], Batch [12240], G_Loss[0.136], D_Real_Loss[0.326], D_Fake_Loss[0.517]
Progress[ 51%], ETA[  96m], Batch [12250], G_Loss[0.124], D_Real_Loss[0.233], D_Fake_Loss[0.637]
Progress[ 51%], ETA[  96m], Batch [12260], G_Loss[0.182], D_Real_Loss[1.232], D_Fake_Loss[0.294]
Progress[ 51%], ETA[  96m], Batch [12270], G_Loss[0.194], D_Real_Loss[0.253], D_Fake_Loss[0.276]
Progress[ 51%], ETA[  96m], Batch [12280], G_Loss[0.110], D_Real_Loss[0.461], D_Fake_Loss[0.840]
Progress[ 51%], ETA[  96m], Batch [12290], G_Loss[0.097], D_Real_Loss[0.025], D_Fake_Loss[1.033]
Progress[ 51%], ETA[  96m], Batch [12300], G_Loss[0.286], D_Real_Loss[0.397], D_Fake_Loss[0.102]
Progress[ 51%], ETA[  96m], Batch [12310], G_Loss[0.178], D_Real_Loss[0.456], D_Fake_Loss[0.350]
Progress[ 51%], ETA[  96m], Batch [12320], G_Loss[0.135], D_Real_Loss[0.159], D_Fake_Loss[0.559]
Progress[ 51%], ETA[  96m], Batch [12330], G_Loss[0.104], D_Real_Loss[0.287], D_Fake_Loss[0.991]
Progress[ 51%], ETA[  96m], Batch [12340], G_Loss[0.194], D_Real_Loss[0.171], D_Fake_Loss[0.313]
Progress[ 51%], ETA[  96m], Batch [12350], G_Loss[0.224], D_Real_Loss[0.415], D_Fake_Loss[0.195]
Progress[ 51%], ETA[  96m], Batch [12360], G_Loss[0.237], D_Real_Loss[0.660], D_Fake_Loss[0.177]
Progress[ 52%], ETA[  95m], Batch [12370], G_Loss[0.346], D_Real_Loss[0.553], D_Fake_Loss[0.072]
Progress[ 52%], ETA[  95m], Batch [12380], G_Loss[0.152], D_Real_Loss[0.309], D_Fake_Loss[0.470]
Progress[ 52%], ETA[  95m], Batch [12390], G_Loss[0.145], D_Real_Loss[0.303], D_Fake_Loss[0.482]
Progress[ 52%], ETA[  95m], Batch [12400], G_Loss[0.118], D_Real_Loss[0.041], D_Fake_Loss[0.801]
    Saved train/batch012400_out.png
Progress[ 52%], ETA[  95m], Batch [12410], G_Loss[0.254], D_Real_Loss[0.343], D_Fake_Loss[0.145]
Progress[ 52%], ETA[  95m], Batch [12420], G_Loss[0.123], D_Real_Loss[0.371], D_Fake_Loss[0.673]
Progress[ 52%], ETA[  95m], Batch [12430], G_Loss[0.219], D_Real_Loss[0.805], D_Fake_Loss[0.204]
Progress[ 52%], ETA[  95m], Batch [12440], G_Loss[0.175], D_Real_Loss[0.466], D_Fake_Loss[0.341]
Progress[ 52%], ETA[  95m], Batch [12450], G_Loss[0.147], D_Real_Loss[0.320], D_Fake_Loss[0.441]
Progress[ 52%], ETA[  95m], Batch [12460], G_Loss[0.085], D_Real_Loss[0.273], D_Fake_Loss[1.135]
Progress[ 52%], ETA[  95m], Batch [12470], G_Loss[0.217], D_Real_Loss[1.303], D_Fake_Loss[0.224]
Progress[ 52%], ETA[  94m], Batch [12480], G_Loss[0.272], D_Real_Loss[0.932], D_Fake_Loss[0.114]
Progress[ 52%], ETA[  94m], Batch [12490], G_Loss[0.237], D_Real_Loss[0.368], D_Fake_Loss[0.180]
Progress[ 52%], ETA[  94m], Batch [12500], G_Loss[0.159], D_Real_Loss[0.485], D_Fake_Loss[0.399]
Progress[ 52%], ETA[  94m], Batch [12510], G_Loss[0.129], D_Real_Loss[0.339], D_Fake_Loss[0.608]
Progress[ 52%], ETA[  94m], Batch [12520], G_Loss[0.103], D_Real_Loss[0.301], D_Fake_Loss[0.791]
Progress[ 52%], ETA[  94m], Batch [12530], G_Loss[0.136], D_Real_Loss[0.304], D_Fake_Loss[0.481]
Progress[ 52%], ETA[  94m], Batch [12540], G_Loss[0.097], D_Real_Loss[0.307], D_Fake_Loss[0.817]
Progress[ 52%], ETA[  94m], Batch [12550], G_Loss[0.155], D_Real_Loss[0.538], D_Fake_Loss[0.373]
Progress[ 52%], ETA[  94m], Batch [12560], G_Loss[0.152], D_Real_Loss[0.272], D_Fake_Loss[0.420]
Progress[ 52%], ETA[  94m], Batch [12570], G_Loss[0.111], D_Real_Loss[0.217], D_Fake_Loss[0.691]
Progress[ 52%], ETA[  94m], Batch [12580], G_Loss[0.173], D_Real_Loss[0.316], D_Fake_Loss[0.323]
Progress[ 52%], ETA[  94m], Batch [12590], G_Loss[0.268], D_Real_Loss[0.990], D_Fake_Loss[0.113]
Progress[ 53%], ETA[  93m], Batch [12600], G_Loss[0.080], D_Real_Loss[0.096], D_Fake_Loss[1.196]
    Saved train/batch012600_out.png
Progress[ 53%], ETA[  93m], Batch [12610], G_Loss[0.173], D_Real_Loss[0.328], D_Fake_Loss[0.312]
Progress[ 53%], ETA[  93m], Batch [12620], G_Loss[0.171], D_Real_Loss[0.494], D_Fake_Loss[0.323]
Progress[ 53%], ETA[  93m], Batch [12630], G_Loss[0.198], D_Real_Loss[0.700], D_Fake_Loss[0.245]
Progress[ 53%], ETA[  93m], Batch [12640], G_Loss[0.082], D_Real_Loss[0.066], D_Fake_Loss[1.042]
Progress[ 53%], ETA[  93m], Batch [12650], G_Loss[0.130], D_Real_Loss[0.635], D_Fake_Loss[0.554]
Progress[ 53%], ETA[  93m], Batch [12660], G_Loss[0.122], D_Real_Loss[0.481], D_Fake_Loss[0.651]
Progress[ 53%], ETA[  93m], Batch [12670], G_Loss[0.338], D_Real_Loss[0.821], D_Fake_Loss[0.056]
Progress[ 53%], ETA[  93m], Batch [12680], G_Loss[0.257], D_Real_Loss[0.417], D_Fake_Loss[0.137]
Progress[ 53%], ETA[  93m], Batch [12690], G_Loss[0.186], D_Real_Loss[0.694], D_Fake_Loss[0.286]
Progress[ 53%], ETA[  93m], Batch [12700], G_Loss[0.083], D_Real_Loss[0.349], D_Fake_Loss[1.135]
Progress[ 53%], ETA[  93m], Batch [12710], G_Loss[0.210], D_Real_Loss[0.616], D_Fake_Loss[0.214]
Progress[ 53%], ETA[  93m], Batch [12720], G_Loss[0.172], D_Real_Loss[0.220], D_Fake_Loss[0.356]
Progress[ 53%], ETA[  92m], Batch [12730], G_Loss[0.126], D_Real_Loss[1.045], D_Fake_Loss[0.649]
Progress[ 53%], ETA[  92m], Batch [12740], G_Loss[0.192], D_Real_Loss[0.852], D_Fake_Loss[0.269]
Progress[ 53%], ETA[  92m], Batch [12750], G_Loss[0.183], D_Real_Loss[0.235], D_Fake_Loss[0.311]
Progress[ 53%], ETA[  92m], Batch [12760], G_Loss[0.136], D_Real_Loss[0.455], D_Fake_Loss[0.510]
Progress[ 53%], ETA[  92m], Batch [12770], G_Loss[0.137], D_Real_Loss[0.227], D_Fake_Loss[0.565]
Progress[ 53%], ETA[  92m], Batch [12780], G_Loss[0.259], D_Real_Loss[1.794], D_Fake_Loss[0.145]
Progress[ 53%], ETA[  92m], Batch [12790], G_Loss[0.175], D_Real_Loss[0.193], D_Fake_Loss[0.439]
Progress[ 53%], ETA[  92m], Batch [12800], G_Loss[0.091], D_Real_Loss[0.250], D_Fake_Loss[1.366]
    Saved train/batch012800_out.png
Progress[ 53%], ETA[  92m], Batch [12810], G_Loss[0.210], D_Real_Loss[0.801], D_Fake_Loss[0.254]
Progress[ 53%], ETA[  92m], Batch [12820], G_Loss[0.168], D_Real_Loss[0.270], D_Fake_Loss[0.391]
Progress[ 53%], ETA[  92m], Batch [12830], G_Loss[0.183], D_Real_Loss[0.652], D_Fake_Loss[0.315]
Progress[ 53%], ETA[  92m], Batch [12840], G_Loss[0.166], D_Real_Loss[0.410], D_Fake_Loss[0.411]
Progress[ 53%], ETA[  92m], Batch [12850], G_Loss[0.131], D_Real_Loss[0.458], D_Fake_Loss[0.673]
Progress[ 53%], ETA[  92m], Batch [12860], G_Loss[0.084], D_Real_Loss[0.473], D_Fake_Loss[1.324]
Progress[ 53%], ETA[  92m], Batch [12870], G_Loss[0.134], D_Real_Loss[0.526], D_Fake_Loss[0.563]
Progress[ 54%], ETA[  91m], Batch [12880], G_Loss[0.131], D_Real_Loss[0.557], D_Fake_Loss[0.572]
Progress[ 54%], ETA[  91m], Batch [12890], G_Loss[0.100], D_Real_Loss[0.241], D_Fake_Loss[0.851]
Progress[ 54%], ETA[  91m], Batch [12900], G_Loss[0.135], D_Real_Loss[0.330], D_Fake_Loss[0.608]
Progress[ 54%], ETA[  91m], Batch [12910], G_Loss[0.074], D_Real_Loss[0.328], D_Fake_Loss[1.488]
Progress[ 54%], ETA[  91m], Batch [12920], G_Loss[0.166], D_Real_Loss[0.271], D_Fake_Loss[0.421]
Progress[ 54%], ETA[  91m], Batch [12930], G_Loss[0.141], D_Real_Loss[0.372], D_Fake_Loss[0.537]
Progress[ 54%], ETA[  91m], Batch [12940], G_Loss[0.082], D_Real_Loss[0.476], D_Fake_Loss[1.254]
Progress[ 54%], ETA[  91m], Batch [12950], G_Loss[0.139], D_Real_Loss[0.398], D_Fake_Loss[0.505]
Progress[ 54%], ETA[  91m], Batch [12960], G_Loss[0.157], D_Real_Loss[0.381], D_Fake_Loss[0.462]
Progress[ 54%], ETA[  91m], Batch [12970], G_Loss[0.243], D_Real_Loss[0.622], D_Fake_Loss[0.176]
Progress[ 54%], ETA[  91m], Batch [12980], G_Loss[0.157], D_Real_Loss[0.098], D_Fake_Loss[0.507]
Progress[ 54%], ETA[  91m], Batch [12990], G_Loss[0.171], D_Real_Loss[0.250], D_Fake_Loss[0.379]
Progress[ 54%], ETA[  91m], Batch [13000], G_Loss[0.136], D_Real_Loss[0.942], D_Fake_Loss[0.583]
    Saved train/batch013000_out.png
Progress[ 54%], ETA[  91m], Batch [13010], G_Loss[0.156], D_Real_Loss[0.303], D_Fake_Loss[0.418]
Progress[ 54%], ETA[  91m], Batch [13020], G_Loss[0.193], D_Real_Loss[0.551], D_Fake_Loss[0.316]
Progress[ 54%], ETA[  91m], Batch [13030], G_Loss[0.125], D_Real_Loss[0.368], D_Fake_Loss[0.635]
Progress[ 54%], ETA[  90m], Batch [13040], G_Loss[0.123], D_Real_Loss[0.674], D_Fake_Loss[0.730]
Progress[ 54%], ETA[  90m], Batch [13050], G_Loss[0.210], D_Real_Loss[0.949], D_Fake_Loss[0.230]
Progress[ 54%], ETA[  90m], Batch [13060], G_Loss[0.205], D_Real_Loss[0.749], D_Fake_Loss[0.276]
Progress[ 54%], ETA[  90m], Batch [13070], G_Loss[0.138], D_Real_Loss[0.157], D_Fake_Loss[0.615]
Progress[ 54%], ETA[  90m], Batch [13080], G_Loss[0.107], D_Real_Loss[0.458], D_Fake_Loss[0.930]
Progress[ 54%], ETA[  90m], Batch [13090], G_Loss[0.114], D_Real_Loss[0.174], D_Fake_Loss[0.821]
Progress[ 54%], ETA[  90m], Batch [13100], G_Loss[0.129], D_Real_Loss[0.353], D_Fake_Loss[0.629]
Progress[ 54%], ETA[  90m], Batch [13110], G_Loss[0.170], D_Real_Loss[0.231], D_Fake_Loss[0.400]
Progress[ 54%], ETA[  90m], Batch [13120], G_Loss[0.209], D_Real_Loss[0.518], D_Fake_Loss[0.232]
Progress[ 54%], ETA[  90m], Batch [13130], G_Loss[0.126], D_Real_Loss[0.539], D_Fake_Loss[0.628]
Progress[ 54%], ETA[  90m], Batch [13140], G_Loss[0.222], D_Real_Loss[0.368], D_Fake_Loss[0.199]
Progress[ 54%], ETA[  90m], Batch [13150], G_Loss[0.147], D_Real_Loss[0.315], D_Fake_Loss[0.487]
Progress[ 54%], ETA[  90m], Batch [13160], G_Loss[0.149], D_Real_Loss[0.509], D_Fake_Loss[0.519]
Progress[ 54%], ETA[  90m], Batch [13170], G_Loss[0.147], D_Real_Loss[0.279], D_Fake_Loss[0.505]
Progress[ 54%], ETA[  90m], Batch [13180], G_Loss[0.150], D_Real_Loss[0.436], D_Fake_Loss[0.490]
Progress[ 55%], ETA[  89m], Batch [13190], G_Loss[0.238], D_Real_Loss[0.468], D_Fake_Loss[0.185]
Progress[ 55%], ETA[  89m], Batch [13200], G_Loss[0.192], D_Real_Loss[1.018], D_Fake_Loss[0.311]
    Saved train/batch013200_out.png
Progress[ 55%], ETA[  89m], Batch [13210], G_Loss[0.108], D_Real_Loss[0.278], D_Fake_Loss[0.958]
Progress[ 55%], ETA[  89m], Batch [13220], G_Loss[0.182], D_Real_Loss[0.618], D_Fake_Loss[0.323]
Progress[ 55%], ETA[  89m], Batch [13230], G_Loss[0.137], D_Real_Loss[0.537], D_Fake_Loss[0.768]
Progress[ 55%], ETA[  89m], Batch [13240], G_Loss[0.134], D_Real_Loss[0.165], D_Fake_Loss[0.543]
Progress[ 55%], ETA[  89m], Batch [13250], G_Loss[0.080], D_Real_Loss[0.102], D_Fake_Loss[1.400]
Progress[ 55%], ETA[  89m], Batch [13260], G_Loss[0.182], D_Real_Loss[0.344], D_Fake_Loss[0.322]
Progress[ 55%], ETA[  89m], Batch [13270], G_Loss[0.114], D_Real_Loss[0.410], D_Fake_Loss[0.729]
Progress[ 55%], ETA[  89m], Batch [13280], G_Loss[0.137], D_Real_Loss[0.246], D_Fake_Loss[0.557]
Progress[ 55%], ETA[  89m], Batch [13290], G_Loss[0.156], D_Real_Loss[0.228], D_Fake_Loss[0.412]
Progress[ 55%], ETA[  89m], Batch [13300], G_Loss[0.138], D_Real_Loss[0.708], D_Fake_Loss[0.552]
Progress[ 55%], ETA[  89m], Batch [13310], G_Loss[0.127], D_Real_Loss[0.140], D_Fake_Loss[0.640]
Progress[ 55%], ETA[  89m], Batch [13320], G_Loss[0.149], D_Real_Loss[0.335], D_Fake_Loss[0.476]
Progress[ 55%], ETA[  89m], Batch [13330], G_Loss[0.181], D_Real_Loss[1.100], D_Fake_Loss[0.321]
Progress[ 55%], ETA[  88m], Batch [13340], G_Loss[0.181], D_Real_Loss[0.499], D_Fake_Loss[0.316]
Progress[ 55%], ETA[  88m], Batch [13350], G_Loss[0.232], D_Real_Loss[0.344], D_Fake_Loss[0.178]
Progress[ 55%], ETA[  88m], Batch [13360], G_Loss[0.293], D_Real_Loss[0.545], D_Fake_Loss[0.104]
Progress[ 55%], ETA[  88m], Batch [13370], G_Loss[0.236], D_Real_Loss[0.692], D_Fake_Loss[0.166]
Progress[ 55%], ETA[  88m], Batch [13380], G_Loss[0.160], D_Real_Loss[0.140], D_Fake_Loss[0.406]
Progress[ 55%], ETA[  88m], Batch [13390], G_Loss[0.160], D_Real_Loss[0.207], D_Fake_Loss[0.411]
Progress[ 55%], ETA[  88m], Batch [13400], G_Loss[0.126], D_Real_Loss[0.444], D_Fake_Loss[0.614]
    Saved train/batch013400_out.png
Progress[ 55%], ETA[  88m], Batch [13410], G_Loss[0.193], D_Real_Loss[0.247], D_Fake_Loss[0.258]
Progress[ 55%], ETA[  88m], Batch [13420], G_Loss[0.231], D_Real_Loss[1.083], D_Fake_Loss[0.188]
Progress[ 55%], ETA[  88m], Batch [13430], G_Loss[0.156], D_Real_Loss[0.266], D_Fake_Loss[0.418]
Progress[ 55%], ETA[  88m], Batch [13440], G_Loss[0.192], D_Real_Loss[0.660], D_Fake_Loss[0.290]
Progress[ 55%], ETA[  88m], Batch [13450], G_Loss[0.213], D_Real_Loss[0.269], D_Fake_Loss[0.212]
Progress[ 55%], ETA[  88m], Batch [13460], G_Loss[0.238], D_Real_Loss[0.355], D_Fake_Loss[0.171]
Progress[ 55%], ETA[  88m], Batch [13470], G_Loss[0.167], D_Real_Loss[0.215], D_Fake_Loss[0.370]
Progress[ 55%], ETA[  88m], Batch [13480], G_Loss[0.261], D_Real_Loss[1.369], D_Fake_Loss[0.136]
Progress[ 56%], ETA[  87m], Batch [13490], G_Loss[0.193], D_Real_Loss[0.528], D_Fake_Loss[0.308]
Progress[ 56%], ETA[  87m], Batch [13500], G_Loss[0.117], D_Real_Loss[0.287], D_Fake_Loss[0.684]
Progress[ 56%], ETA[  87m], Batch [13510], G_Loss[0.157], D_Real_Loss[0.678], D_Fake_Loss[0.400]
Progress[ 56%], ETA[  87m], Batch [13520], G_Loss[0.110], D_Real_Loss[0.297], D_Fake_Loss[0.707]
Progress[ 56%], ETA[  87m], Batch [13530], G_Loss[0.295], D_Real_Loss[0.889], D_Fake_Loss[0.088]
Progress[ 56%], ETA[  87m], Batch [13540], G_Loss[0.150], D_Real_Loss[0.314], D_Fake_Loss[0.436]
Progress[ 56%], ETA[  87m], Batch [13550], G_Loss[0.161], D_Real_Loss[0.201], D_Fake_Loss[0.368]
Progress[ 56%], ETA[  87m], Batch [13560], G_Loss[0.158], D_Real_Loss[0.412], D_Fake_Loss[0.497]
Progress[ 56%], ETA[  87m], Batch [13570], G_Loss[0.160], D_Real_Loss[1.035], D_Fake_Loss[0.422]
Progress[ 56%], ETA[  87m], Batch [13580], G_Loss[0.101], D_Real_Loss[0.088], D_Fake_Loss[0.952]
Progress[ 56%], ETA[  87m], Batch [13590], G_Loss[0.209], D_Real_Loss[0.618], D_Fake_Loss[0.240]
Progress[ 56%], ETA[  87m], Batch [13600], G_Loss[0.328], D_Real_Loss[0.769], D_Fake_Loss[0.074]
    Saved train/batch013600_out.png
Progress[ 56%], ETA[  87m], Batch [13610], G_Loss[0.149], D_Real_Loss[0.354], D_Fake_Loss[0.449]
Progress[ 56%], ETA[  87m], Batch [13620], G_Loss[0.217], D_Real_Loss[0.408], D_Fake_Loss[0.227]
Progress[ 56%], ETA[  87m], Batch [13630], G_Loss[0.094], D_Real_Loss[0.184], D_Fake_Loss[0.913]
Progress[ 56%], ETA[  86m], Batch [13640], G_Loss[0.232], D_Real_Loss[0.396], D_Fake_Loss[0.168]
Progress[ 56%], ETA[  86m], Batch [13650], G_Loss[0.272], D_Real_Loss[0.892], D_Fake_Loss[0.127]
Progress[ 56%], ETA[  86m], Batch [13660], G_Loss[0.153], D_Real_Loss[0.383], D_Fake_Loss[0.393]
Progress[ 56%], ETA[  86m], Batch [13670], G_Loss[0.147], D_Real_Loss[0.236], D_Fake_Loss[0.504]
Progress[ 56%], ETA[  86m], Batch [13680], G_Loss[0.236], D_Real_Loss[0.580], D_Fake_Loss[0.174]
Progress[ 56%], ETA[  86m], Batch [13690], G_Loss[0.124], D_Real_Loss[0.195], D_Fake_Loss[0.728]
Progress[ 56%], ETA[  86m], Batch [13700], G_Loss[0.100], D_Real_Loss[0.274], D_Fake_Loss[0.876]
Progress[ 56%], ETA[  86m], Batch [13710], G_Loss[0.172], D_Real_Loss[0.500], D_Fake_Loss[0.354]
Progress[ 56%], ETA[  86m], Batch [13720], G_Loss[0.154], D_Real_Loss[0.111], D_Fake_Loss[0.377]
Progress[ 56%], ETA[  86m], Batch [13730], G_Loss[0.143], D_Real_Loss[0.569], D_Fake_Loss[0.504]
Progress[ 56%], ETA[  86m], Batch [13740], G_Loss[0.122], D_Real_Loss[0.207], D_Fake_Loss[0.665]
Progress[ 56%], ETA[  86m], Batch [13750], G_Loss[0.293], D_Real_Loss[0.285], D_Fake_Loss[0.093]
Progress[ 56%], ETA[  86m], Batch [13760], G_Loss[0.204], D_Real_Loss[0.292], D_Fake_Loss[0.241]
Progress[ 56%], ETA[  86m], Batch [13770], G_Loss[0.185], D_Real_Loss[0.193], D_Fake_Loss[0.344]
Progress[ 56%], ETA[  86m], Batch [13780], G_Loss[0.195], D_Real_Loss[0.302], D_Fake_Loss[0.279]
Progress[ 57%], ETA[  85m], Batch [13790], G_Loss[0.138], D_Real_Loss[0.203], D_Fake_Loss[0.547]
Progress[ 57%], ETA[  85m], Batch [13800], G_Loss[0.215], D_Real_Loss[0.629], D_Fake_Loss[0.220]
    Saved train/batch013800_out.png
Progress[ 57%], ETA[  85m], Batch [13810], G_Loss[0.131], D_Real_Loss[0.520], D_Fake_Loss[0.557]
Progress[ 57%], ETA[  85m], Batch [13820], G_Loss[0.193], D_Real_Loss[0.249], D_Fake_Loss[0.338]
Progress[ 57%], ETA[  85m], Batch [13830], G_Loss[0.158], D_Real_Loss[0.814], D_Fake_Loss[0.431]
Progress[ 57%], ETA[  85m], Batch [13840], G_Loss[0.147], D_Real_Loss[0.608], D_Fake_Loss[0.463]
Progress[ 57%], ETA[  85m], Batch [13850], G_Loss[0.111], D_Real_Loss[0.338], D_Fake_Loss[0.754]
Progress[ 57%], ETA[  85m], Batch [13860], G_Loss[0.214], D_Real_Loss[0.858], D_Fake_Loss[0.223]
Progress[ 57%], ETA[  85m], Batch [13870], G_Loss[0.233], D_Real_Loss[0.485], D_Fake_Loss[0.186]
Progress[ 57%], ETA[  85m], Batch [13880], G_Loss[0.232], D_Real_Loss[0.554], D_Fake_Loss[0.190]
Progress[ 57%], ETA[  85m], Batch [13890], G_Loss[0.167], D_Real_Loss[0.285], D_Fake_Loss[0.352]
Progress[ 57%], ETA[  85m], Batch [13900], G_Loss[0.175], D_Real_Loss[0.392], D_Fake_Loss[0.324]
Progress[ 57%], ETA[  85m], Batch [13910], G_Loss[0.094], D_Real_Loss[0.357], D_Fake_Loss[0.955]
Progress[ 57%], ETA[  85m], Batch [13920], G_Loss[0.140], D_Real_Loss[0.186], D_Fake_Loss[0.546]
Progress[ 57%], ETA[  85m], Batch [13930], G_Loss[0.167], D_Real_Loss[0.532], D_Fake_Loss[0.349]
Progress[ 57%], ETA[  84m], Batch [13940], G_Loss[0.107], D_Real_Loss[0.289], D_Fake_Loss[0.711]
Progress[ 57%], ETA[  84m], Batch [13950], G_Loss[0.133], D_Real_Loss[0.266], D_Fake_Loss[0.543]
Progress[ 57%], ETA[  84m], Batch [13960], G_Loss[0.190], D_Real_Loss[0.500], D_Fake_Loss[0.275]
Progress[ 57%], ETA[  84m], Batch [13970], G_Loss[0.161], D_Real_Loss[0.258], D_Fake_Loss[0.393]
Progress[ 57%], ETA[  84m], Batch [13980], G_Loss[0.236], D_Real_Loss[0.817], D_Fake_Loss[0.169]
Progress[ 57%], ETA[  84m], Batch [13990], G_Loss[0.162], D_Real_Loss[0.596], D_Fake_Loss[0.431]
Progress[ 57%], ETA[  84m], Batch [14000], G_Loss[0.232], D_Real_Loss[0.739], D_Fake_Loss[0.166]
    Saved train/batch014000_out.png
Progress[ 57%], ETA[  84m], Batch [14010], G_Loss[0.250], D_Real_Loss[0.672], D_Fake_Loss[0.147]
Progress[ 57%], ETA[  84m], Batch [14020], G_Loss[0.198], D_Real_Loss[0.303], D_Fake_Loss[0.249]
Progress[ 57%], ETA[  84m], Batch [14030], G_Loss[0.082], D_Real_Loss[0.337], D_Fake_Loss[1.232]
Progress[ 57%], ETA[  84m], Batch [14040], G_Loss[0.118], D_Real_Loss[0.264], D_Fake_Loss[0.677]
Progress[ 57%], ETA[  84m], Batch [14050], G_Loss[0.224], D_Real_Loss[0.318], D_Fake_Loss[0.191]
Progress[ 57%], ETA[  84m], Batch [14060], G_Loss[0.189], D_Real_Loss[0.536], D_Fake_Loss[0.303]
Progress[ 57%], ETA[  84m], Batch [14070], G_Loss[0.157], D_Real_Loss[0.495], D_Fake_Loss[0.405]
Progress[ 57%], ETA[  84m], Batch [14080], G_Loss[0.155], D_Real_Loss[0.820], D_Fake_Loss[0.417]
Progress[ 58%], ETA[  83m], Batch [14090], G_Loss[0.257], D_Real_Loss[0.409], D_Fake_Loss[0.136]
Progress[ 58%], ETA[  83m], Batch [14100], G_Loss[0.189], D_Real_Loss[0.826], D_Fake_Loss[0.291]
Progress[ 58%], ETA[  83m], Batch [14110], G_Loss[0.120], D_Real_Loss[0.366], D_Fake_Loss[0.648]
Progress[ 58%], ETA[  83m], Batch [14120], G_Loss[0.084], D_Real_Loss[0.124], D_Fake_Loss[1.011]
Progress[ 58%], ETA[  83m], Batch [14130], G_Loss[0.117], D_Real_Loss[0.241], D_Fake_Loss[0.669]
Progress[ 58%], ETA[  83m], Batch [14140], G_Loss[0.177], D_Real_Loss[0.330], D_Fake_Loss[0.347]
Progress[ 58%], ETA[  83m], Batch [14150], G_Loss[0.115], D_Real_Loss[0.172], D_Fake_Loss[0.664]
Progress[ 58%], ETA[  83m], Batch [14160], G_Loss[0.328], D_Real_Loss[0.460], D_Fake_Loss[0.061]
Progress[ 58%], ETA[  83m], Batch [14170], G_Loss[0.230], D_Real_Loss[0.503], D_Fake_Loss[0.166]
Progress[ 58%], ETA[  83m], Batch [14180], G_Loss[0.219], D_Real_Loss[0.297], D_Fake_Loss[0.200]
Progress[ 58%], ETA[  83m], Batch [14190], G_Loss[0.141], D_Real_Loss[0.293], D_Fake_Loss[0.483]
Progress[ 58%], ETA[  83m], Batch [14200], G_Loss[0.144], D_Real_Loss[0.229], D_Fake_Loss[0.493]
    Saved train/batch014200_out.png
Progress[ 58%], ETA[  83m], Batch [14210], G_Loss[0.201], D_Real_Loss[0.230], D_Fake_Loss[0.235]
Progress[ 58%], ETA[  83m], Batch [14220], G_Loss[0.181], D_Real_Loss[0.316], D_Fake_Loss[0.294]
Progress[ 58%], ETA[  83m], Batch [14230], G_Loss[0.198], D_Real_Loss[0.216], D_Fake_Loss[0.247]
Progress[ 58%], ETA[  82m], Batch [14240], G_Loss[0.195], D_Real_Loss[0.663], D_Fake_Loss[0.286]
Progress[ 58%], ETA[  82m], Batch [14250], G_Loss[0.242], D_Real_Loss[0.463], D_Fake_Loss[0.155]
Progress[ 58%], ETA[  82m], Batch [14260], G_Loss[0.192], D_Real_Loss[0.963], D_Fake_Loss[0.259]
Progress[ 58%], ETA[  82m], Batch [14270], G_Loss[0.197], D_Real_Loss[0.398], D_Fake_Loss[0.258]
Progress[ 58%], ETA[  82m], Batch [14280], G_Loss[0.286], D_Real_Loss[0.624], D_Fake_Loss[0.095]
Progress[ 58%], ETA[  82m], Batch [14290], G_Loss[0.131], D_Real_Loss[0.092], D_Fake_Loss[0.574]
Progress[ 58%], ETA[  82m], Batch [14300], G_Loss[0.187], D_Real_Loss[0.218], D_Fake_Loss[0.267]
Progress[ 58%], ETA[  82m], Batch [14310], G_Loss[0.144], D_Real_Loss[0.495], D_Fake_Loss[0.466]
Progress[ 58%], ETA[  82m], Batch [14320], G_Loss[0.281], D_Real_Loss[1.484], D_Fake_Loss[0.106]
Progress[ 58%], ETA[  82m], Batch [14330], G_Loss[0.182], D_Real_Loss[0.424], D_Fake_Loss[0.306]
Progress[ 58%], ETA[  82m], Batch [14340], G_Loss[0.216], D_Real_Loss[0.438], D_Fake_Loss[0.225]
Progress[ 58%], ETA[  82m], Batch [14350], G_Loss[0.094], D_Real_Loss[0.295], D_Fake_Loss[0.965]
Progress[ 58%], ETA[  82m], Batch [14360], G_Loss[0.150], D_Real_Loss[0.279], D_Fake_Loss[0.466]
Progress[ 58%], ETA[  82m], Batch [14370], G_Loss[0.161], D_Real_Loss[0.251], D_Fake_Loss[0.438]
Progress[ 58%], ETA[  82m], Batch [14380], G_Loss[0.161], D_Real_Loss[0.483], D_Fake_Loss[0.411]
Progress[ 59%], ETA[  81m], Batch [14390], G_Loss[0.080], D_Real_Loss[0.173], D_Fake_Loss[1.212]
Progress[ 59%], ETA[  81m], Batch [14400], G_Loss[0.064], D_Real_Loss[0.153], D_Fake_Loss[1.772]
    Saved train/batch014400_out.png
Progress[ 59%], ETA[  81m], Batch [14410], G_Loss[0.155], D_Real_Loss[0.213], D_Fake_Loss[0.420]
Progress[ 59%], ETA[  81m], Batch [14420], G_Loss[0.326], D_Real_Loss[0.844], D_Fake_Loss[0.066]
Progress[ 59%], ETA[  81m], Batch [14430], G_Loss[0.166], D_Real_Loss[0.172], D_Fake_Loss[0.364]
Progress[ 59%], ETA[  81m], Batch [14440], G_Loss[0.218], D_Real_Loss[0.715], D_Fake_Loss[0.204]
Progress[ 59%], ETA[  81m], Batch [14450], G_Loss[0.080], D_Real_Loss[0.094], D_Fake_Loss[1.209]
Progress[ 59%], ETA[  81m], Batch [14460], G_Loss[0.108], D_Real_Loss[0.208], D_Fake_Loss[0.820]
Progress[ 59%], ETA[  81m], Batch [14470], G_Loss[0.225], D_Real_Loss[0.482], D_Fake_Loss[0.197]
Progress[ 59%], ETA[  81m], Batch [14480], G_Loss[0.179], D_Real_Loss[0.840], D_Fake_Loss[0.332]
Progress[ 59%], ETA[  81m], Batch [14490], G_Loss[0.190], D_Real_Loss[0.399], D_Fake_Loss[0.343]
Progress[ 59%], ETA[  81m], Batch [14500], G_Loss[0.158], D_Real_Loss[0.265], D_Fake_Loss[0.448]
Progress[ 59%], ETA[  81m], Batch [14510], G_Loss[0.133], D_Real_Loss[0.529], D_Fake_Loss[0.525]
Progress[ 59%], ETA[  81m], Batch [14520], G_Loss[0.143], D_Real_Loss[0.808], D_Fake_Loss[0.455]
Progress[ 59%], ETA[  81m], Batch [14530], G_Loss[0.142], D_Real_Loss[0.397], D_Fake_Loss[0.497]
Progress[ 59%], ETA[  80m], Batch [14540], G_Loss[0.230], D_Real_Loss[0.360], D_Fake_Loss[0.176]
Progress[ 59%], ETA[  80m], Batch [14550], G_Loss[0.155], D_Real_Loss[0.974], D_Fake_Loss[0.414]
Progress[ 59%], ETA[  80m], Batch [14560], G_Loss[0.138], D_Real_Loss[0.229], D_Fake_Loss[0.529]
Progress[ 59%], ETA[  80m], Batch [14570], G_Loss[0.152], D_Real_Loss[0.144], D_Fake_Loss[0.420]
Progress[ 59%], ETA[  80m], Batch [14580], G_Loss[0.156], D_Real_Loss[0.555], D_Fake_Loss[0.413]
Progress[ 59%], ETA[  80m], Batch [14590], G_Loss[0.111], D_Real_Loss[0.583], D_Fake_Loss[0.647]
Progress[ 59%], ETA[  80m], Batch [14600], G_Loss[0.185], D_Real_Loss[0.447], D_Fake_Loss[0.318]
    Saved train/batch014600_out.png
Progress[ 59%], ETA[  80m], Batch [14610], G_Loss[0.085], D_Real_Loss[0.138], D_Fake_Loss[1.104]
Progress[ 59%], ETA[  80m], Batch [14620], G_Loss[0.159], D_Real_Loss[0.274], D_Fake_Loss[0.444]
Progress[ 59%], ETA[  80m], Batch [14630], G_Loss[0.178], D_Real_Loss[0.522], D_Fake_Loss[0.309]
Progress[ 59%], ETA[  80m], Batch [14640], G_Loss[0.346], D_Real_Loss[1.020], D_Fake_Loss[0.071]
Progress[ 59%], ETA[  80m], Batch [14650], G_Loss[0.326], D_Real_Loss[0.856], D_Fake_Loss[0.069]
Progress[ 59%], ETA[  80m], Batch [14660], G_Loss[0.152], D_Real_Loss[0.192], D_Fake_Loss[0.503]
Progress[ 59%], ETA[  80m], Batch [14670], G_Loss[0.184], D_Real_Loss[0.846], D_Fake_Loss[0.297]
Progress[ 59%], ETA[  80m], Batch [14680], G_Loss[0.153], D_Real_Loss[0.158], D_Fake_Loss[0.422]
Progress[ 60%], ETA[  79m], Batch [14690], G_Loss[0.143], D_Real_Loss[0.323], D_Fake_Loss[0.474]
Progress[ 60%], ETA[  79m], Batch [14700], G_Loss[0.110], D_Real_Loss[0.358], D_Fake_Loss[0.771]
Progress[ 60%], ETA[  79m], Batch [14710], G_Loss[0.113], D_Real_Loss[0.245], D_Fake_Loss[0.738]
Progress[ 60%], ETA[  79m], Batch [14720], G_Loss[0.184], D_Real_Loss[0.132], D_Fake_Loss[0.281]
Progress[ 60%], ETA[  79m], Batch [14730], G_Loss[0.160], D_Real_Loss[0.381], D_Fake_Loss[0.373]
Progress[ 60%], ETA[  79m], Batch [14740], G_Loss[0.160], D_Real_Loss[0.633], D_Fake_Loss[0.379]
Progress[ 60%], ETA[  79m], Batch [14750], G_Loss[0.088], D_Real_Loss[0.373], D_Fake_Loss[1.131]
Progress[ 60%], ETA[  79m], Batch [14760], G_Loss[0.151], D_Real_Loss[0.399], D_Fake_Loss[0.428]
Progress[ 60%], ETA[  79m], Batch [14770], G_Loss[0.222], D_Real_Loss[0.403], D_Fake_Loss[0.181]
Progress[ 60%], ETA[  79m], Batch [14780], G_Loss[0.264], D_Real_Loss[0.299], D_Fake_Loss[0.135]
Progress[ 60%], ETA[  79m], Batch [14790], G_Loss[0.092], D_Real_Loss[0.179], D_Fake_Loss[0.981]
Progress[ 60%], ETA[  79m], Batch [14800], G_Loss[0.269], D_Real_Loss[0.245], D_Fake_Loss[0.129]
    Saved train/batch014800_out.png
Progress[ 60%], ETA[  79m], Batch [14810], G_Loss[0.098], D_Real_Loss[0.132], D_Fake_Loss[0.865]
Progress[ 60%], ETA[  79m], Batch [14820], G_Loss[0.124], D_Real_Loss[0.386], D_Fake_Loss[0.630]
Progress[ 60%], ETA[  79m], Batch [14830], G_Loss[0.110], D_Real_Loss[0.377], D_Fake_Loss[0.716]
Progress[ 60%], ETA[  78m], Batch [14840], G_Loss[0.218], D_Real_Loss[0.470], D_Fake_Loss[0.215]
Progress[ 60%], ETA[  78m], Batch [14850], G_Loss[0.132], D_Real_Loss[0.181], D_Fake_Loss[0.582]
Progress[ 60%], ETA[  78m], Batch [14860], G_Loss[0.171], D_Real_Loss[0.387], D_Fake_Loss[0.372]
Progress[ 60%], ETA[  78m], Batch [14870], G_Loss[0.220], D_Real_Loss[0.450], D_Fake_Loss[0.216]
Progress[ 60%], ETA[  78m], Batch [14880], G_Loss[0.203], D_Real_Loss[0.917], D_Fake_Loss[0.265]
Progress[ 60%], ETA[  78m], Batch [14890], G_Loss[0.131], D_Real_Loss[0.292], D_Fake_Loss[0.674]
Progress[ 60%], ETA[  78m], Batch [14900], G_Loss[0.180], D_Real_Loss[0.182], D_Fake_Loss[0.314]
Progress[ 60%], ETA[  78m], Batch [14910], G_Loss[0.208], D_Real_Loss[0.090], D_Fake_Loss[0.265]
Progress[ 60%], ETA[  78m], Batch [14920], G_Loss[0.169], D_Real_Loss[0.618], D_Fake_Loss[0.377]
Progress[ 60%], ETA[  78m], Batch [14930], G_Loss[0.164], D_Real_Loss[0.116], D_Fake_Loss[0.389]
Progress[ 60%], ETA[  78m], Batch [14940], G_Loss[0.285], D_Real_Loss[1.426], D_Fake_Loss[0.101]
Progress[ 60%], ETA[  78m], Batch [14950], G_Loss[0.298], D_Real_Loss[1.265], D_Fake_Loss[0.088]
Progress[ 60%], ETA[  78m], Batch [14960], G_Loss[0.155], D_Real_Loss[0.743], D_Fake_Loss[0.421]
Progress[ 60%], ETA[  78m], Batch [14970], G_Loss[0.298], D_Real_Loss[1.522], D_Fake_Loss[0.090]
Progress[ 60%], ETA[  78m], Batch [14980], G_Loss[0.147], D_Real_Loss[0.254], D_Fake_Loss[0.575]
Progress[ 61%], ETA[  78m], Batch [14990], G_Loss[0.101], D_Real_Loss[0.163], D_Fake_Loss[0.805]
Progress[ 61%], ETA[  77m], Batch [15000], G_Loss[0.207], D_Real_Loss[0.563], D_Fake_Loss[0.247]
    Saved train/batch015000_out.png
Progress[ 61%], ETA[  77m], Batch [15010], G_Loss[0.109], D_Real_Loss[0.318], D_Fake_Loss[0.786]
Progress[ 61%], ETA[  77m], Batch [15020], G_Loss[0.227], D_Real_Loss[0.404], D_Fake_Loss[0.174]
Progress[ 61%], ETA[  77m], Batch [15030], G_Loss[0.229], D_Real_Loss[0.756], D_Fake_Loss[0.179]
Progress[ 61%], ETA[  77m], Batch [15040], G_Loss[0.122], D_Real_Loss[0.685], D_Fake_Loss[0.657]
Progress[ 61%], ETA[  77m], Batch [15050], G_Loss[0.139], D_Real_Loss[0.543], D_Fake_Loss[0.528]
Progress[ 61%], ETA[  77m], Batch [15060], G_Loss[0.150], D_Real_Loss[0.881], D_Fake_Loss[0.470]
Progress[ 61%], ETA[  77m], Batch [15070], G_Loss[0.094], D_Real_Loss[0.198], D_Fake_Loss[0.851]
Progress[ 61%], ETA[  77m], Batch [15080], G_Loss[0.198], D_Real_Loss[0.992], D_Fake_Loss[0.256]
Progress[ 61%], ETA[  77m], Batch [15090], G_Loss[0.066], D_Real_Loss[0.115], D_Fake_Loss[1.400]
Progress[ 61%], ETA[  77m], Batch [15100], G_Loss[0.189], D_Real_Loss[0.984], D_Fake_Loss[0.261]
Progress[ 61%], ETA[  77m], Batch [15110], G_Loss[0.202], D_Real_Loss[0.664], D_Fake_Loss[0.264]
Progress[ 61%], ETA[  77m], Batch [15120], G_Loss[0.179], D_Real_Loss[0.606], D_Fake_Loss[0.303]
Progress[ 61%], ETA[  77m], Batch [15130], G_Loss[0.106], D_Real_Loss[0.137], D_Fake_Loss[0.741]
Progress[ 61%], ETA[  77m], Batch [15140], G_Loss[0.134], D_Real_Loss[0.202], D_Fake_Loss[0.523]
Progress[ 61%], ETA[  76m], Batch [15150], G_Loss[0.159], D_Real_Loss[0.148], D_Fake_Loss[0.406]
Progress[ 61%], ETA[  76m], Batch [15160], G_Loss[0.122], D_Real_Loss[0.198], D_Fake_Loss[0.758]
Progress[ 61%], ETA[  76m], Batch [15170], G_Loss[0.181], D_Real_Loss[0.589], D_Fake_Loss[0.322]
Progress[ 61%], ETA[  76m], Batch [15180], G_Loss[0.154], D_Real_Loss[0.223], D_Fake_Loss[0.446]
Progress[ 61%], ETA[  76m], Batch [15190], G_Loss[0.188], D_Real_Loss[0.259], D_Fake_Loss[0.300]
Progress[ 61%], ETA[  76m], Batch [15200], G_Loss[0.175], D_Real_Loss[0.430], D_Fake_Loss[0.300]
    Saved train/batch015200_out.png
Progress[ 61%], ETA[  76m], Batch [15210], G_Loss[0.124], D_Real_Loss[0.333], D_Fake_Loss[0.587]
Progress[ 61%], ETA[  76m], Batch [15220], G_Loss[0.107], D_Real_Loss[0.444], D_Fake_Loss[0.810]
Progress[ 61%], ETA[  76m], Batch [15230], G_Loss[0.124], D_Real_Loss[0.433], D_Fake_Loss[0.543]
Progress[ 61%], ETA[  76m], Batch [15240], G_Loss[0.154], D_Real_Loss[0.452], D_Fake_Loss[0.418]
Progress[ 61%], ETA[  76m], Batch [15250], G_Loss[0.131], D_Real_Loss[0.201], D_Fake_Loss[0.580]
Progress[ 61%], ETA[  76m], Batch [15260], G_Loss[0.121], D_Real_Loss[0.110], D_Fake_Loss[0.632]
Progress[ 61%], ETA[  76m], Batch [15270], G_Loss[0.181], D_Real_Loss[0.703], D_Fake_Loss[0.297]
Progress[ 61%], ETA[  76m], Batch [15280], G_Loss[0.182], D_Real_Loss[0.606], D_Fake_Loss[0.337]
Progress[ 62%], ETA[  76m], Batch [15290], G_Loss[0.129], D_Real_Loss[0.343], D_Fake_Loss[0.641]
Progress[ 62%], ETA[  75m], Batch [15300], G_Loss[0.088], D_Real_Loss[0.140], D_Fake_Loss[1.004]
Progress[ 62%], ETA[  75m], Batch [15310], G_Loss[0.210], D_Real_Loss[0.283], D_Fake_Loss[0.219]
Progress[ 62%], ETA[  75m], Batch [15320], G_Loss[0.186], D_Real_Loss[0.734], D_Fake_Loss[0.289]
Progress[ 62%], ETA[  75m], Batch [15330], G_Loss[0.189], D_Real_Loss[0.120], D_Fake_Loss[0.265]
Progress[ 62%], ETA[  75m], Batch [15340], G_Loss[0.158], D_Real_Loss[0.242], D_Fake_Loss[0.386]
Progress[ 62%], ETA[  75m], Batch [15350], G_Loss[0.249], D_Real_Loss[0.852], D_Fake_Loss[0.153]
Progress[ 62%], ETA[  75m], Batch [15360], G_Loss[0.093], D_Real_Loss[0.099], D_Fake_Loss[0.873]
Progress[ 62%], ETA[  75m], Batch [15370], G_Loss[0.196], D_Real_Loss[0.262], D_Fake_Loss[0.246]
Progress[ 62%], ETA[  75m], Batch [15380], G_Loss[0.122], D_Real_Loss[0.267], D_Fake_Loss[0.585]
Progress[ 62%], ETA[  75m], Batch [15390], G_Loss[0.166], D_Real_Loss[0.159], D_Fake_Loss[0.334]
Progress[ 62%], ETA[  75m], Batch [15400], G_Loss[0.235], D_Real_Loss[0.518], D_Fake_Loss[0.169]
    Saved train/batch015400_out.png
Progress[ 62%], ETA[  75m], Batch [15410], G_Loss[0.178], D_Real_Loss[0.951], D_Fake_Loss[0.298]
Progress[ 62%], ETA[  75m], Batch [15420], G_Loss[0.199], D_Real_Loss[0.176], D_Fake_Loss[0.247]
Progress[ 62%], ETA[  75m], Batch [15430], G_Loss[0.105], D_Real_Loss[0.123], D_Fake_Loss[0.723]
Progress[ 62%], ETA[  75m], Batch [15440], G_Loss[0.165], D_Real_Loss[0.445], D_Fake_Loss[0.355]
Progress[ 62%], ETA[  74m], Batch [15450], G_Loss[0.120], D_Real_Loss[0.212], D_Fake_Loss[0.646]
Progress[ 62%], ETA[  74m], Batch [15460], G_Loss[0.136], D_Real_Loss[0.334], D_Fake_Loss[0.524]
Progress[ 62%], ETA[  74m], Batch [15470], G_Loss[0.161], D_Real_Loss[0.339], D_Fake_Loss[0.359]
Progress[ 62%], ETA[  74m], Batch [15480], G_Loss[0.189], D_Real_Loss[0.385], D_Fake_Loss[0.272]
Progress[ 62%], ETA[  74m], Batch [15490], G_Loss[0.122], D_Real_Loss[0.432], D_Fake_Loss[0.608]
Progress[ 62%], ETA[  74m], Batch [15500], G_Loss[0.247], D_Real_Loss[1.464], D_Fake_Loss[0.138]
Progress[ 62%], ETA[  74m], Batch [15510], G_Loss[0.152], D_Real_Loss[0.221], D_Fake_Loss[0.444]
Progress[ 62%], ETA[  74m], Batch [15520], G_Loss[0.169], D_Real_Loss[0.342], D_Fake_Loss[0.341]
Progress[ 62%], ETA[  74m], Batch [15530], G_Loss[0.181], D_Real_Loss[0.207], D_Fake_Loss[0.333]
Progress[ 62%], ETA[  74m], Batch [15540], G_Loss[0.251], D_Real_Loss[0.416], D_Fake_Loss[0.140]
Progress[ 62%], ETA[  74m], Batch [15550], G_Loss[0.159], D_Real_Loss[0.831], D_Fake_Loss[0.385]
Progress[ 62%], ETA[  74m], Batch [15560], G_Loss[0.169], D_Real_Loss[0.228], D_Fake_Loss[0.336]
Progress[ 62%], ETA[  74m], Batch [15570], G_Loss[0.198], D_Real_Loss[0.604], D_Fake_Loss[0.273]
Progress[ 62%], ETA[  74m], Batch [15580], G_Loss[0.166], D_Real_Loss[0.645], D_Fake_Loss[0.341]
Progress[ 62%], ETA[  74m], Batch [15590], G_Loss[0.095], D_Real_Loss[0.645], D_Fake_Loss[0.875]
Progress[ 63%], ETA[  73m], Batch [15600], G_Loss[0.184], D_Real_Loss[0.224], D_Fake_Loss[0.287]
    Saved train/batch015600_out.png
Progress[ 63%], ETA[  73m], Batch [15610], G_Loss[0.114], D_Real_Loss[0.175], D_Fake_Loss[0.641]
Progress[ 63%], ETA[  73m], Batch [15620], G_Loss[0.222], D_Real_Loss[0.254], D_Fake_Loss[0.199]
Progress[ 63%], ETA[  73m], Batch [15630], G_Loss[0.120], D_Real_Loss[0.381], D_Fake_Loss[0.591]
Progress[ 63%], ETA[  73m], Batch [15640], G_Loss[0.179], D_Real_Loss[1.086], D_Fake_Loss[0.293]
Progress[ 63%], ETA[  73m], Batch [15650], G_Loss[0.160], D_Real_Loss[0.616], D_Fake_Loss[0.369]
Progress[ 63%], ETA[  73m], Batch [15660], G_Loss[0.171], D_Real_Loss[0.477], D_Fake_Loss[0.325]
Progress[ 63%], ETA[  73m], Batch [15670], G_Loss[0.149], D_Real_Loss[0.609], D_Fake_Loss[0.461]
Progress[ 63%], ETA[  73m], Batch [15680], G_Loss[0.130], D_Real_Loss[0.405], D_Fake_Loss[0.562]
Progress[ 63%], ETA[  73m], Batch [15690], G_Loss[0.195], D_Real_Loss[0.145], D_Fake_Loss[0.248]
Progress[ 63%], ETA[  73m], Batch [15700], G_Loss[0.099], D_Real_Loss[0.181], D_Fake_Loss[0.827]
Progress[ 63%], ETA[  73m], Batch [15710], G_Loss[0.134], D_Real_Loss[0.191], D_Fake_Loss[0.519]
Progress[ 63%], ETA[  73m], Batch [15720], G_Loss[0.114], D_Real_Loss[0.069], D_Fake_Loss[0.677]
Progress[ 63%], ETA[  73m], Batch [15730], G_Loss[0.162], D_Real_Loss[0.191], D_Fake_Loss[0.359]
Progress[ 63%], ETA[  73m], Batch [15740], G_Loss[0.090], D_Real_Loss[0.260], D_Fake_Loss[1.017]
Progress[ 63%], ETA[  72m], Batch [15750], G_Loss[0.162], D_Real_Loss[0.842], D_Fake_Loss[0.367]
Progress[ 63%], ETA[  72m], Batch [15760], G_Loss[0.115], D_Real_Loss[0.448], D_Fake_Loss[0.698]
Progress[ 63%], ETA[  72m], Batch [15770], G_Loss[0.178], D_Real_Loss[0.412], D_Fake_Loss[0.331]
Progress[ 63%], ETA[  72m], Batch [15780], G_Loss[0.104], D_Real_Loss[0.374], D_Fake_Loss[0.792]
Progress[ 63%], ETA[  72m], Batch [15790], G_Loss[0.172], D_Real_Loss[0.511], D_Fake_Loss[0.338]
Progress[ 63%], ETA[  72m], Batch [15800], G_Loss[0.144], D_Real_Loss[0.387], D_Fake_Loss[0.495]
    Saved train/batch015800_out.png
Progress[ 63%], ETA[  72m], Batch [15810], G_Loss[0.125], D_Real_Loss[0.147], D_Fake_Loss[0.606]
Progress[ 63%], ETA[  72m], Batch [15820], G_Loss[0.204], D_Real_Loss[0.263], D_Fake_Loss[0.259]
Progress[ 63%], ETA[  72m], Batch [15830], G_Loss[0.126], D_Real_Loss[0.201], D_Fake_Loss[0.643]
Progress[ 63%], ETA[  72m], Batch [15840], G_Loss[0.241], D_Real_Loss[0.758], D_Fake_Loss[0.169]
Progress[ 63%], ETA[  72m], Batch [15850], G_Loss[0.165], D_Real_Loss[0.421], D_Fake_Loss[0.381]
Progress[ 63%], ETA[  72m], Batch [15860], G_Loss[0.231], D_Real_Loss[1.423], D_Fake_Loss[0.193]
Progress[ 63%], ETA[  72m], Batch [15870], G_Loss[0.347], D_Real_Loss[1.225], D_Fake_Loss[0.061]
Progress[ 63%], ETA[  72m], Batch [15880], G_Loss[0.108], D_Real_Loss[0.195], D_Fake_Loss[0.776]
Progress[ 63%], ETA[  72m], Batch [15890], G_Loss[0.153], D_Real_Loss[0.069], D_Fake_Loss[0.422]
Progress[ 64%], ETA[  71m], Batch [15900], G_Loss[0.176], D_Real_Loss[0.429], D_Fake_Loss[0.328]
Progress[ 64%], ETA[  71m], Batch [15910], G_Loss[0.098], D_Real_Loss[0.153], D_Fake_Loss[0.961]
Progress[ 64%], ETA[  71m], Batch [15920], G_Loss[0.126], D_Real_Loss[0.178], D_Fake_Loss[0.586]
Progress[ 64%], ETA[  71m], Batch [15930], G_Loss[0.106], D_Real_Loss[0.184], D_Fake_Loss[0.722]
Progress[ 64%], ETA[  71m], Batch [15940], G_Loss[0.249], D_Real_Loss[1.015], D_Fake_Loss[0.163]
Progress[ 64%], ETA[  71m], Batch [15950], G_Loss[0.285], D_Real_Loss[0.418], D_Fake_Loss[0.103]
Progress[ 64%], ETA[  71m], Batch [15960], G_Loss[0.087], D_Real_Loss[0.330], D_Fake_Loss[1.064]
Progress[ 64%], ETA[  71m], Batch [15970], G_Loss[0.251], D_Real_Loss[0.405], D_Fake_Loss[0.143]
Progress[ 64%], ETA[  71m], Batch [15980], G_Loss[0.101], D_Real_Loss[0.070], D_Fake_Loss[0.777]
Progress[ 64%], ETA[  71m], Batch [15990], G_Loss[0.137], D_Real_Loss[0.392], D_Fake_Loss[0.478]
Progress[ 64%], ETA[  71m], Batch [16000], G_Loss[0.162], D_Real_Loss[0.272], D_Fake_Loss[0.355]
    Saved train/batch016000_out.png
Progress[ 64%], ETA[  71m], Batch [16010], G_Loss[0.137], D_Real_Loss[0.349], D_Fake_Loss[0.513]
Progress[ 64%], ETA[  71m], Batch [16020], G_Loss[0.132], D_Real_Loss[0.383], D_Fake_Loss[0.510]
Progress[ 64%], ETA[  71m], Batch [16030], G_Loss[0.171], D_Real_Loss[0.911], D_Fake_Loss[0.345]
Progress[ 64%], ETA[  71m], Batch [16040], G_Loss[0.171], D_Real_Loss[0.392], D_Fake_Loss[0.337]
Progress[ 64%], ETA[  70m], Batch [16050], G_Loss[0.192], D_Real_Loss[1.446], D_Fake_Loss[0.251]
Progress[ 64%], ETA[  70m], Batch [16060], G_Loss[0.214], D_Real_Loss[0.389], D_Fake_Loss[0.206]
Progress[ 64%], ETA[  70m], Batch [16070], G_Loss[0.143], D_Real_Loss[0.175], D_Fake_Loss[0.495]
Progress[ 64%], ETA[  70m], Batch [16080], G_Loss[0.164], D_Real_Loss[0.328], D_Fake_Loss[0.379]
Progress[ 64%], ETA[  70m], Batch [16090], G_Loss[0.184], D_Real_Loss[0.484], D_Fake_Loss[0.338]
Progress[ 64%], ETA[  70m], Batch [16100], G_Loss[0.151], D_Real_Loss[0.448], D_Fake_Loss[0.422]
Progress[ 64%], ETA[  70m], Batch [16110], G_Loss[0.220], D_Real_Loss[0.928], D_Fake_Loss[0.203]
Progress[ 64%], ETA[  70m], Batch [16120], G_Loss[0.190], D_Real_Loss[1.884], D_Fake_Loss[0.261]
Progress[ 64%], ETA[  70m], Batch [16130], G_Loss[0.132], D_Real_Loss[0.128], D_Fake_Loss[0.556]
Progress[ 64%], ETA[  70m], Batch [16140], G_Loss[0.150], D_Real_Loss[0.170], D_Fake_Loss[0.470]
Progress[ 64%], ETA[  70m], Batch [16150], G_Loss[0.233], D_Real_Loss[0.892], D_Fake_Loss[0.173]
Progress[ 64%], ETA[  70m], Batch [16160], G_Loss[0.290], D_Real_Loss[0.792], D_Fake_Loss[0.096]
Progress[ 64%], ETA[  70m], Batch [16170], G_Loss[0.159], D_Real_Loss[0.397], D_Fake_Loss[0.365]
Progress[ 64%], ETA[  70m], Batch [16180], G_Loss[0.116], D_Real_Loss[0.292], D_Fake_Loss[0.678]
Progress[ 64%], ETA[  70m], Batch [16190], G_Loss[0.259], D_Real_Loss[1.042], D_Fake_Loss[0.122]
Progress[ 65%], ETA[  69m], Batch [16200], G_Loss[0.134], D_Real_Loss[0.210], D_Fake_Loss[0.505]
    Saved train/batch016200_out.png
Progress[ 65%], ETA[  69m], Batch [16210], G_Loss[0.121], D_Real_Loss[0.206], D_Fake_Loss[0.636]
Progress[ 65%], ETA[  69m], Batch [16220], G_Loss[0.257], D_Real_Loss[0.938], D_Fake_Loss[0.145]
Progress[ 65%], ETA[  69m], Batch [16230], G_Loss[0.095], D_Real_Loss[0.475], D_Fake_Loss[0.837]
Progress[ 65%], ETA[  69m], Batch [16240], G_Loss[0.261], D_Real_Loss[0.298], D_Fake_Loss[0.134]
Progress[ 65%], ETA[  69m], Batch [16250], G_Loss[0.167], D_Real_Loss[0.620], D_Fake_Loss[0.357]
Progress[ 65%], ETA[  69m], Batch [16260], G_Loss[0.195], D_Real_Loss[0.571], D_Fake_Loss[0.255]
Progress[ 65%], ETA[  69m], Batch [16270], G_Loss[0.157], D_Real_Loss[0.238], D_Fake_Loss[0.372]
Progress[ 65%], ETA[  69m], Batch [16280], G_Loss[0.199], D_Real_Loss[0.507], D_Fake_Loss[0.252]
Progress[ 65%], ETA[  69m], Batch [16290], G_Loss[0.182], D_Real_Loss[0.541], D_Fake_Loss[0.307]
Progress[ 65%], ETA[  69m], Batch [16300], G_Loss[0.166], D_Real_Loss[0.179], D_Fake_Loss[0.376]
Progress[ 65%], ETA[  69m], Batch [16310], G_Loss[0.085], D_Real_Loss[0.183], D_Fake_Loss[1.159]
Progress[ 65%], ETA[  69m], Batch [16320], G_Loss[0.126], D_Real_Loss[0.140], D_Fake_Loss[0.595]
Progress[ 65%], ETA[  69m], Batch [16330], G_Loss[0.197], D_Real_Loss[0.682], D_Fake_Loss[0.249]
Progress[ 65%], ETA[  69m], Batch [16340], G_Loss[0.250], D_Real_Loss[0.512], D_Fake_Loss[0.144]
Progress[ 65%], ETA[  68m], Batch [16350], G_Loss[0.268], D_Real_Loss[0.437], D_Fake_Loss[0.121]
Progress[ 65%], ETA[  68m], Batch [16360], G_Loss[0.160], D_Real_Loss[0.697], D_Fake_Loss[0.407]
Progress[ 65%], ETA[  68m], Batch [16370], G_Loss[0.107], D_Real_Loss[0.270], D_Fake_Loss[0.752]
Progress[ 65%], ETA[  68m], Batch [16380], G_Loss[0.129], D_Real_Loss[0.519], D_Fake_Loss[0.601]
Progress[ 65%], ETA[  68m], Batch [16390], G_Loss[0.268], D_Real_Loss[0.752], D_Fake_Loss[0.123]
Progress[ 65%], ETA[  68m], Batch [16400], G_Loss[0.171], D_Real_Loss[0.212], D_Fake_Loss[0.372]
    Saved train/batch016400_out.png
Progress[ 65%], ETA[  68m], Batch [16410], G_Loss[0.163], D_Real_Loss[0.361], D_Fake_Loss[0.382]
Progress[ 65%], ETA[  68m], Batch [16420], G_Loss[0.170], D_Real_Loss[0.169], D_Fake_Loss[0.380]
Progress[ 65%], ETA[  68m], Batch [16430], G_Loss[0.141], D_Real_Loss[0.395], D_Fake_Loss[0.466]
Progress[ 65%], ETA[  68m], Batch [16440], G_Loss[0.164], D_Real_Loss[0.454], D_Fake_Loss[0.383]
Progress[ 65%], ETA[  68m], Batch [16450], G_Loss[0.175], D_Real_Loss[0.357], D_Fake_Loss[0.308]
Progress[ 65%], ETA[  68m], Batch [16460], G_Loss[0.189], D_Real_Loss[0.756], D_Fake_Loss[0.284]
Progress[ 65%], ETA[  68m], Batch [16470], G_Loss[0.182], D_Real_Loss[0.295], D_Fake_Loss[0.308]
Progress[ 65%], ETA[  68m], Batch [16480], G_Loss[0.233], D_Real_Loss[0.894], D_Fake_Loss[0.167]
Progress[ 65%], ETA[  68m], Batch [16490], G_Loss[0.164], D_Real_Loss[0.597], D_Fake_Loss[0.398]
Progress[ 66%], ETA[  67m], Batch [16500], G_Loss[0.124], D_Real_Loss[0.772], D_Fake_Loss[0.630]
Progress[ 66%], ETA[  67m], Batch [16510], G_Loss[0.172], D_Real_Loss[0.763], D_Fake_Loss[0.357]
Progress[ 66%], ETA[  67m], Batch [16520], G_Loss[0.139], D_Real_Loss[0.551], D_Fake_Loss[0.513]
Progress[ 66%], ETA[  67m], Batch [16530], G_Loss[0.239], D_Real_Loss[0.387], D_Fake_Loss[0.172]
Progress[ 66%], ETA[  67m], Batch [16540], G_Loss[0.171], D_Real_Loss[0.403], D_Fake_Loss[0.343]
Progress[ 66%], ETA[  67m], Batch [16550], G_Loss[0.079], D_Real_Loss[0.298], D_Fake_Loss[1.311]
Progress[ 66%], ETA[  67m], Batch [16560], G_Loss[0.127], D_Real_Loss[0.343], D_Fake_Loss[0.575]
Progress[ 66%], ETA[  67m], Batch [16570], G_Loss[0.165], D_Real_Loss[0.644], D_Fake_Loss[0.349]
Progress[ 66%], ETA[  67m], Batch [16580], G_Loss[0.120], D_Real_Loss[0.534], D_Fake_Loss[0.664]
Progress[ 66%], ETA[  67m], Batch [16590], G_Loss[0.141], D_Real_Loss[0.439], D_Fake_Loss[0.489]
Progress[ 66%], ETA[  67m], Batch [16600], G_Loss[0.215], D_Real_Loss[0.731], D_Fake_Loss[0.209]
    Saved train/batch016600_out.png
Progress[ 66%], ETA[  67m], Batch [16610], G_Loss[0.180], D_Real_Loss[0.745], D_Fake_Loss[0.326]
Progress[ 66%], ETA[  67m], Batch [16620], G_Loss[0.086], D_Real_Loss[0.611], D_Fake_Loss[1.041]
Progress[ 66%], ETA[  67m], Batch [16630], G_Loss[0.147], D_Real_Loss[0.730], D_Fake_Loss[0.455]
Progress[ 66%], ETA[  67m], Batch [16640], G_Loss[0.172], D_Real_Loss[0.060], D_Fake_Loss[0.341]
Progress[ 66%], ETA[  66m], Batch [16650], G_Loss[0.089], D_Real_Loss[0.190], D_Fake_Loss[0.990]
Progress[ 66%], ETA[  66m], Batch [16660], G_Loss[0.237], D_Real_Loss[0.579], D_Fake_Loss[0.170]
Progress[ 66%], ETA[  66m], Batch [16670], G_Loss[0.160], D_Real_Loss[0.857], D_Fake_Loss[0.433]
Progress[ 66%], ETA[  66m], Batch [16680], G_Loss[0.143], D_Real_Loss[0.590], D_Fake_Loss[0.511]
Progress[ 66%], ETA[  66m], Batch [16690], G_Loss[0.133], D_Real_Loss[0.496], D_Fake_Loss[0.524]
Progress[ 66%], ETA[  66m], Batch [16700], G_Loss[0.146], D_Real_Loss[0.713], D_Fake_Loss[0.440]
Progress[ 66%], ETA[  66m], Batch [16710], G_Loss[0.136], D_Real_Loss[0.598], D_Fake_Loss[0.525]
Progress[ 66%], ETA[  66m], Batch [16720], G_Loss[0.131], D_Real_Loss[0.500], D_Fake_Loss[0.545]
Progress[ 66%], ETA[  66m], Batch [16730], G_Loss[0.099], D_Real_Loss[0.271], D_Fake_Loss[0.845]
Progress[ 66%], ETA[  66m], Batch [16740], G_Loss[0.177], D_Real_Loss[0.166], D_Fake_Loss[0.310]
Progress[ 66%], ETA[  66m], Batch [16750], G_Loss[0.157], D_Real_Loss[0.633], D_Fake_Loss[0.413]
Progress[ 66%], ETA[  66m], Batch [16760], G_Loss[0.228], D_Real_Loss[0.827], D_Fake_Loss[0.178]
Progress[ 66%], ETA[  66m], Batch [16770], G_Loss[0.103], D_Real_Loss[0.245], D_Fake_Loss[0.781]
Progress[ 66%], ETA[  66m], Batch [16780], G_Loss[0.173], D_Real_Loss[0.398], D_Fake_Loss[0.318]
Progress[ 66%], ETA[  66m], Batch [16790], G_Loss[0.106], D_Real_Loss[0.206], D_Fake_Loss[0.762]
Progress[ 67%], ETA[  66m], Batch [16800], G_Loss[0.229], D_Real_Loss[1.062], D_Fake_Loss[0.183]
    Saved train/batch016800_out.png
Progress[ 67%], ETA[  65m], Batch [16810], G_Loss[0.154], D_Real_Loss[0.468], D_Fake_Loss[0.489]
Progress[ 67%], ETA[  65m], Batch [16820], G_Loss[0.117], D_Real_Loss[0.237], D_Fake_Loss[0.653]
Progress[ 67%], ETA[  65m], Batch [16830], G_Loss[0.130], D_Real_Loss[0.533], D_Fake_Loss[0.558]
Progress[ 67%], ETA[  65m], Batch [16840], G_Loss[0.158], D_Real_Loss[0.473], D_Fake_Loss[0.415]
Progress[ 67%], ETA[  65m], Batch [16850], G_Loss[0.122], D_Real_Loss[0.293], D_Fake_Loss[0.615]
Progress[ 67%], ETA[  65m], Batch [16860], G_Loss[0.193], D_Real_Loss[0.389], D_Fake_Loss[0.277]
Progress[ 67%], ETA[  65m], Batch [16870], G_Loss[0.296], D_Real_Loss[0.248], D_Fake_Loss[0.105]
Progress[ 67%], ETA[  65m], Batch [16880], G_Loss[0.155], D_Real_Loss[0.729], D_Fake_Loss[0.381]
Progress[ 67%], ETA[  65m], Batch [16890], G_Loss[0.111], D_Real_Loss[0.164], D_Fake_Loss[0.856]
Progress[ 67%], ETA[  65m], Batch [16900], G_Loss[0.141], D_Real_Loss[0.257], D_Fake_Loss[0.506]
Progress[ 67%], ETA[  65m], Batch [16910], G_Loss[0.152], D_Real_Loss[0.486], D_Fake_Loss[0.385]
Progress[ 67%], ETA[  65m], Batch [16920], G_Loss[0.155], D_Real_Loss[0.795], D_Fake_Loss[0.420]
Progress[ 67%], ETA[  65m], Batch [16930], G_Loss[0.183], D_Real_Loss[0.347], D_Fake_Loss[0.303]
Progress[ 67%], ETA[  65m], Batch [16940], G_Loss[0.092], D_Real_Loss[0.158], D_Fake_Loss[0.946]
Progress[ 67%], ETA[  65m], Batch [16950], G_Loss[0.118], D_Real_Loss[0.351], D_Fake_Loss[0.702]
Progress[ 67%], ETA[  64m], Batch [16960], G_Loss[0.161], D_Real_Loss[0.329], D_Fake_Loss[0.371]
Progress[ 67%], ETA[  64m], Batch [16970], G_Loss[0.093], D_Real_Loss[0.206], D_Fake_Loss[0.949]
Progress[ 67%], ETA[  64m], Batch [16980], G_Loss[0.125], D_Real_Loss[0.214], D_Fake_Loss[0.579]
Progress[ 67%], ETA[  64m], Batch [16990], G_Loss[0.165], D_Real_Loss[0.538], D_Fake_Loss[0.345]
Progress[ 67%], ETA[  64m], Batch [17000], G_Loss[0.212], D_Real_Loss[0.749], D_Fake_Loss[0.233]
    Saved train/batch017000_out.png
Progress[ 67%], ETA[  64m], Batch [17010], G_Loss[0.132], D_Real_Loss[0.189], D_Fake_Loss[0.505]
Progress[ 67%], ETA[  64m], Batch [17020], G_Loss[0.184], D_Real_Loss[0.327], D_Fake_Loss[0.326]
Progress[ 67%], ETA[  64m], Batch [17030], G_Loss[0.060], D_Real_Loss[0.369], D_Fake_Loss[1.625]
Progress[ 67%], ETA[  64m], Batch [17040], G_Loss[0.092], D_Real_Loss[0.332], D_Fake_Loss[0.881]
Progress[ 67%], ETA[  64m], Batch [17050], G_Loss[0.308], D_Real_Loss[0.613], D_Fake_Loss[0.081]
Progress[ 67%], ETA[  64m], Batch [17060], G_Loss[0.172], D_Real_Loss[0.522], D_Fake_Loss[0.329]
Progress[ 67%], ETA[  64m], Batch [17070], G_Loss[0.192], D_Real_Loss[0.667], D_Fake_Loss[0.264]
Progress[ 67%], ETA[  64m], Batch [17080], G_Loss[0.129], D_Real_Loss[0.207], D_Fake_Loss[0.545]
Progress[ 67%], ETA[  64m], Batch [17090], G_Loss[0.118], D_Real_Loss[0.533], D_Fake_Loss[0.651]
Progress[ 68%], ETA[  64m], Batch [17100], G_Loss[0.183], D_Real_Loss[0.517], D_Fake_Loss[0.280]
Progress[ 68%], ETA[  63m], Batch [17110], G_Loss[0.222], D_Real_Loss[0.819], D_Fake_Loss[0.226]
Progress[ 68%], ETA[  63m], Batch [17120], G_Loss[0.163], D_Real_Loss[0.230], D_Fake_Loss[0.387]
Progress[ 68%], ETA[  63m], Batch [17130], G_Loss[0.137], D_Real_Loss[0.295], D_Fake_Loss[0.568]
Progress[ 68%], ETA[  63m], Batch [17140], G_Loss[0.119], D_Real_Loss[0.254], D_Fake_Loss[0.609]
Progress[ 68%], ETA[  63m], Batch [17150], G_Loss[0.082], D_Real_Loss[0.247], D_Fake_Loss[1.052]
Progress[ 68%], ETA[  63m], Batch [17160], G_Loss[0.096], D_Real_Loss[0.464], D_Fake_Loss[0.897]
Progress[ 68%], ETA[  63m], Batch [17170], G_Loss[0.130], D_Real_Loss[0.812], D_Fake_Loss[0.559]
Progress[ 68%], ETA[  63m], Batch [17180], G_Loss[0.173], D_Real_Loss[0.355], D_Fake_Loss[0.389]
Progress[ 68%], ETA[  63m], Batch [17190], G_Loss[0.154], D_Real_Loss[0.136], D_Fake_Loss[0.418]
Progress[ 68%], ETA[  63m], Batch [17200], G_Loss[0.177], D_Real_Loss[0.401], D_Fake_Loss[0.335]
    Saved train/batch017200_out.png
Progress[ 68%], ETA[  63m], Batch [17210], G_Loss[0.225], D_Real_Loss[0.787], D_Fake_Loss[0.180]
Progress[ 68%], ETA[  63m], Batch [17220], G_Loss[0.173], D_Real_Loss[0.569], D_Fake_Loss[0.334]
Progress[ 68%], ETA[  63m], Batch [17230], G_Loss[0.192], D_Real_Loss[0.559], D_Fake_Loss[0.268]
Progress[ 68%], ETA[  63m], Batch [17240], G_Loss[0.110], D_Real_Loss[0.205], D_Fake_Loss[0.758]
Progress[ 68%], ETA[  63m], Batch [17250], G_Loss[0.200], D_Real_Loss[0.172], D_Fake_Loss[0.306]
Progress[ 68%], ETA[  62m], Batch [17260], G_Loss[0.196], D_Real_Loss[0.231], D_Fake_Loss[0.244]
Progress[ 68%], ETA[  62m], Batch [17270], G_Loss[0.139], D_Real_Loss[0.292], D_Fake_Loss[0.480]
Progress[ 68%], ETA[  62m], Batch [17280], G_Loss[0.092], D_Real_Loss[0.139], D_Fake_Loss[1.204]
Progress[ 68%], ETA[  62m], Batch [17290], G_Loss[0.123], D_Real_Loss[0.138], D_Fake_Loss[0.593]
Progress[ 68%], ETA[  62m], Batch [17300], G_Loss[0.135], D_Real_Loss[1.050], D_Fake_Loss[0.533]
Progress[ 68%], ETA[  62m], Batch [17310], G_Loss[0.231], D_Real_Loss[0.739], D_Fake_Loss[0.161]
Progress[ 68%], ETA[  62m], Batch [17320], G_Loss[0.119], D_Real_Loss[0.128], D_Fake_Loss[0.714]
Progress[ 68%], ETA[  62m], Batch [17330], G_Loss[0.108], D_Real_Loss[0.438], D_Fake_Loss[0.763]
Progress[ 68%], ETA[  62m], Batch [17340], G_Loss[0.138], D_Real_Loss[0.185], D_Fake_Loss[0.499]
Progress[ 68%], ETA[  62m], Batch [17350], G_Loss[0.122], D_Real_Loss[0.377], D_Fake_Loss[0.623]
Progress[ 68%], ETA[  62m], Batch [17360], G_Loss[0.172], D_Real_Loss[0.633], D_Fake_Loss[0.377]
Progress[ 68%], ETA[  62m], Batch [17370], G_Loss[0.141], D_Real_Loss[0.336], D_Fake_Loss[0.497]
Progress[ 68%], ETA[  62m], Batch [17380], G_Loss[0.127], D_Real_Loss[0.255], D_Fake_Loss[0.681]
Progress[ 68%], ETA[  62m], Batch [17390], G_Loss[0.203], D_Real_Loss[0.255], D_Fake_Loss[0.243]
Progress[ 68%], ETA[  62m], Batch [17400], G_Loss[0.227], D_Real_Loss[0.601], D_Fake_Loss[0.180]
    Saved train/batch017400_out.png
Progress[ 69%], ETA[  61m], Batch [17410], G_Loss[0.149], D_Real_Loss[0.153], D_Fake_Loss[0.447]
Progress[ 69%], ETA[  61m], Batch [17420], G_Loss[0.292], D_Real_Loss[0.665], D_Fake_Loss[0.088]
Progress[ 69%], ETA[  61m], Batch [17430], G_Loss[0.163], D_Real_Loss[0.241], D_Fake_Loss[0.359]
Progress[ 69%], ETA[  61m], Batch [17440], G_Loss[0.138], D_Real_Loss[0.096], D_Fake_Loss[0.497]
Progress[ 69%], ETA[  61m], Batch [17450], G_Loss[0.263], D_Real_Loss[0.855], D_Fake_Loss[0.117]
Progress[ 69%], ETA[  61m], Batch [17460], G_Loss[0.138], D_Real_Loss[0.338], D_Fake_Loss[0.479]
Progress[ 69%], ETA[  61m], Batch [17470], G_Loss[0.085], D_Real_Loss[0.281], D_Fake_Loss[1.070]
Progress[ 69%], ETA[  61m], Batch [17480], G_Loss[0.156], D_Real_Loss[0.069], D_Fake_Loss[0.433]
Progress[ 69%], ETA[  61m], Batch [17490], G_Loss[0.165], D_Real_Loss[0.270], D_Fake_Loss[0.352]
Progress[ 69%], ETA[  61m], Batch [17500], G_Loss[0.182], D_Real_Loss[0.615], D_Fake_Loss[0.302]
Progress[ 69%], ETA[  61m], Batch [17510], G_Loss[0.078], D_Real_Loss[0.164], D_Fake_Loss[1.231]
Progress[ 69%], ETA[  61m], Batch [17520], G_Loss[0.203], D_Real_Loss[0.915], D_Fake_Loss[0.230]
Progress[ 69%], ETA[  61m], Batch [17530], G_Loss[0.122], D_Real_Loss[0.478], D_Fake_Loss[0.606]
Progress[ 69%], ETA[  61m], Batch [17540], G_Loss[0.235], D_Real_Loss[0.297], D_Fake_Loss[0.158]
Progress[ 69%], ETA[  61m], Batch [17550], G_Loss[0.180], D_Real_Loss[0.726], D_Fake_Loss[0.364]
Progress[ 69%], ETA[  60m], Batch [17560], G_Loss[0.153], D_Real_Loss[0.232], D_Fake_Loss[0.417]
Progress[ 69%], ETA[  60m], Batch [17570], G_Loss[0.080], D_Real_Loss[0.062], D_Fake_Loss[1.103]
Progress[ 69%], ETA[  60m], Batch [17580], G_Loss[0.180], D_Real_Loss[1.379], D_Fake_Loss[0.371]
Progress[ 69%], ETA[  60m], Batch [17590], G_Loss[0.188], D_Real_Loss[0.496], D_Fake_Loss[0.286]
Progress[ 69%], ETA[  60m], Batch [17600], G_Loss[0.142], D_Real_Loss[0.767], D_Fake_Loss[0.494]
    Saved train/batch017600_out.png
Progress[ 69%], ETA[  60m], Batch [17610], G_Loss[0.155], D_Real_Loss[0.319], D_Fake_Loss[0.394]
Progress[ 69%], ETA[  60m], Batch [17620], G_Loss[0.138], D_Real_Loss[0.776], D_Fake_Loss[0.489]
Progress[ 69%], ETA[  60m], Batch [17630], G_Loss[0.145], D_Real_Loss[0.686], D_Fake_Loss[0.476]
Progress[ 69%], ETA[  60m], Batch [17640], G_Loss[0.247], D_Real_Loss[0.385], D_Fake_Loss[0.147]
Progress[ 69%], ETA[  60m], Batch [17650], G_Loss[0.194], D_Real_Loss[0.303], D_Fake_Loss[0.263]
Progress[ 69%], ETA[  60m], Batch [17660], G_Loss[0.150], D_Real_Loss[0.677], D_Fake_Loss[0.419]
Progress[ 69%], ETA[  60m], Batch [17670], G_Loss[0.226], D_Real_Loss[1.097], D_Fake_Loss[0.183]
Progress[ 69%], ETA[  60m], Batch [17680], G_Loss[0.209], D_Real_Loss[1.043], D_Fake_Loss[0.209]
Progress[ 69%], ETA[  60m], Batch [17690], G_Loss[0.219], D_Real_Loss[0.240], D_Fake_Loss[0.200]
Progress[ 69%], ETA[  60m], Batch [17700], G_Loss[0.121], D_Real_Loss[0.191], D_Fake_Loss[0.656]
Progress[ 70%], ETA[  59m], Batch [17710], G_Loss[0.213], D_Real_Loss[0.157], D_Fake_Loss[0.199]
Progress[ 70%], ETA[  59m], Batch [17720], G_Loss[0.159], D_Real_Loss[0.151], D_Fake_Loss[0.363]
Progress[ 70%], ETA[  59m], Batch [17730], G_Loss[0.144], D_Real_Loss[0.846], D_Fake_Loss[0.426]
Progress[ 70%], ETA[  59m], Batch [17740], G_Loss[0.089], D_Real_Loss[0.117], D_Fake_Loss[0.947]
Progress[ 70%], ETA[  59m], Batch [17750], G_Loss[0.120], D_Real_Loss[0.320], D_Fake_Loss[0.602]
Progress[ 70%], ETA[  59m], Batch [17760], G_Loss[0.108], D_Real_Loss[0.421], D_Fake_Loss[0.752]
Progress[ 70%], ETA[  59m], Batch [17770], G_Loss[0.121], D_Real_Loss[0.174], D_Fake_Loss[0.612]
Progress[ 70%], ETA[  59m], Batch [17780], G_Loss[0.136], D_Real_Loss[0.198], D_Fake_Loss[0.475]
Progress[ 70%], ETA[  59m], Batch [17790], G_Loss[0.118], D_Real_Loss[0.192], D_Fake_Loss[0.615]
Progress[ 70%], ETA[  59m], Batch [17800], G_Loss[0.092], D_Real_Loss[0.468], D_Fake_Loss[0.937]
    Saved train/batch017800_out.png
Progress[ 70%], ETA[  59m], Batch [17810], G_Loss[0.070], D_Real_Loss[0.182], D_Fake_Loss[1.405]
Progress[ 70%], ETA[  59m], Batch [17820], G_Loss[0.105], D_Real_Loss[0.510], D_Fake_Loss[0.726]
Progress[ 70%], ETA[  59m], Batch [17830], G_Loss[0.189], D_Real_Loss[0.321], D_Fake_Loss[0.316]
Progress[ 70%], ETA[  59m], Batch [17840], G_Loss[0.177], D_Real_Loss[0.470], D_Fake_Loss[0.302]
Progress[ 70%], ETA[  59m], Batch [17850], G_Loss[0.221], D_Real_Loss[1.121], D_Fake_Loss[0.182]
Progress[ 70%], ETA[  58m], Batch [17860], G_Loss[0.095], D_Real_Loss[0.320], D_Fake_Loss[0.846]
Progress[ 70%], ETA[  58m], Batch [17870], G_Loss[0.208], D_Real_Loss[0.619], D_Fake_Loss[0.228]
Progress[ 70%], ETA[  58m], Batch [17880], G_Loss[0.167], D_Real_Loss[0.961], D_Fake_Loss[0.371]
Progress[ 70%], ETA[  58m], Batch [17890], G_Loss[0.173], D_Real_Loss[0.363], D_Fake_Loss[0.318]
Progress[ 70%], ETA[  58m], Batch [17900], G_Loss[0.155], D_Real_Loss[0.396], D_Fake_Loss[0.386]
Progress[ 70%], ETA[  58m], Batch [17910], G_Loss[0.151], D_Real_Loss[0.424], D_Fake_Loss[0.414]
Progress[ 70%], ETA[  58m], Batch [17920], G_Loss[0.276], D_Real_Loss[0.372], D_Fake_Loss[0.111]
Progress[ 70%], ETA[  58m], Batch [17930], G_Loss[0.157], D_Real_Loss[0.544], D_Fake_Loss[0.382]
Progress[ 70%], ETA[  58m], Batch [17940], G_Loss[0.127], D_Real_Loss[0.542], D_Fake_Loss[0.588]
Progress[ 70%], ETA[  58m], Batch [17950], G_Loss[0.127], D_Real_Loss[0.285], D_Fake_Loss[0.558]
Progress[ 70%], ETA[  58m], Batch [17960], G_Loss[0.133], D_Real_Loss[0.187], D_Fake_Loss[0.525]
Progress[ 70%], ETA[  58m], Batch [17970], G_Loss[0.087], D_Real_Loss[0.105], D_Fake_Loss[0.944]
Progress[ 70%], ETA[  58m], Batch [17980], G_Loss[0.107], D_Real_Loss[0.126], D_Fake_Loss[0.785]
Progress[ 70%], ETA[  58m], Batch [17990], G_Loss[0.089], D_Real_Loss[0.391], D_Fake_Loss[0.965]
Progress[ 70%], ETA[  58m], Batch [18000], G_Loss[0.131], D_Real_Loss[0.150], D_Fake_Loss[0.555]
    Saved train/batch018000_out.png
Progress[ 71%], ETA[  57m], Batch [18010], G_Loss[0.223], D_Real_Loss[0.507], D_Fake_Loss[0.198]
Progress[ 71%], ETA[  57m], Batch [18020], G_Loss[0.099], D_Real_Loss[0.211], D_Fake_Loss[0.825]
Progress[ 71%], ETA[  57m], Batch [18030], G_Loss[0.100], D_Real_Loss[0.825], D_Fake_Loss[0.827]
Progress[ 71%], ETA[  57m], Batch [18040], G_Loss[0.334], D_Real_Loss[0.662], D_Fake_Loss[0.056]
Progress[ 71%], ETA[  57m], Batch [18050], G_Loss[0.168], D_Real_Loss[0.339], D_Fake_Loss[0.343]
Progress[ 71%], ETA[  57m], Batch [18060], G_Loss[0.299], D_Real_Loss[0.835], D_Fake_Loss[0.089]
Progress[ 71%], ETA[  57m], Batch [18070], G_Loss[0.092], D_Real_Loss[0.306], D_Fake_Loss[0.972]
Progress[ 71%], ETA[  57m], Batch [18080], G_Loss[0.124], D_Real_Loss[0.331], D_Fake_Loss[0.575]
Progress[ 71%], ETA[  57m], Batch [18090], G_Loss[0.228], D_Real_Loss[0.426], D_Fake_Loss[0.191]
Progress[ 71%], ETA[  57m], Batch [18100], G_Loss[0.259], D_Real_Loss[0.446], D_Fake_Loss[0.120]
Progress[ 71%], ETA[  57m], Batch [18110], G_Loss[0.114], D_Real_Loss[0.319], D_Fake_Loss[0.669]
Progress[ 71%], ETA[  57m], Batch [18120], G_Loss[0.108], D_Real_Loss[0.686], D_Fake_Loss[0.714]
Progress[ 71%], ETA[  57m], Batch [18130], G_Loss[0.246], D_Real_Loss[0.577], D_Fake_Loss[0.151]
Progress[ 71%], ETA[  57m], Batch [18140], G_Loss[0.105], D_Real_Loss[0.333], D_Fake_Loss[0.757]
Progress[ 71%], ETA[  57m], Batch [18150], G_Loss[0.104], D_Real_Loss[0.166], D_Fake_Loss[0.885]
Progress[ 71%], ETA[  56m], Batch [18160], G_Loss[0.144], D_Real_Loss[0.396], D_Fake_Loss[0.480]
Progress[ 71%], ETA[  56m], Batch [18170], G_Loss[0.146], D_Real_Loss[0.356], D_Fake_Loss[0.474]
Progress[ 71%], ETA[  56m], Batch [18180], G_Loss[0.132], D_Real_Loss[0.428], D_Fake_Loss[0.557]
Progress[ 71%], ETA[  56m], Batch [18190], G_Loss[0.197], D_Real_Loss[0.617], D_Fake_Loss[0.241]
Progress[ 71%], ETA[  56m], Batch [18200], G_Loss[0.221], D_Real_Loss[0.453], D_Fake_Loss[0.188]
    Saved train/batch018200_out.png
Progress[ 71%], ETA[  56m], Batch [18210], G_Loss[0.179], D_Real_Loss[0.338], D_Fake_Loss[0.360]
Progress[ 71%], ETA[  56m], Batch [18220], G_Loss[0.209], D_Real_Loss[0.459], D_Fake_Loss[0.245]
Progress[ 71%], ETA[  56m], Batch [18230], G_Loss[0.121], D_Real_Loss[0.208], D_Fake_Loss[0.586]
Progress[ 71%], ETA[  56m], Batch [18240], G_Loss[0.228], D_Real_Loss[0.258], D_Fake_Loss[0.175]
Progress[ 71%], ETA[  56m], Batch [18250], G_Loss[0.152], D_Real_Loss[0.470], D_Fake_Loss[0.422]
Progress[ 71%], ETA[  56m], Batch [18260], G_Loss[0.144], D_Real_Loss[0.243], D_Fake_Loss[0.497]
Progress[ 71%], ETA[  56m], Batch [18270], G_Loss[0.216], D_Real_Loss[1.379], D_Fake_Loss[0.214]
Progress[ 71%], ETA[  56m], Batch [18280], G_Loss[0.169], D_Real_Loss[0.442], D_Fake_Loss[0.336]
Progress[ 71%], ETA[  56m], Batch [18290], G_Loss[0.172], D_Real_Loss[0.508], D_Fake_Loss[0.309]
Progress[ 71%], ETA[  56m], Batch [18300], G_Loss[0.112], D_Real_Loss[0.319], D_Fake_Loss[0.660]
Progress[ 72%], ETA[  55m], Batch [18310], G_Loss[0.144], D_Real_Loss[0.569], D_Fake_Loss[0.445]
Progress[ 72%], ETA[  55m], Batch [18320], G_Loss[0.125], D_Real_Loss[0.293], D_Fake_Loss[0.583]
Progress[ 72%], ETA[  55m], Batch [18330], G_Loss[0.175], D_Real_Loss[0.390], D_Fake_Loss[0.303]
Progress[ 72%], ETA[  55m], Batch [18340], G_Loss[0.133], D_Real_Loss[0.259], D_Fake_Loss[0.491]
Progress[ 72%], ETA[  55m], Batch [18350], G_Loss[0.215], D_Real_Loss[0.167], D_Fake_Loss[0.204]
Progress[ 72%], ETA[  55m], Batch [18360], G_Loss[0.149], D_Real_Loss[0.253], D_Fake_Loss[0.482]
Progress[ 72%], ETA[  55m], Batch [18370], G_Loss[0.166], D_Real_Loss[0.233], D_Fake_Loss[0.380]
Progress[ 72%], ETA[  55m], Batch [18380], G_Loss[0.246], D_Real_Loss[0.623], D_Fake_Loss[0.144]
Progress[ 72%], ETA[  55m], Batch [18390], G_Loss[0.164], D_Real_Loss[0.733], D_Fake_Loss[0.406]
Progress[ 72%], ETA[  55m], Batch [18400], G_Loss[0.192], D_Real_Loss[1.258], D_Fake_Loss[0.271]
    Saved train/batch018400_out.png
Progress[ 72%], ETA[  55m], Batch [18410], G_Loss[0.134], D_Real_Loss[0.631], D_Fake_Loss[0.502]
Progress[ 72%], ETA[  55m], Batch [18420], G_Loss[0.183], D_Real_Loss[0.332], D_Fake_Loss[0.280]
Progress[ 72%], ETA[  55m], Batch [18430], G_Loss[0.194], D_Real_Loss[0.573], D_Fake_Loss[0.261]
Progress[ 72%], ETA[  55m], Batch [18440], G_Loss[0.170], D_Real_Loss[1.053], D_Fake_Loss[0.335]
Progress[ 72%], ETA[  55m], Batch [18450], G_Loss[0.177], D_Real_Loss[0.383], D_Fake_Loss[0.326]
Progress[ 72%], ETA[  54m], Batch [18460], G_Loss[0.133], D_Real_Loss[0.735], D_Fake_Loss[0.548]
Progress[ 72%], ETA[  54m], Batch [18470], G_Loss[0.206], D_Real_Loss[0.353], D_Fake_Loss[0.221]
Progress[ 72%], ETA[  54m], Batch [18480], G_Loss[0.089], D_Real_Loss[0.227], D_Fake_Loss[1.001]
Progress[ 72%], ETA[  54m], Batch [18490], G_Loss[0.153], D_Real_Loss[0.267], D_Fake_Loss[0.423]
Progress[ 72%], ETA[  54m], Batch [18500], G_Loss[0.154], D_Real_Loss[0.560], D_Fake_Loss[0.387]
Progress[ 72%], ETA[  54m], Batch [18510], G_Loss[0.163], D_Real_Loss[1.009], D_Fake_Loss[0.356]
Progress[ 72%], ETA[  54m], Batch [18520], G_Loss[0.160], D_Real_Loss[1.086], D_Fake_Loss[0.372]
Progress[ 72%], ETA[  54m], Batch [18530], G_Loss[0.274], D_Real_Loss[0.685], D_Fake_Loss[0.106]
Progress[ 72%], ETA[  54m], Batch [18540], G_Loss[0.223], D_Real_Loss[1.228], D_Fake_Loss[0.181]
Progress[ 72%], ETA[  54m], Batch [18550], G_Loss[0.143], D_Real_Loss[0.498], D_Fake_Loss[0.445]
Progress[ 72%], ETA[  54m], Batch [18560], G_Loss[0.157], D_Real_Loss[0.704], D_Fake_Loss[0.392]
Progress[ 72%], ETA[  54m], Batch [18570], G_Loss[0.113], D_Real_Loss[0.149], D_Fake_Loss[0.622]
Progress[ 72%], ETA[  54m], Batch [18580], G_Loss[0.237], D_Real_Loss[0.829], D_Fake_Loss[0.174]
Progress[ 72%], ETA[  54m], Batch [18590], G_Loss[0.279], D_Real_Loss[0.786], D_Fake_Loss[0.103]
Progress[ 72%], ETA[  54m], Batch [18600], G_Loss[0.177], D_Real_Loss[0.094], D_Fake_Loss[0.319]
    Saved train/batch018600_out.png
Progress[ 73%], ETA[  53m], Batch [18610], G_Loss[0.212], D_Real_Loss[0.341], D_Fake_Loss[0.199]
Progress[ 73%], ETA[  53m], Batch [18620], G_Loss[0.207], D_Real_Loss[0.531], D_Fake_Loss[0.225]
Progress[ 73%], ETA[  53m], Batch [18630], G_Loss[0.223], D_Real_Loss[0.469], D_Fake_Loss[0.195]
Progress[ 73%], ETA[  53m], Batch [18640], G_Loss[0.127], D_Real_Loss[0.338], D_Fake_Loss[0.538]
Progress[ 73%], ETA[  53m], Batch [18650], G_Loss[0.178], D_Real_Loss[0.578], D_Fake_Loss[0.296]
Progress[ 73%], ETA[  53m], Batch [18660], G_Loss[0.141], D_Real_Loss[0.168], D_Fake_Loss[0.471]
Progress[ 73%], ETA[  53m], Batch [18670], G_Loss[0.131], D_Real_Loss[0.185], D_Fake_Loss[0.510]
Progress[ 73%], ETA[  53m], Batch [18680], G_Loss[0.128], D_Real_Loss[0.289], D_Fake_Loss[0.600]
Progress[ 73%], ETA[  53m], Batch [18690], G_Loss[0.103], D_Real_Loss[0.148], D_Fake_Loss[0.919]
Progress[ 73%], ETA[  53m], Batch [18700], G_Loss[0.278], D_Real_Loss[0.393], D_Fake_Loss[0.104]
Progress[ 73%], ETA[  53m], Batch [18710], G_Loss[0.168], D_Real_Loss[0.410], D_Fake_Loss[0.380]
Progress[ 73%], ETA[  53m], Batch [18720], G_Loss[0.166], D_Real_Loss[0.309], D_Fake_Loss[0.373]
Progress[ 73%], ETA[  53m], Batch [18730], G_Loss[0.173], D_Real_Loss[0.470], D_Fake_Loss[0.343]
Progress[ 73%], ETA[  53m], Batch [18740], G_Loss[0.154], D_Real_Loss[0.349], D_Fake_Loss[0.408]
Progress[ 73%], ETA[  53m], Batch [18750], G_Loss[0.113], D_Real_Loss[0.403], D_Fake_Loss[0.667]
Progress[ 73%], ETA[  53m], Batch [18760], G_Loss[0.224], D_Real_Loss[0.431], D_Fake_Loss[0.205]
Progress[ 73%], ETA[  52m], Batch [18770], G_Loss[0.094], D_Real_Loss[0.263], D_Fake_Loss[0.870]
Progress[ 73%], ETA[  52m], Batch [18780], G_Loss[0.143], D_Real_Loss[0.974], D_Fake_Loss[0.442]
Progress[ 73%], ETA[  52m], Batch [18790], G_Loss[0.132], D_Real_Loss[0.642], D_Fake_Loss[0.573]
Progress[ 73%], ETA[  52m], Batch [18800], G_Loss[0.169], D_Real_Loss[0.171], D_Fake_Loss[0.349]
    Saved train/batch018800_out.png
Progress[ 73%], ETA[  52m], Batch [18810], G_Loss[0.108], D_Real_Loss[0.129], D_Fake_Loss[0.821]
Progress[ 73%], ETA[  52m], Batch [18820], G_Loss[0.247], D_Real_Loss[0.576], D_Fake_Loss[0.155]
Progress[ 73%], ETA[  52m], Batch [18830], G_Loss[0.179], D_Real_Loss[0.919], D_Fake_Loss[0.319]
Progress[ 73%], ETA[  52m], Batch [18840], G_Loss[0.137], D_Real_Loss[0.299], D_Fake_Loss[0.496]
Progress[ 73%], ETA[  52m], Batch [18850], G_Loss[0.155], D_Real_Loss[0.281], D_Fake_Loss[0.412]
Progress[ 73%], ETA[  52m], Batch [18860], G_Loss[0.146], D_Real_Loss[0.350], D_Fake_Loss[0.482]
Progress[ 73%], ETA[  52m], Batch [18870], G_Loss[0.227], D_Real_Loss[0.350], D_Fake_Loss[0.191]
Progress[ 73%], ETA[  52m], Batch [18880], G_Loss[0.159], D_Real_Loss[0.289], D_Fake_Loss[0.426]
Progress[ 73%], ETA[  52m], Batch [18890], G_Loss[0.215], D_Real_Loss[0.744], D_Fake_Loss[0.200]
Progress[ 73%], ETA[  52m], Batch [18900], G_Loss[0.174], D_Real_Loss[0.427], D_Fake_Loss[0.319]
Progress[ 74%], ETA[  52m], Batch [18910], G_Loss[0.136], D_Real_Loss[0.617], D_Fake_Loss[0.494]
Progress[ 74%], ETA[  51m], Batch [18920], G_Loss[0.206], D_Real_Loss[0.882], D_Fake_Loss[0.221]
Progress[ 74%], ETA[  51m], Batch [18930], G_Loss[0.195], D_Real_Loss[0.833], D_Fake_Loss[0.276]
Progress[ 74%], ETA[  51m], Batch [18940], G_Loss[0.137], D_Real_Loss[0.601], D_Fake_Loss[0.525]
Progress[ 74%], ETA[  51m], Batch [18950], G_Loss[0.149], D_Real_Loss[0.265], D_Fake_Loss[0.509]
Progress[ 74%], ETA[  51m], Batch [18960], G_Loss[0.137], D_Real_Loss[0.132], D_Fake_Loss[0.512]
Progress[ 74%], ETA[  51m], Batch [18970], G_Loss[0.123], D_Real_Loss[0.351], D_Fake_Loss[0.634]
Progress[ 74%], ETA[  51m], Batch [18980], G_Loss[0.203], D_Real_Loss[0.873], D_Fake_Loss[0.262]
Progress[ 74%], ETA[  51m], Batch [18990], G_Loss[0.173], D_Real_Loss[0.182], D_Fake_Loss[0.323]
Progress[ 74%], ETA[  51m], Batch [19000], G_Loss[0.240], D_Real_Loss[0.507], D_Fake_Loss[0.155]
    Saved train/batch019000_out.png
Progress[ 74%], ETA[  51m], Batch [19010], G_Loss[0.120], D_Real_Loss[0.130], D_Fake_Loss[0.777]
Progress[ 74%], ETA[  51m], Batch [19020], G_Loss[0.215], D_Real_Loss[0.479], D_Fake_Loss[0.229]
Progress[ 74%], ETA[  51m], Batch [19030], G_Loss[0.091], D_Real_Loss[0.360], D_Fake_Loss[0.956]
Progress[ 74%], ETA[  51m], Batch [19040], G_Loss[0.175], D_Real_Loss[0.448], D_Fake_Loss[0.310]
Progress[ 74%], ETA[  51m], Batch [19050], G_Loss[0.114], D_Real_Loss[0.425], D_Fake_Loss[0.777]
Progress[ 74%], ETA[  51m], Batch [19060], G_Loss[0.230], D_Real_Loss[0.510], D_Fake_Loss[0.174]
Progress[ 74%], ETA[  50m], Batch [19070], G_Loss[0.114], D_Real_Loss[0.133], D_Fake_Loss[0.656]
Progress[ 74%], ETA[  50m], Batch [19080], G_Loss[0.083], D_Real_Loss[0.381], D_Fake_Loss[1.090]
Progress[ 74%], ETA[  50m], Batch [19090], G_Loss[0.248], D_Real_Loss[0.710], D_Fake_Loss[0.138]
Progress[ 74%], ETA[  50m], Batch [19100], G_Loss[0.165], D_Real_Loss[0.260], D_Fake_Loss[0.392]
Progress[ 74%], ETA[  50m], Batch [19110], G_Loss[0.148], D_Real_Loss[0.545], D_Fake_Loss[0.443]
Progress[ 74%], ETA[  50m], Batch [19120], G_Loss[0.224], D_Real_Loss[0.745], D_Fake_Loss[0.205]
Progress[ 74%], ETA[  50m], Batch [19130], G_Loss[0.225], D_Real_Loss[0.306], D_Fake_Loss[0.186]
Progress[ 74%], ETA[  50m], Batch [19140], G_Loss[0.157], D_Real_Loss[0.486], D_Fake_Loss[0.377]
Progress[ 74%], ETA[  50m], Batch [19150], G_Loss[0.241], D_Real_Loss[0.985], D_Fake_Loss[0.149]
Progress[ 74%], ETA[  50m], Batch [19160], G_Loss[0.196], D_Real_Loss[0.556], D_Fake_Loss[0.285]
Progress[ 74%], ETA[  50m], Batch [19170], G_Loss[0.147], D_Real_Loss[0.781], D_Fake_Loss[0.439]
Progress[ 74%], ETA[  50m], Batch [19180], G_Loss[0.159], D_Real_Loss[0.218], D_Fake_Loss[0.453]
Progress[ 74%], ETA[  50m], Batch [19190], G_Loss[0.233], D_Real_Loss[0.848], D_Fake_Loss[0.164]
Progress[ 74%], ETA[  50m], Batch [19200], G_Loss[0.081], D_Real_Loss[0.510], D_Fake_Loss[1.012]
    Saved train/batch019200_out.png
Progress[ 75%], ETA[  50m], Batch [19210], G_Loss[0.089], D_Real_Loss[0.072], D_Fake_Loss[0.970]
Progress[ 75%], ETA[  49m], Batch [19220], G_Loss[0.139], D_Real_Loss[0.122], D_Fake_Loss[0.592]
Progress[ 75%], ETA[  49m], Batch [19230], G_Loss[0.231], D_Real_Loss[0.458], D_Fake_Loss[0.184]
Progress[ 75%], ETA[  49m], Batch [19240], G_Loss[0.144], D_Real_Loss[0.466], D_Fake_Loss[0.453]
Progress[ 75%], ETA[  49m], Batch [19250], G_Loss[0.093], D_Real_Loss[0.168], D_Fake_Loss[1.042]
Progress[ 75%], ETA[  49m], Batch [19260], G_Loss[0.090], D_Real_Loss[0.382], D_Fake_Loss[0.902]
Progress[ 75%], ETA[  49m], Batch [19270], G_Loss[0.168], D_Real_Loss[0.185], D_Fake_Loss[0.328]
Progress[ 75%], ETA[  49m], Batch [19280], G_Loss[0.277], D_Real_Loss[0.918], D_Fake_Loss[0.114]
Progress[ 75%], ETA[  49m], Batch [19290], G_Loss[0.189], D_Real_Loss[0.573], D_Fake_Loss[0.283]
Progress[ 75%], ETA[  49m], Batch [19300], G_Loss[0.166], D_Real_Loss[0.657], D_Fake_Loss[0.368]
Progress[ 75%], ETA[  49m], Batch [19310], G_Loss[0.200], D_Real_Loss[0.200], D_Fake_Loss[0.256]
Progress[ 75%], ETA[  49m], Batch [19320], G_Loss[0.152], D_Real_Loss[0.127], D_Fake_Loss[0.481]
Progress[ 75%], ETA[  49m], Batch [19330], G_Loss[0.132], D_Real_Loss[0.461], D_Fake_Loss[0.562]
Progress[ 75%], ETA[  49m], Batch [19340], G_Loss[0.119], D_Real_Loss[0.256], D_Fake_Loss[0.656]
Progress[ 75%], ETA[  49m], Batch [19350], G_Loss[0.132], D_Real_Loss[0.520], D_Fake_Loss[0.529]
Progress[ 75%], ETA[  49m], Batch [19360], G_Loss[0.138], D_Real_Loss[0.762], D_Fake_Loss[0.654]
Progress[ 75%], ETA[  48m], Batch [19370], G_Loss[0.192], D_Real_Loss[0.585], D_Fake_Loss[0.269]
Progress[ 75%], ETA[  48m], Batch [19380], G_Loss[0.290], D_Real_Loss[0.184], D_Fake_Loss[0.098]
Progress[ 75%], ETA[  48m], Batch [19390], G_Loss[0.135], D_Real_Loss[0.257], D_Fake_Loss[0.558]
Progress[ 75%], ETA[  48m], Batch [19400], G_Loss[0.157], D_Real_Loss[0.470], D_Fake_Loss[0.391]
    Saved train/batch019400_out.png
Progress[ 75%], ETA[  48m], Batch [19410], G_Loss[0.160], D_Real_Loss[0.866], D_Fake_Loss[0.422]
Progress[ 75%], ETA[  48m], Batch [19420], G_Loss[0.119], D_Real_Loss[0.584], D_Fake_Loss[0.683]
Progress[ 75%], ETA[  48m], Batch [19430], G_Loss[0.201], D_Real_Loss[0.708], D_Fake_Loss[0.294]
Progress[ 75%], ETA[  48m], Batch [19440], G_Loss[0.230], D_Real_Loss[0.556], D_Fake_Loss[0.173]
Progress[ 75%], ETA[  48m], Batch [19450], G_Loss[0.246], D_Real_Loss[0.587], D_Fake_Loss[0.154]
Progress[ 75%], ETA[  48m], Batch [19460], G_Loss[0.207], D_Real_Loss[0.288], D_Fake_Loss[0.231]
Progress[ 75%], ETA[  48m], Batch [19470], G_Loss[0.270], D_Real_Loss[0.714], D_Fake_Loss[0.109]
Progress[ 75%], ETA[  48m], Batch [19480], G_Loss[0.196], D_Real_Loss[0.618], D_Fake_Loss[0.279]
Progress[ 75%], ETA[  48m], Batch [19490], G_Loss[0.104], D_Real_Loss[0.260], D_Fake_Loss[0.729]
Progress[ 75%], ETA[  48m], Batch [19500], G_Loss[0.104], D_Real_Loss[0.212], D_Fake_Loss[0.814]
Progress[ 75%], ETA[  48m], Batch [19510], G_Loss[0.068], D_Real_Loss[0.128], D_Fake_Loss[1.419]
Progress[ 76%], ETA[  47m], Batch [19520], G_Loss[0.213], D_Real_Loss[0.265], D_Fake_Loss[0.196]
Progress[ 76%], ETA[  47m], Batch [19530], G_Loss[0.109], D_Real_Loss[0.229], D_Fake_Loss[0.719]
Progress[ 76%], ETA[  47m], Batch [19540], G_Loss[0.138], D_Real_Loss[0.202], D_Fake_Loss[0.523]
Progress[ 76%], ETA[  47m], Batch [19550], G_Loss[0.144], D_Real_Loss[0.712], D_Fake_Loss[0.429]
Progress[ 76%], ETA[  47m], Batch [19560], G_Loss[0.117], D_Real_Loss[0.162], D_Fake_Loss[0.672]
Progress[ 76%], ETA[  47m], Batch [19570], G_Loss[0.148], D_Real_Loss[0.307], D_Fake_Loss[0.414]
Progress[ 76%], ETA[  47m], Batch [19580], G_Loss[0.084], D_Real_Loss[0.197], D_Fake_Loss[1.021]
Progress[ 76%], ETA[  47m], Batch [19590], G_Loss[0.138], D_Real_Loss[0.644], D_Fake_Loss[0.500]
Progress[ 76%], ETA[  47m], Batch [19600], G_Loss[0.160], D_Real_Loss[0.558], D_Fake_Loss[0.413]
    Saved train/batch019600_out.png
Progress[ 76%], ETA[  47m], Batch [19610], G_Loss[0.148], D_Real_Loss[1.390], D_Fake_Loss[0.441]
Progress[ 76%], ETA[  47m], Batch [19620], G_Loss[0.079], D_Real_Loss[0.384], D_Fake_Loss[1.107]
Progress[ 76%], ETA[  47m], Batch [19630], G_Loss[0.211], D_Real_Loss[0.174], D_Fake_Loss[0.215]
Progress[ 76%], ETA[  47m], Batch [19640], G_Loss[0.172], D_Real_Loss[0.271], D_Fake_Loss[0.318]
Progress[ 76%], ETA[  47m], Batch [19650], G_Loss[0.171], D_Real_Loss[0.162], D_Fake_Loss[0.322]
Progress[ 76%], ETA[  47m], Batch [19660], G_Loss[0.112], D_Real_Loss[0.216], D_Fake_Loss[0.749]
Progress[ 76%], ETA[  46m], Batch [19670], G_Loss[0.211], D_Real_Loss[0.839], D_Fake_Loss[0.209]
Progress[ 76%], ETA[  46m], Batch [19680], G_Loss[0.107], D_Real_Loss[0.282], D_Fake_Loss[0.728]
Progress[ 76%], ETA[  46m], Batch [19690], G_Loss[0.187], D_Real_Loss[0.201], D_Fake_Loss[0.290]
Progress[ 76%], ETA[  46m], Batch [19700], G_Loss[0.118], D_Real_Loss[0.096], D_Fake_Loss[0.617]
Progress[ 76%], ETA[  46m], Batch [19710], G_Loss[0.099], D_Real_Loss[0.170], D_Fake_Loss[0.847]
Progress[ 76%], ETA[  46m], Batch [19720], G_Loss[0.182], D_Real_Loss[0.457], D_Fake_Loss[0.282]
Progress[ 76%], ETA[  46m], Batch [19730], G_Loss[0.114], D_Real_Loss[0.063], D_Fake_Loss[0.633]
Progress[ 76%], ETA[  46m], Batch [19740], G_Loss[0.139], D_Real_Loss[0.373], D_Fake_Loss[0.458]
Progress[ 76%], ETA[  46m], Batch [19750], G_Loss[0.236], D_Real_Loss[0.497], D_Fake_Loss[0.168]
Progress[ 76%], ETA[  46m], Batch [19760], G_Loss[0.134], D_Real_Loss[0.591], D_Fake_Loss[0.499]
Progress[ 76%], ETA[  46m], Batch [19770], G_Loss[0.147], D_Real_Loss[0.209], D_Fake_Loss[0.503]
Progress[ 76%], ETA[  46m], Batch [19780], G_Loss[0.140], D_Real_Loss[0.310], D_Fake_Loss[0.445]
Progress[ 76%], ETA[  46m], Batch [19790], G_Loss[0.120], D_Real_Loss[0.287], D_Fake_Loss[0.598]
Progress[ 76%], ETA[  46m], Batch [19800], G_Loss[0.161], D_Real_Loss[0.442], D_Fake_Loss[0.341]
    Saved train/batch019800_out.png
Progress[ 76%], ETA[  46m], Batch [19810], G_Loss[0.130], D_Real_Loss[0.168], D_Fake_Loss[0.578]
Progress[ 77%], ETA[  45m], Batch [19820], G_Loss[0.236], D_Real_Loss[1.070], D_Fake_Loss[0.188]
Progress[ 77%], ETA[  45m], Batch [19830], G_Loss[0.152], D_Real_Loss[0.113], D_Fake_Loss[0.496]
Progress[ 77%], ETA[  45m], Batch [19840], G_Loss[0.126], D_Real_Loss[0.320], D_Fake_Loss[0.575]
Progress[ 77%], ETA[  45m], Batch [19850], G_Loss[0.126], D_Real_Loss[0.284], D_Fake_Loss[0.610]
Progress[ 77%], ETA[  45m], Batch [19860], G_Loss[0.201], D_Real_Loss[0.344], D_Fake_Loss[0.236]
Progress[ 77%], ETA[  45m], Batch [19870], G_Loss[0.149], D_Real_Loss[0.728], D_Fake_Loss[0.446]
Progress[ 77%], ETA[  45m], Batch [19880], G_Loss[0.134], D_Real_Loss[0.380], D_Fake_Loss[0.527]
Progress[ 77%], ETA[  45m], Batch [19890], G_Loss[0.183], D_Real_Loss[0.335], D_Fake_Loss[0.282]
Progress[ 77%], ETA[  45m], Batch [19900], G_Loss[0.110], D_Real_Loss[0.206], D_Fake_Loss[0.761]
Progress[ 77%], ETA[  45m], Batch [19910], G_Loss[0.108], D_Real_Loss[0.384], D_Fake_Loss[0.799]
Progress[ 77%], ETA[  45m], Batch [19920], G_Loss[0.118], D_Real_Loss[0.274], D_Fake_Loss[0.676]
Progress[ 77%], ETA[  45m], Batch [19930], G_Loss[0.130], D_Real_Loss[0.223], D_Fake_Loss[0.546]
Progress[ 77%], ETA[  45m], Batch [19940], G_Loss[0.150], D_Real_Loss[0.641], D_Fake_Loss[0.442]
Progress[ 77%], ETA[  45m], Batch [19950], G_Loss[0.220], D_Real_Loss[0.486], D_Fake_Loss[0.194]
Progress[ 77%], ETA[  45m], Batch [19960], G_Loss[0.101], D_Real_Loss[0.464], D_Fake_Loss[0.841]
Progress[ 77%], ETA[  44m], Batch [19970], G_Loss[0.178], D_Real_Loss[1.350], D_Fake_Loss[0.319]
Progress[ 77%], ETA[  44m], Batch [19980], G_Loss[0.227], D_Real_Loss[0.284], D_Fake_Loss[0.175]
Progress[ 77%], ETA[  44m], Batch [19990], G_Loss[0.136], D_Real_Loss[0.365], D_Fake_Loss[0.529]
Progress[ 77%], ETA[  44m], Batch [20000], G_Loss[0.153], D_Real_Loss[0.226], D_Fake_Loss[0.422]
    Saved train/batch020000_out.png
    Checkpoint saved
Progress[ 77%], ETA[  44m], Batch [20010], G_Loss[0.215], D_Real_Loss[0.274], D_Fake_Loss[0.226]
Progress[ 77%], ETA[  44m], Batch [20020], G_Loss[0.190], D_Real_Loss[0.227], D_Fake_Loss[0.295]
Progress[ 77%], ETA[  44m], Batch [20030], G_Loss[0.265], D_Real_Loss[0.648], D_Fake_Loss[0.116]
Progress[ 77%], ETA[  44m], Batch [20040], G_Loss[0.213], D_Real_Loss[0.376], D_Fake_Loss[0.212]
Progress[ 77%], ETA[  44m], Batch [20050], G_Loss[0.114], D_Real_Loss[0.200], D_Fake_Loss[0.673]
Progress[ 77%], ETA[  44m], Batch [20060], G_Loss[0.184], D_Real_Loss[0.600], D_Fake_Loss[0.288]
Progress[ 77%], ETA[  44m], Batch [20070], G_Loss[0.144], D_Real_Loss[0.365], D_Fake_Loss[0.437]
Progress[ 77%], ETA[  44m], Batch [20080], G_Loss[0.147], D_Real_Loss[0.155], D_Fake_Loss[0.422]
Progress[ 77%], ETA[  44m], Batch [20090], G_Loss[0.290], D_Real_Loss[1.124], D_Fake_Loss[0.100]
Progress[ 77%], ETA[  44m], Batch [20100], G_Loss[0.135], D_Real_Loss[0.519], D_Fake_Loss[0.510]
Progress[ 78%], ETA[  43m], Batch [20110], G_Loss[0.134], D_Real_Loss[0.197], D_Fake_Loss[0.501]
Progress[ 78%], ETA[  43m], Batch [20120], G_Loss[0.131], D_Real_Loss[0.201], D_Fake_Loss[0.545]
Progress[ 78%], ETA[  43m], Batch [20130], G_Loss[0.118], D_Real_Loss[0.091], D_Fake_Loss[0.635]
Progress[ 78%], ETA[  43m], Batch [20140], G_Loss[0.230], D_Real_Loss[0.878], D_Fake_Loss[0.178]
Progress[ 78%], ETA[  43m], Batch [20150], G_Loss[0.160], D_Real_Loss[0.281], D_Fake_Loss[0.355]
Progress[ 78%], ETA[  43m], Batch [20160], G_Loss[0.164], D_Real_Loss[0.167], D_Fake_Loss[0.356]
Progress[ 78%], ETA[  43m], Batch [20170], G_Loss[0.163], D_Real_Loss[0.260], D_Fake_Loss[0.383]
Progress[ 78%], ETA[  43m], Batch [20180], G_Loss[0.102], D_Real_Loss[0.461], D_Fake_Loss[0.863]
Progress[ 78%], ETA[  43m], Batch [20190], G_Loss[0.160], D_Real_Loss[0.099], D_Fake_Loss[0.431]
Progress[ 78%], ETA[  43m], Batch [20200], G_Loss[0.173], D_Real_Loss[0.254], D_Fake_Loss[0.359]
    Saved train/batch020200_out.png
Progress[ 78%], ETA[  43m], Batch [20210], G_Loss[0.127], D_Real_Loss[0.396], D_Fake_Loss[0.557]
Progress[ 78%], ETA[  43m], Batch [20220], G_Loss[0.181], D_Real_Loss[0.518], D_Fake_Loss[0.313]
Progress[ 78%], ETA[  43m], Batch [20230], G_Loss[0.129], D_Real_Loss[0.552], D_Fake_Loss[0.524]
Progress[ 78%], ETA[  43m], Batch [20240], G_Loss[0.149], D_Real_Loss[0.170], D_Fake_Loss[0.466]
Progress[ 78%], ETA[  43m], Batch [20250], G_Loss[0.138], D_Real_Loss[0.470], D_Fake_Loss[0.469]
Progress[ 78%], ETA[  42m], Batch [20260], G_Loss[0.168], D_Real_Loss[0.487], D_Fake_Loss[0.341]
Progress[ 78%], ETA[  42m], Batch [20270], G_Loss[0.091], D_Real_Loss[0.204], D_Fake_Loss[1.280]
Progress[ 78%], ETA[  42m], Batch [20280], G_Loss[0.091], D_Real_Loss[0.587], D_Fake_Loss[0.975]
Progress[ 78%], ETA[  42m], Batch [20290], G_Loss[0.128], D_Real_Loss[0.199], D_Fake_Loss[0.547]
Progress[ 78%], ETA[  42m], Batch [20300], G_Loss[0.157], D_Real_Loss[0.158], D_Fake_Loss[0.434]
Progress[ 78%], ETA[  42m], Batch [20310], G_Loss[0.193], D_Real_Loss[0.308], D_Fake_Loss[0.252]
Progress[ 78%], ETA[  42m], Batch [20320], G_Loss[0.087], D_Real_Loss[0.183], D_Fake_Loss[0.991]
Progress[ 78%], ETA[  42m], Batch [20330], G_Loss[0.187], D_Real_Loss[0.529], D_Fake_Loss[0.279]
Progress[ 78%], ETA[  42m], Batch [20340], G_Loss[0.148], D_Real_Loss[0.469], D_Fake_Loss[0.398]
Progress[ 78%], ETA[  42m], Batch [20350], G_Loss[0.126], D_Real_Loss[0.595], D_Fake_Loss[0.573]
Progress[ 78%], ETA[  42m], Batch [20360], G_Loss[0.134], D_Real_Loss[0.339], D_Fake_Loss[0.483]
Progress[ 78%], ETA[  42m], Batch [20370], G_Loss[0.079], D_Real_Loss[0.145], D_Fake_Loss[1.088]
Progress[ 78%], ETA[  42m], Batch [20380], G_Loss[0.134], D_Real_Loss[0.714], D_Fake_Loss[0.501]
Progress[ 78%], ETA[  42m], Batch [20390], G_Loss[0.197], D_Real_Loss[0.199], D_Fake_Loss[0.248]
Progress[ 78%], ETA[  42m], Batch [20400], G_Loss[0.190], D_Real_Loss[0.385], D_Fake_Loss[0.255]
    Saved train/batch020400_out.png
Progress[ 79%], ETA[  41m], Batch [20410], G_Loss[0.081], D_Real_Loss[0.167], D_Fake_Loss[1.083]
Progress[ 79%], ETA[  41m], Batch [20420], G_Loss[0.177], D_Real_Loss[0.377], D_Fake_Loss[0.284]
Progress[ 79%], ETA[  41m], Batch [20430], G_Loss[0.150], D_Real_Loss[0.290], D_Fake_Loss[0.453]
Progress[ 79%], ETA[  41m], Batch [20440], G_Loss[0.183], D_Real_Loss[0.310], D_Fake_Loss[0.273]
Progress[ 79%], ETA[  41m], Batch [20450], G_Loss[0.178], D_Real_Loss[0.386], D_Fake_Loss[0.311]
Progress[ 79%], ETA[  41m], Batch [20460], G_Loss[0.130], D_Real_Loss[0.604], D_Fake_Loss[0.523]
Progress[ 79%], ETA[  41m], Batch [20470], G_Loss[0.181], D_Real_Loss[0.106], D_Fake_Loss[0.282]
Progress[ 79%], ETA[  41m], Batch [20480], G_Loss[0.212], D_Real_Loss[0.358], D_Fake_Loss[0.248]
Progress[ 79%], ETA[  41m], Batch [20490], G_Loss[0.190], D_Real_Loss[0.215], D_Fake_Loss[0.253]
Progress[ 79%], ETA[  41m], Batch [20500], G_Loss[0.092], D_Real_Loss[0.197], D_Fake_Loss[0.842]
Progress[ 79%], ETA[  41m], Batch [20510], G_Loss[0.128], D_Real_Loss[0.238], D_Fake_Loss[0.554]
Progress[ 79%], ETA[  41m], Batch [20520], G_Loss[0.159], D_Real_Loss[0.174], D_Fake_Loss[0.379]
Progress[ 79%], ETA[  41m], Batch [20530], G_Loss[0.204], D_Real_Loss[0.586], D_Fake_Loss[0.221]
Progress[ 79%], ETA[  41m], Batch [20540], G_Loss[0.172], D_Real_Loss[0.730], D_Fake_Loss[0.320]
Progress[ 79%], ETA[  41m], Batch [20550], G_Loss[0.163], D_Real_Loss[0.327], D_Fake_Loss[0.357]
Progress[ 79%], ETA[  40m], Batch [20560], G_Loss[0.208], D_Real_Loss[0.400], D_Fake_Loss[0.210]
Progress[ 79%], ETA[  40m], Batch [20570], G_Loss[0.098], D_Real_Loss[0.207], D_Fake_Loss[0.830]
Progress[ 79%], ETA[  40m], Batch [20580], G_Loss[0.217], D_Real_Loss[0.690], D_Fake_Loss[0.189]
Progress[ 79%], ETA[  40m], Batch [20590], G_Loss[0.144], D_Real_Loss[0.237], D_Fake_Loss[0.449]
Progress[ 79%], ETA[  40m], Batch [20600], G_Loss[0.125], D_Real_Loss[0.355], D_Fake_Loss[0.568]
    Saved train/batch020600_out.png
Progress[ 79%], ETA[  40m], Batch [20610], G_Loss[0.155], D_Real_Loss[0.681], D_Fake_Loss[0.386]
Progress[ 79%], ETA[  40m], Batch [20620], G_Loss[0.110], D_Real_Loss[0.257], D_Fake_Loss[0.707]
Progress[ 79%], ETA[  40m], Batch [20630], G_Loss[0.159], D_Real_Loss[0.360], D_Fake_Loss[0.405]
Progress[ 79%], ETA[  40m], Batch [20640], G_Loss[0.149], D_Real_Loss[0.181], D_Fake_Loss[0.420]
Progress[ 79%], ETA[  40m], Batch [20650], G_Loss[0.168], D_Real_Loss[0.312], D_Fake_Loss[0.344]
Progress[ 79%], ETA[  40m], Batch [20660], G_Loss[0.106], D_Real_Loss[0.205], D_Fake_Loss[0.747]
Progress[ 79%], ETA[  40m], Batch [20670], G_Loss[0.134], D_Real_Loss[0.249], D_Fake_Loss[0.479]
Progress[ 79%], ETA[  40m], Batch [20680], G_Loss[0.221], D_Real_Loss[0.429], D_Fake_Loss[0.212]
Progress[ 79%], ETA[  40m], Batch [20690], G_Loss[0.120], D_Real_Loss[0.527], D_Fake_Loss[0.669]
Progress[ 79%], ETA[  40m], Batch [20700], G_Loss[0.127], D_Real_Loss[0.176], D_Fake_Loss[0.593]
Progress[ 80%], ETA[  39m], Batch [20710], G_Loss[0.178], D_Real_Loss[0.279], D_Fake_Loss[0.328]
Progress[ 80%], ETA[  39m], Batch [20720], G_Loss[0.108], D_Real_Loss[0.243], D_Fake_Loss[0.745]
Progress[ 80%], ETA[  39m], Batch [20730], G_Loss[0.186], D_Real_Loss[0.422], D_Fake_Loss[0.303]
Progress[ 80%], ETA[  39m], Batch [20740], G_Loss[0.137], D_Real_Loss[0.682], D_Fake_Loss[0.513]
Progress[ 80%], ETA[  39m], Batch [20750], G_Loss[0.161], D_Real_Loss[0.929], D_Fake_Loss[0.387]
Progress[ 80%], ETA[  39m], Batch [20760], G_Loss[0.236], D_Real_Loss[0.622], D_Fake_Loss[0.156]
Progress[ 80%], ETA[  39m], Batch [20770], G_Loss[0.202], D_Real_Loss[0.373], D_Fake_Loss[0.239]
Progress[ 80%], ETA[  39m], Batch [20780], G_Loss[0.175], D_Real_Loss[0.690], D_Fake_Loss[0.336]
Progress[ 80%], ETA[  39m], Batch [20790], G_Loss[0.143], D_Real_Loss[0.541], D_Fake_Loss[0.467]
Progress[ 80%], ETA[  39m], Batch [20800], G_Loss[0.194], D_Real_Loss[0.710], D_Fake_Loss[0.273]
    Saved train/batch020800_out.png
Progress[ 80%], ETA[  39m], Batch [20810], G_Loss[0.211], D_Real_Loss[0.249], D_Fake_Loss[0.213]
Progress[ 80%], ETA[  39m], Batch [20820], G_Loss[0.122], D_Real_Loss[0.151], D_Fake_Loss[0.633]
Progress[ 80%], ETA[  39m], Batch [20830], G_Loss[0.182], D_Real_Loss[0.249], D_Fake_Loss[0.295]
Progress[ 80%], ETA[  39m], Batch [20840], G_Loss[0.127], D_Real_Loss[0.442], D_Fake_Loss[0.578]
Progress[ 80%], ETA[  39m], Batch [20850], G_Loss[0.258], D_Real_Loss[0.391], D_Fake_Loss[0.132]
Progress[ 80%], ETA[  38m], Batch [20860], G_Loss[0.177], D_Real_Loss[0.107], D_Fake_Loss[0.417]
Progress[ 80%], ETA[  38m], Batch [20870], G_Loss[0.181], D_Real_Loss[0.194], D_Fake_Loss[0.304]
Progress[ 80%], ETA[  38m], Batch [20880], G_Loss[0.200], D_Real_Loss[0.304], D_Fake_Loss[0.250]
Progress[ 80%], ETA[  38m], Batch [20890], G_Loss[0.194], D_Real_Loss[0.191], D_Fake_Loss[0.257]
Progress[ 80%], ETA[  38m], Batch [20900], G_Loss[0.127], D_Real_Loss[0.934], D_Fake_Loss[0.563]
Progress[ 80%], ETA[  38m], Batch [20910], G_Loss[0.217], D_Real_Loss[0.397], D_Fake_Loss[0.212]
Progress[ 80%], ETA[  38m], Batch [20920], G_Loss[0.319], D_Real_Loss[1.372], D_Fake_Loss[0.075]
Progress[ 80%], ETA[  38m], Batch [20930], G_Loss[0.191], D_Real_Loss[0.676], D_Fake_Loss[0.285]
Progress[ 80%], ETA[  38m], Batch [20940], G_Loss[0.095], D_Real_Loss[0.333], D_Fake_Loss[0.859]
Progress[ 80%], ETA[  38m], Batch [20950], G_Loss[0.107], D_Real_Loss[0.436], D_Fake_Loss[0.875]
Progress[ 80%], ETA[  38m], Batch [20960], G_Loss[0.103], D_Real_Loss[0.173], D_Fake_Loss[0.827]
Progress[ 80%], ETA[  38m], Batch [20970], G_Loss[0.111], D_Real_Loss[0.420], D_Fake_Loss[0.771]
Progress[ 80%], ETA[  38m], Batch [20980], G_Loss[0.154], D_Real_Loss[0.532], D_Fake_Loss[0.413]
Progress[ 80%], ETA[  38m], Batch [20990], G_Loss[0.155], D_Real_Loss[0.591], D_Fake_Loss[0.428]
Progress[ 80%], ETA[  38m], Batch [21000], G_Loss[0.172], D_Real_Loss[0.469], D_Fake_Loss[0.373]
    Saved train/batch021000_out.png
Progress[ 81%], ETA[  37m], Batch [21010], G_Loss[0.133], D_Real_Loss[0.179], D_Fake_Loss[0.593]
Progress[ 81%], ETA[  37m], Batch [21020], G_Loss[0.236], D_Real_Loss[1.000], D_Fake_Loss[0.167]
Progress[ 81%], ETA[  37m], Batch [21030], G_Loss[0.204], D_Real_Loss[0.386], D_Fake_Loss[0.239]
Progress[ 81%], ETA[  37m], Batch [21040], G_Loss[0.133], D_Real_Loss[0.275], D_Fake_Loss[0.622]
Progress[ 81%], ETA[  37m], Batch [21050], G_Loss[0.215], D_Real_Loss[0.587], D_Fake_Loss[0.247]
Progress[ 81%], ETA[  37m], Batch [21060], G_Loss[0.116], D_Real_Loss[0.103], D_Fake_Loss[0.747]
Progress[ 81%], ETA[  37m], Batch [21070], G_Loss[0.197], D_Real_Loss[0.368], D_Fake_Loss[0.277]
Progress[ 81%], ETA[  37m], Batch [21080], G_Loss[0.170], D_Real_Loss[0.228], D_Fake_Loss[0.365]
Progress[ 81%], ETA[  37m], Batch [21090], G_Loss[0.135], D_Real_Loss[0.158], D_Fake_Loss[0.566]
Progress[ 81%], ETA[  37m], Batch [21100], G_Loss[0.148], D_Real_Loss[0.389], D_Fake_Loss[0.462]
Progress[ 81%], ETA[  37m], Batch [21110], G_Loss[0.192], D_Real_Loss[0.186], D_Fake_Loss[0.271]
Progress[ 81%], ETA[  37m], Batch [21120], G_Loss[0.104], D_Real_Loss[0.181], D_Fake_Loss[0.939]
Progress[ 81%], ETA[  37m], Batch [21130], G_Loss[0.162], D_Real_Loss[0.528], D_Fake_Loss[0.375]
Progress[ 81%], ETA[  37m], Batch [21140], G_Loss[0.135], D_Real_Loss[0.396], D_Fake_Loss[0.575]
Progress[ 81%], ETA[  37m], Batch [21150], G_Loss[0.154], D_Real_Loss[0.812], D_Fake_Loss[0.427]
Progress[ 81%], ETA[  36m], Batch [21160], G_Loss[0.180], D_Real_Loss[0.363], D_Fake_Loss[0.349]
Progress[ 81%], ETA[  36m], Batch [21170], G_Loss[0.226], D_Real_Loss[0.263], D_Fake_Loss[0.220]
Progress[ 81%], ETA[  36m], Batch [21180], G_Loss[0.133], D_Real_Loss[0.514], D_Fake_Loss[0.539]
Progress[ 81%], ETA[  36m], Batch [21190], G_Loss[0.125], D_Real_Loss[0.169], D_Fake_Loss[0.625]
Progress[ 81%], ETA[  36m], Batch [21200], G_Loss[0.134], D_Real_Loss[0.441], D_Fake_Loss[0.579]
    Saved train/batch021200_out.png
Progress[ 81%], ETA[  36m], Batch [21210], G_Loss[0.178], D_Real_Loss[0.256], D_Fake_Loss[0.301]
Progress[ 81%], ETA[  36m], Batch [21220], G_Loss[0.134], D_Real_Loss[0.214], D_Fake_Loss[0.542]
Progress[ 81%], ETA[  36m], Batch [21230], G_Loss[0.275], D_Real_Loss[1.169], D_Fake_Loss[0.109]
Progress[ 81%], ETA[  36m], Batch [21240], G_Loss[0.093], D_Real_Loss[0.149], D_Fake_Loss[0.955]
Progress[ 81%], ETA[  36m], Batch [21250], G_Loss[0.157], D_Real_Loss[0.913], D_Fake_Loss[0.396]
Progress[ 81%], ETA[  36m], Batch [21260], G_Loss[0.145], D_Real_Loss[0.837], D_Fake_Loss[0.458]
Progress[ 81%], ETA[  36m], Batch [21270], G_Loss[0.150], D_Real_Loss[0.533], D_Fake_Loss[0.426]
Progress[ 81%], ETA[  36m], Batch [21280], G_Loss[0.136], D_Real_Loss[0.545], D_Fake_Loss[0.504]
Progress[ 81%], ETA[  36m], Batch [21290], G_Loss[0.152], D_Real_Loss[0.327], D_Fake_Loss[0.484]
Progress[ 81%], ETA[  36m], Batch [21300], G_Loss[0.119], D_Real_Loss[0.275], D_Fake_Loss[0.667]
Progress[ 82%], ETA[  35m], Batch [21310], G_Loss[0.178], D_Real_Loss[0.425], D_Fake_Loss[0.320]
Progress[ 82%], ETA[  35m], Batch [21320], G_Loss[0.124], D_Real_Loss[0.310], D_Fake_Loss[0.568]
Progress[ 82%], ETA[  35m], Batch [21330], G_Loss[0.188], D_Real_Loss[0.640], D_Fake_Loss[0.301]
Progress[ 82%], ETA[  35m], Batch [21340], G_Loss[0.190], D_Real_Loss[1.079], D_Fake_Loss[0.271]
Progress[ 82%], ETA[  35m], Batch [21350], G_Loss[0.177], D_Real_Loss[0.409], D_Fake_Loss[0.319]
Progress[ 82%], ETA[  35m], Batch [21360], G_Loss[0.252], D_Real_Loss[0.201], D_Fake_Loss[0.136]
Progress[ 82%], ETA[  35m], Batch [21370], G_Loss[0.145], D_Real_Loss[0.241], D_Fake_Loss[0.511]
Progress[ 82%], ETA[  35m], Batch [21380], G_Loss[0.174], D_Real_Loss[0.478], D_Fake_Loss[0.320]
Progress[ 82%], ETA[  35m], Batch [21390], G_Loss[0.126], D_Real_Loss[0.914], D_Fake_Loss[0.579]
Progress[ 82%], ETA[  35m], Batch [21400], G_Loss[0.222], D_Real_Loss[0.246], D_Fake_Loss[0.192]
    Saved train/batch021400_out.png
Progress[ 82%], ETA[  35m], Batch [21410], G_Loss[0.119], D_Real_Loss[0.361], D_Fake_Loss[0.649]
Progress[ 82%], ETA[  35m], Batch [21420], G_Loss[0.165], D_Real_Loss[0.103], D_Fake_Loss[0.339]
Progress[ 82%], ETA[  35m], Batch [21430], G_Loss[0.072], D_Real_Loss[0.102], D_Fake_Loss[1.432]
Progress[ 82%], ETA[  35m], Batch [21440], G_Loss[0.127], D_Real_Loss[0.890], D_Fake_Loss[0.594]
Progress[ 82%], ETA[  35m], Batch [21450], G_Loss[0.127], D_Real_Loss[0.380], D_Fake_Loss[0.545]
Progress[ 82%], ETA[  34m], Batch [21460], G_Loss[0.210], D_Real_Loss[1.146], D_Fake_Loss[0.208]
Progress[ 82%], ETA[  34m], Batch [21470], G_Loss[0.209], D_Real_Loss[0.451], D_Fake_Loss[0.209]
Progress[ 82%], ETA[  34m], Batch [21480], G_Loss[0.166], D_Real_Loss[0.426], D_Fake_Loss[0.362]
Progress[ 82%], ETA[  34m], Batch [21490], G_Loss[0.123], D_Real_Loss[0.128], D_Fake_Loss[0.592]
Progress[ 82%], ETA[  34m], Batch [21500], G_Loss[0.171], D_Real_Loss[0.585], D_Fake_Loss[0.328]
Progress[ 82%], ETA[  34m], Batch [21510], G_Loss[0.161], D_Real_Loss[0.945], D_Fake_Loss[0.395]
Progress[ 82%], ETA[  34m], Batch [21520], G_Loss[0.085], D_Real_Loss[0.236], D_Fake_Loss[0.969]
Progress[ 82%], ETA[  34m], Batch [21530], G_Loss[0.219], D_Real_Loss[0.544], D_Fake_Loss[0.207]
Progress[ 82%], ETA[  34m], Batch [21540], G_Loss[0.166], D_Real_Loss[0.286], D_Fake_Loss[0.331]
Progress[ 82%], ETA[  34m], Batch [21550], G_Loss[0.203], D_Real_Loss[0.379], D_Fake_Loss[0.259]
Progress[ 82%], ETA[  34m], Batch [21560], G_Loss[0.188], D_Real_Loss[0.421], D_Fake_Loss[0.254]
Progress[ 82%], ETA[  34m], Batch [21570], G_Loss[0.239], D_Real_Loss[0.716], D_Fake_Loss[0.161]
Progress[ 82%], ETA[  34m], Batch [21580], G_Loss[0.114], D_Real_Loss[0.412], D_Fake_Loss[0.714]
Progress[ 82%], ETA[  34m], Batch [21590], G_Loss[0.102], D_Real_Loss[0.405], D_Fake_Loss[0.749]
Progress[ 82%], ETA[  34m], Batch [21600], G_Loss[0.249], D_Real_Loss[0.284], D_Fake_Loss[0.142]
    Saved train/batch021600_out.png
Progress[ 83%], ETA[  33m], Batch [21610], G_Loss[0.114], D_Real_Loss[0.255], D_Fake_Loss[0.667]
Progress[ 83%], ETA[  33m], Batch [21620], G_Loss[0.156], D_Real_Loss[0.227], D_Fake_Loss[0.385]
Progress[ 83%], ETA[  33m], Batch [21630], G_Loss[0.148], D_Real_Loss[0.281], D_Fake_Loss[0.439]
Progress[ 83%], ETA[  33m], Batch [21640], G_Loss[0.165], D_Real_Loss[0.868], D_Fake_Loss[0.363]
Progress[ 83%], ETA[  33m], Batch [21650], G_Loss[0.130], D_Real_Loss[0.588], D_Fake_Loss[0.529]
Progress[ 83%], ETA[  33m], Batch [21660], G_Loss[0.150], D_Real_Loss[0.323], D_Fake_Loss[0.440]
Progress[ 83%], ETA[  33m], Batch [21670], G_Loss[0.190], D_Real_Loss[0.460], D_Fake_Loss[0.277]
Progress[ 83%], ETA[  33m], Batch [21680], G_Loss[0.098], D_Real_Loss[0.251], D_Fake_Loss[0.816]
Progress[ 83%], ETA[  33m], Batch [21690], G_Loss[0.175], D_Real_Loss[0.399], D_Fake_Loss[0.309]
Progress[ 83%], ETA[  33m], Batch [21700], G_Loss[0.140], D_Real_Loss[0.431], D_Fake_Loss[0.477]
Progress[ 83%], ETA[  33m], Batch [21710], G_Loss[0.094], D_Real_Loss[0.367], D_Fake_Loss[0.901]
Progress[ 83%], ETA[  33m], Batch [21720], G_Loss[0.161], D_Real_Loss[0.514], D_Fake_Loss[0.435]
Progress[ 83%], ETA[  33m], Batch [21730], G_Loss[0.143], D_Real_Loss[0.329], D_Fake_Loss[0.450]
Progress[ 83%], ETA[  33m], Batch [21740], G_Loss[0.136], D_Real_Loss[0.984], D_Fake_Loss[0.488]
Progress[ 83%], ETA[  33m], Batch [21750], G_Loss[0.111], D_Real_Loss[0.229], D_Fake_Loss[0.648]
Progress[ 83%], ETA[  32m], Batch [21760], G_Loss[0.205], D_Real_Loss[0.241], D_Fake_Loss[0.213]
Progress[ 83%], ETA[  32m], Batch [21770], G_Loss[0.107], D_Real_Loss[0.341], D_Fake_Loss[0.800]
Progress[ 83%], ETA[  32m], Batch [21780], G_Loss[0.163], D_Real_Loss[0.855], D_Fake_Loss[0.382]
Progress[ 83%], ETA[  32m], Batch [21790], G_Loss[0.180], D_Real_Loss[0.317], D_Fake_Loss[0.293]
Progress[ 83%], ETA[  32m], Batch [21800], G_Loss[0.123], D_Real_Loss[0.079], D_Fake_Loss[0.572]
    Saved train/batch021800_out.png
Progress[ 83%], ETA[  32m], Batch [21810], G_Loss[0.106], D_Real_Loss[0.405], D_Fake_Loss[0.755]
Progress[ 83%], ETA[  32m], Batch [21820], G_Loss[0.183], D_Real_Loss[0.534], D_Fake_Loss[0.284]
Progress[ 83%], ETA[  32m], Batch [21830], G_Loss[0.090], D_Real_Loss[0.267], D_Fake_Loss[0.911]
Progress[ 83%], ETA[  32m], Batch [21840], G_Loss[0.184], D_Real_Loss[0.545], D_Fake_Loss[0.283]
Progress[ 83%], ETA[  32m], Batch [21850], G_Loss[0.102], D_Real_Loss[0.136], D_Fake_Loss[0.755]
Progress[ 83%], ETA[  32m], Batch [21860], G_Loss[0.171], D_Real_Loss[0.463], D_Fake_Loss[0.357]
Progress[ 83%], ETA[  32m], Batch [21870], G_Loss[0.234], D_Real_Loss[0.420], D_Fake_Loss[0.166]
Progress[ 83%], ETA[  32m], Batch [21880], G_Loss[0.131], D_Real_Loss[0.118], D_Fake_Loss[0.513]
Progress[ 83%], ETA[  32m], Batch [21890], G_Loss[0.116], D_Real_Loss[0.674], D_Fake_Loss[0.604]
Progress[ 83%], ETA[  32m], Batch [21900], G_Loss[0.145], D_Real_Loss[0.537], D_Fake_Loss[0.423]
Progress[ 84%], ETA[  31m], Batch [21910], G_Loss[0.132], D_Real_Loss[0.179], D_Fake_Loss[0.528]
Progress[ 84%], ETA[  31m], Batch [21920], G_Loss[0.158], D_Real_Loss[0.199], D_Fake_Loss[0.359]
Progress[ 84%], ETA[  31m], Batch [21930], G_Loss[0.210], D_Real_Loss[0.348], D_Fake_Loss[0.224]
Progress[ 84%], ETA[  31m], Batch [21940], G_Loss[0.127], D_Real_Loss[0.402], D_Fake_Loss[0.523]
Progress[ 84%], ETA[  31m], Batch [21950], G_Loss[0.194], D_Real_Loss[0.386], D_Fake_Loss[0.308]
Progress[ 84%], ETA[  31m], Batch [21960], G_Loss[0.132], D_Real_Loss[0.094], D_Fake_Loss[0.546]
Progress[ 84%], ETA[  31m], Batch [21970], G_Loss[0.208], D_Real_Loss[0.488], D_Fake_Loss[0.224]
Progress[ 84%], ETA[  31m], Batch [21980], G_Loss[0.159], D_Real_Loss[1.004], D_Fake_Loss[0.374]
Progress[ 84%], ETA[  31m], Batch [21990], G_Loss[0.170], D_Real_Loss[0.151], D_Fake_Loss[0.413]
Progress[ 84%], ETA[  31m], Batch [22000], G_Loss[0.087], D_Real_Loss[0.129], D_Fake_Loss[1.020]
    Saved train/batch022000_out.png
Progress[ 84%], ETA[  31m], Batch [22010], G_Loss[0.301], D_Real_Loss[0.482], D_Fake_Loss[0.080]
Progress[ 84%], ETA[  31m], Batch [22020], G_Loss[0.159], D_Real_Loss[0.325], D_Fake_Loss[0.386]
Progress[ 84%], ETA[  31m], Batch [22030], G_Loss[0.241], D_Real_Loss[0.264], D_Fake_Loss[0.141]
Progress[ 84%], ETA[  31m], Batch [22040], G_Loss[0.190], D_Real_Loss[0.279], D_Fake_Loss[0.247]
Progress[ 84%], ETA[  31m], Batch [22050], G_Loss[0.194], D_Real_Loss[0.242], D_Fake_Loss[0.276]
Progress[ 84%], ETA[  30m], Batch [22060], G_Loss[0.120], D_Real_Loss[0.035], D_Fake_Loss[0.636]
Progress[ 84%], ETA[  30m], Batch [22070], G_Loss[0.157], D_Real_Loss[0.214], D_Fake_Loss[0.399]
Progress[ 84%], ETA[  30m], Batch [22080], G_Loss[0.125], D_Real_Loss[0.299], D_Fake_Loss[0.595]
Progress[ 84%], ETA[  30m], Batch [22090], G_Loss[0.259], D_Real_Loss[0.996], D_Fake_Loss[0.129]
Progress[ 84%], ETA[  30m], Batch [22100], G_Loss[0.179], D_Real_Loss[0.120], D_Fake_Loss[0.331]
Progress[ 84%], ETA[  30m], Batch [22110], G_Loss[0.171], D_Real_Loss[0.556], D_Fake_Loss[0.324]
Progress[ 84%], ETA[  30m], Batch [22120], G_Loss[0.192], D_Real_Loss[0.611], D_Fake_Loss[0.252]
Progress[ 84%], ETA[  30m], Batch [22130], G_Loss[0.113], D_Real_Loss[0.200], D_Fake_Loss[0.669]
Progress[ 84%], ETA[  30m], Batch [22140], G_Loss[0.112], D_Real_Loss[0.418], D_Fake_Loss[0.693]
Progress[ 84%], ETA[  30m], Batch [22150], G_Loss[0.164], D_Real_Loss[0.853], D_Fake_Loss[0.355]
Progress[ 84%], ETA[  30m], Batch [22160], G_Loss[0.142], D_Real_Loss[0.384], D_Fake_Loss[0.497]
Progress[ 84%], ETA[  30m], Batch [22170], G_Loss[0.206], D_Real_Loss[0.596], D_Fake_Loss[0.223]
Progress[ 84%], ETA[  30m], Batch [22180], G_Loss[0.122], D_Real_Loss[0.345], D_Fake_Loss[0.625]
Progress[ 84%], ETA[  30m], Batch [22190], G_Loss[0.216], D_Real_Loss[0.288], D_Fake_Loss[0.193]
Progress[ 84%], ETA[  30m], Batch [22200], G_Loss[0.182], D_Real_Loss[0.198], D_Fake_Loss[0.289]
    Saved train/batch022200_out.png
Progress[ 85%], ETA[  29m], Batch [22210], G_Loss[0.177], D_Real_Loss[0.227], D_Fake_Loss[0.307]
Progress[ 85%], ETA[  29m], Batch [22220], G_Loss[0.228], D_Real_Loss[0.484], D_Fake_Loss[0.182]
Progress[ 85%], ETA[  29m], Batch [22230], G_Loss[0.101], D_Real_Loss[0.092], D_Fake_Loss[0.796]
Progress[ 85%], ETA[  29m], Batch [22240], G_Loss[0.185], D_Real_Loss[0.417], D_Fake_Loss[0.298]
Progress[ 85%], ETA[  29m], Batch [22250], G_Loss[0.130], D_Real_Loss[0.394], D_Fake_Loss[0.536]
Progress[ 85%], ETA[  29m], Batch [22260], G_Loss[0.300], D_Real_Loss[0.651], D_Fake_Loss[0.084]
Progress[ 85%], ETA[  29m], Batch [22270], G_Loss[0.176], D_Real_Loss[0.115], D_Fake_Loss[0.320]
Progress[ 85%], ETA[  29m], Batch [22280], G_Loss[0.087], D_Real_Loss[0.076], D_Fake_Loss[1.064]
Progress[ 85%], ETA[  29m], Batch [22290], G_Loss[0.108], D_Real_Loss[0.408], D_Fake_Loss[0.683]
Progress[ 85%], ETA[  29m], Batch [22300], G_Loss[0.214], D_Real_Loss[0.466], D_Fake_Loss[0.198]
Progress[ 85%], ETA[  29m], Batch [22310], G_Loss[0.188], D_Real_Loss[0.361], D_Fake_Loss[0.285]
Progress[ 85%], ETA[  29m], Batch [22320], G_Loss[0.149], D_Real_Loss[0.156], D_Fake_Loss[0.443]
Progress[ 85%], ETA[  29m], Batch [22330], G_Loss[0.145], D_Real_Loss[0.307], D_Fake_Loss[0.505]
Progress[ 85%], ETA[  29m], Batch [22340], G_Loss[0.141], D_Real_Loss[0.399], D_Fake_Loss[0.461]
Progress[ 85%], ETA[  29m], Batch [22350], G_Loss[0.200], D_Real_Loss[0.179], D_Fake_Loss[0.237]
Progress[ 85%], ETA[  29m], Batch [22360], G_Loss[0.194], D_Real_Loss[0.567], D_Fake_Loss[0.251]
Progress[ 85%], ETA[  28m], Batch [22370], G_Loss[0.068], D_Real_Loss[0.062], D_Fake_Loss[1.476]
Progress[ 85%], ETA[  28m], Batch [22380], G_Loss[0.182], D_Real_Loss[0.353], D_Fake_Loss[0.274]
Progress[ 85%], ETA[  28m], Batch [22390], G_Loss[0.165], D_Real_Loss[0.128], D_Fake_Loss[0.360]
Progress[ 85%], ETA[  28m], Batch [22400], G_Loss[0.157], D_Real_Loss[1.018], D_Fake_Loss[0.387]
    Saved train/batch022400_out.png
Progress[ 85%], ETA[  28m], Batch [22410], G_Loss[0.245], D_Real_Loss[0.577], D_Fake_Loss[0.162]
Progress[ 85%], ETA[  28m], Batch [22420], G_Loss[0.169], D_Real_Loss[0.315], D_Fake_Loss[0.358]
Progress[ 85%], ETA[  28m], Batch [22430], G_Loss[0.075], D_Real_Loss[0.175], D_Fake_Loss[1.232]
Progress[ 85%], ETA[  28m], Batch [22440], G_Loss[0.076], D_Real_Loss[0.067], D_Fake_Loss[1.212]
Progress[ 85%], ETA[  28m], Batch [22450], G_Loss[0.134], D_Real_Loss[0.119], D_Fake_Loss[0.543]
Progress[ 85%], ETA[  28m], Batch [22460], G_Loss[0.205], D_Real_Loss[0.197], D_Fake_Loss[0.224]
Progress[ 85%], ETA[  28m], Batch [22470], G_Loss[0.222], D_Real_Loss[0.365], D_Fake_Loss[0.181]
Progress[ 85%], ETA[  28m], Batch [22480], G_Loss[0.140], D_Real_Loss[0.226], D_Fake_Loss[0.469]
Progress[ 85%], ETA[  28m], Batch [22490], G_Loss[0.235], D_Real_Loss[0.847], D_Fake_Loss[0.197]
Progress[ 85%], ETA[  28m], Batch [22500], G_Loss[0.146], D_Real_Loss[0.190], D_Fake_Loss[0.421]
Progress[ 86%], ETA[  28m], Batch [22510], G_Loss[0.127], D_Real_Loss[0.586], D_Fake_Loss[0.649]
Progress[ 86%], ETA[  27m], Batch [22520], G_Loss[0.180], D_Real_Loss[0.849], D_Fake_Loss[0.281]
Progress[ 86%], ETA[  27m], Batch [22530], G_Loss[0.165], D_Real_Loss[0.205], D_Fake_Loss[0.346]
Progress[ 86%], ETA[  27m], Batch [22540], G_Loss[0.106], D_Real_Loss[0.422], D_Fake_Loss[0.718]
Progress[ 86%], ETA[  27m], Batch [22550], G_Loss[0.091], D_Real_Loss[0.208], D_Fake_Loss[0.913]
Progress[ 86%], ETA[  27m], Batch [22560], G_Loss[0.153], D_Real_Loss[0.584], D_Fake_Loss[0.411]
Progress[ 86%], ETA[  27m], Batch [22570], G_Loss[0.132], D_Real_Loss[0.426], D_Fake_Loss[0.489]
Progress[ 86%], ETA[  27m], Batch [22580], G_Loss[0.095], D_Real_Loss[0.446], D_Fake_Loss[0.801]
Progress[ 86%], ETA[  27m], Batch [22590], G_Loss[0.273], D_Real_Loss[0.589], D_Fake_Loss[0.105]
Progress[ 86%], ETA[  27m], Batch [22600], G_Loss[0.152], D_Real_Loss[0.824], D_Fake_Loss[0.410]
    Saved train/batch022600_out.png
Progress[ 86%], ETA[  27m], Batch [22610], G_Loss[0.151], D_Real_Loss[0.380], D_Fake_Loss[0.387]
Progress[ 86%], ETA[  27m], Batch [22620], G_Loss[0.197], D_Real_Loss[0.182], D_Fake_Loss[0.262]
Progress[ 86%], ETA[  27m], Batch [22630], G_Loss[0.249], D_Real_Loss[0.569], D_Fake_Loss[0.152]
Progress[ 86%], ETA[  27m], Batch [22640], G_Loss[0.178], D_Real_Loss[0.625], D_Fake_Loss[0.299]
Progress[ 86%], ETA[  27m], Batch [22650], G_Loss[0.100], D_Real_Loss[0.363], D_Fake_Loss[0.764]
Progress[ 86%], ETA[  27m], Batch [22660], G_Loss[0.235], D_Real_Loss[0.489], D_Fake_Loss[0.166]
Progress[ 86%], ETA[  26m], Batch [22670], G_Loss[0.211], D_Real_Loss[0.334], D_Fake_Loss[0.198]
Progress[ 86%], ETA[  26m], Batch [22680], G_Loss[0.188], D_Real_Loss[0.539], D_Fake_Loss[0.266]
Progress[ 86%], ETA[  26m], Batch [22690], G_Loss[0.141], D_Real_Loss[0.148], D_Fake_Loss[0.450]
Progress[ 86%], ETA[  26m], Batch [22700], G_Loss[0.161], D_Real_Loss[0.179], D_Fake_Loss[0.391]
Progress[ 86%], ETA[  26m], Batch [22710], G_Loss[0.120], D_Real_Loss[0.388], D_Fake_Loss[0.600]
Progress[ 86%], ETA[  26m], Batch [22720], G_Loss[0.278], D_Real_Loss[0.638], D_Fake_Loss[0.098]
Progress[ 86%], ETA[  26m], Batch [22730], G_Loss[0.116], D_Real_Loss[0.222], D_Fake_Loss[0.611]
Progress[ 86%], ETA[  26m], Batch [22740], G_Loss[0.130], D_Real_Loss[0.131], D_Fake_Loss[0.502]
Progress[ 86%], ETA[  26m], Batch [22750], G_Loss[0.138], D_Real_Loss[0.169], D_Fake_Loss[0.446]
Progress[ 86%], ETA[  26m], Batch [22760], G_Loss[0.154], D_Real_Loss[0.370], D_Fake_Loss[0.393]
Progress[ 86%], ETA[  26m], Batch [22770], G_Loss[0.170], D_Real_Loss[0.574], D_Fake_Loss[0.331]
Progress[ 86%], ETA[  26m], Batch [22780], G_Loss[0.144], D_Real_Loss[0.617], D_Fake_Loss[0.443]
Progress[ 86%], ETA[  26m], Batch [22790], G_Loss[0.163], D_Real_Loss[0.219], D_Fake_Loss[0.370]
Progress[ 86%], ETA[  26m], Batch [22800], G_Loss[0.126], D_Real_Loss[0.113], D_Fake_Loss[0.571]
    Saved train/batch022800_out.png
Progress[ 87%], ETA[  26m], Batch [22810], G_Loss[0.170], D_Real_Loss[0.351], D_Fake_Loss[0.339]
Progress[ 87%], ETA[  25m], Batch [22820], G_Loss[0.191], D_Real_Loss[0.677], D_Fake_Loss[0.256]
Progress[ 87%], ETA[  25m], Batch [22830], G_Loss[0.115], D_Real_Loss[0.205], D_Fake_Loss[0.642]
Progress[ 87%], ETA[  25m], Batch [22840], G_Loss[0.168], D_Real_Loss[0.595], D_Fake_Loss[0.348]
Progress[ 87%], ETA[  25m], Batch [22850], G_Loss[0.213], D_Real_Loss[0.473], D_Fake_Loss[0.197]
Progress[ 87%], ETA[  25m], Batch [22860], G_Loss[0.173], D_Real_Loss[0.746], D_Fake_Loss[0.323]
Progress[ 87%], ETA[  25m], Batch [22870], G_Loss[0.212], D_Real_Loss[0.232], D_Fake_Loss[0.224]
Progress[ 87%], ETA[  25m], Batch [22880], G_Loss[0.147], D_Real_Loss[0.598], D_Fake_Loss[0.464]
Progress[ 87%], ETA[  25m], Batch [22890], G_Loss[0.166], D_Real_Loss[0.319], D_Fake_Loss[0.353]
Progress[ 87%], ETA[  25m], Batch [22900], G_Loss[0.153], D_Real_Loss[0.306], D_Fake_Loss[0.406]
Progress[ 87%], ETA[  25m], Batch [22910], G_Loss[0.160], D_Real_Loss[0.140], D_Fake_Loss[0.354]
Progress[ 87%], ETA[  25m], Batch [22920], G_Loss[0.256], D_Real_Loss[0.953], D_Fake_Loss[0.131]
Progress[ 87%], ETA[  25m], Batch [22930], G_Loss[0.147], D_Real_Loss[0.613], D_Fake_Loss[0.443]
Progress[ 87%], ETA[  25m], Batch [22940], G_Loss[0.159], D_Real_Loss[0.399], D_Fake_Loss[0.360]
Progress[ 87%], ETA[  25m], Batch [22950], G_Loss[0.086], D_Real_Loss[0.300], D_Fake_Loss[1.041]
Progress[ 87%], ETA[  25m], Batch [22960], G_Loss[0.278], D_Real_Loss[0.429], D_Fake_Loss[0.101]
Progress[ 87%], ETA[  24m], Batch [22970], G_Loss[0.182], D_Real_Loss[0.431], D_Fake_Loss[0.326]
Progress[ 87%], ETA[  24m], Batch [22980], G_Loss[0.170], D_Real_Loss[0.260], D_Fake_Loss[0.318]
Progress[ 87%], ETA[  24m], Batch [22990], G_Loss[0.139], D_Real_Loss[0.416], D_Fake_Loss[0.507]
Progress[ 87%], ETA[  24m], Batch [23000], G_Loss[0.236], D_Real_Loss[0.150], D_Fake_Loss[0.173]
    Saved train/batch023000_out.png
Progress[ 87%], ETA[  24m], Batch [23010], G_Loss[0.099], D_Real_Loss[0.472], D_Fake_Loss[0.837]
Progress[ 87%], ETA[  24m], Batch [23020], G_Loss[0.227], D_Real_Loss[0.545], D_Fake_Loss[0.184]
Progress[ 87%], ETA[  24m], Batch [23030], G_Loss[0.159], D_Real_Loss[0.988], D_Fake_Loss[0.411]
Progress[ 87%], ETA[  24m], Batch [23040], G_Loss[0.203], D_Real_Loss[0.532], D_Fake_Loss[0.221]
Progress[ 87%], ETA[  24m], Batch [23050], G_Loss[0.091], D_Real_Loss[0.209], D_Fake_Loss[0.905]
Progress[ 87%], ETA[  24m], Batch [23060], G_Loss[0.179], D_Real_Loss[0.321], D_Fake_Loss[0.300]
Progress[ 87%], ETA[  24m], Batch [23070], G_Loss[0.131], D_Real_Loss[0.311], D_Fake_Loss[0.534]
Progress[ 87%], ETA[  24m], Batch [23080], G_Loss[0.158], D_Real_Loss[0.357], D_Fake_Loss[0.395]
Progress[ 87%], ETA[  24m], Batch [23090], G_Loss[0.185], D_Real_Loss[1.475], D_Fake_Loss[0.297]
Progress[ 87%], ETA[  24m], Batch [23100], G_Loss[0.173], D_Real_Loss[0.340], D_Fake_Loss[0.313]
Progress[ 87%], ETA[  24m], Batch [23110], G_Loss[0.135], D_Real_Loss[0.400], D_Fake_Loss[0.501]
Progress[ 88%], ETA[  23m], Batch [23120], G_Loss[0.127], D_Real_Loss[0.418], D_Fake_Loss[0.600]
Progress[ 88%], ETA[  23m], Batch [23130], G_Loss[0.127], D_Real_Loss[0.273], D_Fake_Loss[0.536]
Progress[ 88%], ETA[  23m], Batch [23140], G_Loss[0.210], D_Real_Loss[0.308], D_Fake_Loss[0.238]
Progress[ 88%], ETA[  23m], Batch [23150], G_Loss[0.176], D_Real_Loss[0.505], D_Fake_Loss[0.329]
Progress[ 88%], ETA[  23m], Batch [23160], G_Loss[0.206], D_Real_Loss[1.156], D_Fake_Loss[0.223]
Progress[ 88%], ETA[  23m], Batch [23170], G_Loss[0.231], D_Real_Loss[0.787], D_Fake_Loss[0.163]
Progress[ 88%], ETA[  23m], Batch [23180], G_Loss[0.133], D_Real_Loss[0.312], D_Fake_Loss[0.509]
Progress[ 88%], ETA[  23m], Batch [23190], G_Loss[0.199], D_Real_Loss[0.378], D_Fake_Loss[0.246]
Progress[ 88%], ETA[  23m], Batch [23200], G_Loss[0.142], D_Real_Loss[0.164], D_Fake_Loss[0.498]
    Saved train/batch023200_out.png
Progress[ 88%], ETA[  23m], Batch [23210], G_Loss[0.139], D_Real_Loss[0.768], D_Fake_Loss[0.484]
Progress[ 88%], ETA[  23m], Batch [23220], G_Loss[0.175], D_Real_Loss[0.439], D_Fake_Loss[0.324]
Progress[ 88%], ETA[  23m], Batch [23230], G_Loss[0.140], D_Real_Loss[0.244], D_Fake_Loss[0.484]
Progress[ 88%], ETA[  23m], Batch [23240], G_Loss[0.098], D_Real_Loss[0.488], D_Fake_Loss[0.798]
Progress[ 88%], ETA[  23m], Batch [23250], G_Loss[0.103], D_Real_Loss[0.711], D_Fake_Loss[0.793]
Progress[ 88%], ETA[  23m], Batch [23260], G_Loss[0.150], D_Real_Loss[0.305], D_Fake_Loss[0.451]
Progress[ 88%], ETA[  22m], Batch [23270], G_Loss[0.210], D_Real_Loss[0.548], D_Fake_Loss[0.194]
Progress[ 88%], ETA[  22m], Batch [23280], G_Loss[0.205], D_Real_Loss[0.240], D_Fake_Loss[0.235]
Progress[ 88%], ETA[  22m], Batch [23290], G_Loss[0.217], D_Real_Loss[0.735], D_Fake_Loss[0.193]
Progress[ 88%], ETA[  22m], Batch [23300], G_Loss[0.166], D_Real_Loss[1.099], D_Fake_Loss[0.336]
Progress[ 88%], ETA[  22m], Batch [23310], G_Loss[0.079], D_Real_Loss[0.193], D_Fake_Loss[1.133]
Progress[ 88%], ETA[  22m], Batch [23320], G_Loss[0.152], D_Real_Loss[0.259], D_Fake_Loss[0.404]
Progress[ 88%], ETA[  22m], Batch [23330], G_Loss[0.117], D_Real_Loss[0.381], D_Fake_Loss[0.607]
Progress[ 88%], ETA[  22m], Batch [23340], G_Loss[0.218], D_Real_Loss[0.433], D_Fake_Loss[0.208]
Progress[ 88%], ETA[  22m], Batch [23350], G_Loss[0.284], D_Real_Loss[0.400], D_Fake_Loss[0.098]
Progress[ 88%], ETA[  22m], Batch [23360], G_Loss[0.259], D_Real_Loss[0.430], D_Fake_Loss[0.121]
Progress[ 88%], ETA[  22m], Batch [23370], G_Loss[0.255], D_Real_Loss[1.100], D_Fake_Loss[0.130]
Progress[ 88%], ETA[  22m], Batch [23380], G_Loss[0.195], D_Real_Loss[0.514], D_Fake_Loss[0.279]
Progress[ 88%], ETA[  22m], Batch [23390], G_Loss[0.101], D_Real_Loss[0.364], D_Fake_Loss[0.830]
Progress[ 88%], ETA[  22m], Batch [23400], G_Loss[0.103], D_Real_Loss[0.231], D_Fake_Loss[0.758]
    Saved train/batch023400_out.png
Progress[ 88%], ETA[  22m], Batch [23410], G_Loss[0.151], D_Real_Loss[0.418], D_Fake_Loss[0.460]
Progress[ 89%], ETA[  21m], Batch [23420], G_Loss[0.118], D_Real_Loss[0.160], D_Fake_Loss[0.674]
Progress[ 89%], ETA[  21m], Batch [23430], G_Loss[0.185], D_Real_Loss[0.449], D_Fake_Loss[0.280]
Progress[ 89%], ETA[  21m], Batch [23440], G_Loss[0.163], D_Real_Loss[0.522], D_Fake_Loss[0.378]
Progress[ 89%], ETA[  21m], Batch [23450], G_Loss[0.149], D_Real_Loss[0.644], D_Fake_Loss[0.418]
Progress[ 89%], ETA[  21m], Batch [23460], G_Loss[0.143], D_Real_Loss[0.656], D_Fake_Loss[0.438]
Progress[ 89%], ETA[  21m], Batch [23470], G_Loss[0.146], D_Real_Loss[0.332], D_Fake_Loss[0.501]
Progress[ 89%], ETA[  21m], Batch [23480], G_Loss[0.144], D_Real_Loss[0.396], D_Fake_Loss[0.424]
Progress[ 89%], ETA[  21m], Batch [23490], G_Loss[0.139], D_Real_Loss[0.100], D_Fake_Loss[0.524]
Progress[ 89%], ETA[  21m], Batch [23500], G_Loss[0.140], D_Real_Loss[0.199], D_Fake_Loss[0.507]
Progress[ 89%], ETA[  21m], Batch [23510], G_Loss[0.105], D_Real_Loss[0.438], D_Fake_Loss[0.722]
Progress[ 89%], ETA[  21m], Batch [23520], G_Loss[0.208], D_Real_Loss[1.716], D_Fake_Loss[0.219]
Progress[ 89%], ETA[  21m], Batch [23530], G_Loss[0.192], D_Real_Loss[0.096], D_Fake_Loss[0.238]
Progress[ 89%], ETA[  21m], Batch [23540], G_Loss[0.273], D_Real_Loss[0.416], D_Fake_Loss[0.124]
Progress[ 89%], ETA[  21m], Batch [23550], G_Loss[0.106], D_Real_Loss[0.344], D_Fake_Loss[0.721]
Progress[ 89%], ETA[  21m], Batch [23560], G_Loss[0.166], D_Real_Loss[0.860], D_Fake_Loss[0.335]
Progress[ 89%], ETA[  20m], Batch [23570], G_Loss[0.136], D_Real_Loss[0.588], D_Fake_Loss[0.485]
Progress[ 89%], ETA[  20m], Batch [23580], G_Loss[0.130], D_Real_Loss[0.273], D_Fake_Loss[0.528]
Progress[ 89%], ETA[  20m], Batch [23590], G_Loss[0.158], D_Real_Loss[0.618], D_Fake_Loss[0.357]
Progress[ 89%], ETA[  20m], Batch [23600], G_Loss[0.206], D_Real_Loss[0.359], D_Fake_Loss[0.224]
    Saved train/batch023600_out.png
Progress[ 89%], ETA[  20m], Batch [23610], G_Loss[0.178], D_Real_Loss[0.255], D_Fake_Loss[0.302]
Progress[ 89%], ETA[  20m], Batch [23620], G_Loss[0.234], D_Real_Loss[0.574], D_Fake_Loss[0.161]
Progress[ 89%], ETA[  20m], Batch [23630], G_Loss[0.194], D_Real_Loss[0.449], D_Fake_Loss[0.295]
Progress[ 89%], ETA[  20m], Batch [23640], G_Loss[0.212], D_Real_Loss[0.788], D_Fake_Loss[0.205]
Progress[ 89%], ETA[  20m], Batch [23650], G_Loss[0.208], D_Real_Loss[0.613], D_Fake_Loss[0.217]
Progress[ 89%], ETA[  20m], Batch [23660], G_Loss[0.122], D_Real_Loss[0.263], D_Fake_Loss[0.582]
Progress[ 89%], ETA[  20m], Batch [23670], G_Loss[0.182], D_Real_Loss[0.239], D_Fake_Loss[0.281]
Progress[ 89%], ETA[  20m], Batch [23680], G_Loss[0.154], D_Real_Loss[0.718], D_Fake_Loss[0.396]
Progress[ 89%], ETA[  20m], Batch [23690], G_Loss[0.175], D_Real_Loss[0.749], D_Fake_Loss[0.300]
Progress[ 89%], ETA[  20m], Batch [23700], G_Loss[0.254], D_Real_Loss[0.474], D_Fake_Loss[0.140]
Progress[ 89%], ETA[  20m], Batch [23710], G_Loss[0.130], D_Real_Loss[0.504], D_Fake_Loss[0.503]
Progress[ 90%], ETA[  19m], Batch [23720], G_Loss[0.151], D_Real_Loss[0.331], D_Fake_Loss[0.431]
Progress[ 90%], ETA[  19m], Batch [23730], G_Loss[0.166], D_Real_Loss[0.552], D_Fake_Loss[0.331]
Progress[ 90%], ETA[  19m], Batch [23740], G_Loss[0.198], D_Real_Loss[0.405], D_Fake_Loss[0.233]
Progress[ 90%], ETA[  19m], Batch [23750], G_Loss[0.158], D_Real_Loss[0.766], D_Fake_Loss[0.359]
Progress[ 90%], ETA[  19m], Batch [23760], G_Loss[0.115], D_Real_Loss[0.138], D_Fake_Loss[0.621]
Progress[ 90%], ETA[  19m], Batch [23770], G_Loss[0.148], D_Real_Loss[0.423], D_Fake_Loss[0.407]
Progress[ 90%], ETA[  19m], Batch [23780], G_Loss[0.148], D_Real_Loss[0.206], D_Fake_Loss[0.468]
Progress[ 90%], ETA[  19m], Batch [23790], G_Loss[0.127], D_Real_Loss[0.259], D_Fake_Loss[0.555]
Progress[ 90%], ETA[  19m], Batch [23800], G_Loss[0.165], D_Real_Loss[0.746], D_Fake_Loss[0.344]
    Saved train/batch023800_out.png
Progress[ 90%], ETA[  19m], Batch [23810], G_Loss[0.253], D_Real_Loss[0.279], D_Fake_Loss[0.137]
Progress[ 90%], ETA[  19m], Batch [23820], G_Loss[0.201], D_Real_Loss[0.544], D_Fake_Loss[0.222]
Progress[ 90%], ETA[  19m], Batch [23830], G_Loss[0.192], D_Real_Loss[0.215], D_Fake_Loss[0.257]
Progress[ 90%], ETA[  19m], Batch [23840], G_Loss[0.132], D_Real_Loss[0.438], D_Fake_Loss[0.528]
Progress[ 90%], ETA[  19m], Batch [23850], G_Loss[0.238], D_Real_Loss[0.554], D_Fake_Loss[0.155]
Progress[ 90%], ETA[  19m], Batch [23860], G_Loss[0.202], D_Real_Loss[0.312], D_Fake_Loss[0.235]
Progress[ 90%], ETA[  18m], Batch [23870], G_Loss[0.106], D_Real_Loss[0.053], D_Fake_Loss[0.821]
Progress[ 90%], ETA[  18m], Batch [23880], G_Loss[0.179], D_Real_Loss[0.503], D_Fake_Loss[0.306]
Progress[ 90%], ETA[  18m], Batch [23890], G_Loss[0.144], D_Real_Loss[0.167], D_Fake_Loss[0.466]
Progress[ 90%], ETA[  18m], Batch [23900], G_Loss[0.251], D_Real_Loss[0.390], D_Fake_Loss[0.146]
Progress[ 90%], ETA[  18m], Batch [23910], G_Loss[0.151], D_Real_Loss[0.326], D_Fake_Loss[0.408]
Progress[ 90%], ETA[  18m], Batch [23920], G_Loss[0.263], D_Real_Loss[0.689], D_Fake_Loss[0.113]
Progress[ 90%], ETA[  18m], Batch [23930], G_Loss[0.107], D_Real_Loss[0.428], D_Fake_Loss[0.786]
Progress[ 90%], ETA[  18m], Batch [23940], G_Loss[0.164], D_Real_Loss[0.537], D_Fake_Loss[0.368]
Progress[ 90%], ETA[  18m], Batch [23950], G_Loss[0.148], D_Real_Loss[0.421], D_Fake_Loss[0.418]
Progress[ 90%], ETA[  18m], Batch [23960], G_Loss[0.160], D_Real_Loss[0.230], D_Fake_Loss[0.390]
Progress[ 90%], ETA[  18m], Batch [23970], G_Loss[0.132], D_Real_Loss[0.388], D_Fake_Loss[0.540]
Progress[ 90%], ETA[  18m], Batch [23980], G_Loss[0.214], D_Real_Loss[0.560], D_Fake_Loss[0.207]
Progress[ 90%], ETA[  18m], Batch [23990], G_Loss[0.080], D_Real_Loss[0.249], D_Fake_Loss[1.163]
Progress[ 90%], ETA[  18m], Batch [24000], G_Loss[0.235], D_Real_Loss[0.206], D_Fake_Loss[0.196]
    Saved train/batch024000_out.png
Progress[ 90%], ETA[  18m], Batch [24010], G_Loss[0.102], D_Real_Loss[0.364], D_Fake_Loss[0.769]
Progress[ 91%], ETA[  17m], Batch [24020], G_Loss[0.114], D_Real_Loss[0.145], D_Fake_Loss[0.692]
Progress[ 91%], ETA[  17m], Batch [24030], G_Loss[0.159], D_Real_Loss[0.274], D_Fake_Loss[0.359]
Progress[ 91%], ETA[  17m], Batch [24040], G_Loss[0.149], D_Real_Loss[0.188], D_Fake_Loss[0.415]
Progress[ 91%], ETA[  17m], Batch [24050], G_Loss[0.166], D_Real_Loss[0.585], D_Fake_Loss[0.360]
Progress[ 91%], ETA[  17m], Batch [24060], G_Loss[0.180], D_Real_Loss[0.139], D_Fake_Loss[0.306]
Progress[ 91%], ETA[  17m], Batch [24070], G_Loss[0.225], D_Real_Loss[0.260], D_Fake_Loss[0.205]
Progress[ 91%], ETA[  17m], Batch [24080], G_Loss[0.287], D_Real_Loss[0.350], D_Fake_Loss[0.106]
Progress[ 91%], ETA[  17m], Batch [24090], G_Loss[0.141], D_Real_Loss[0.395], D_Fake_Loss[0.466]
Progress[ 91%], ETA[  17m], Batch [24100], G_Loss[0.176], D_Real_Loss[0.473], D_Fake_Loss[0.312]
Progress[ 91%], ETA[  17m], Batch [24110], G_Loss[0.165], D_Real_Loss[0.166], D_Fake_Loss[0.365]
Progress[ 91%], ETA[  17m], Batch [24120], G_Loss[0.090], D_Real_Loss[0.454], D_Fake_Loss[1.009]
Progress[ 91%], ETA[  17m], Batch [24130], G_Loss[0.256], D_Real_Loss[0.210], D_Fake_Loss[0.134]
Progress[ 91%], ETA[  17m], Batch [24140], G_Loss[0.217], D_Real_Loss[0.227], D_Fake_Loss[0.198]
Progress[ 91%], ETA[  17m], Batch [24150], G_Loss[0.187], D_Real_Loss[0.397], D_Fake_Loss[0.308]
Progress[ 91%], ETA[  17m], Batch [24160], G_Loss[0.118], D_Real_Loss[0.302], D_Fake_Loss[0.674]
Progress[ 91%], ETA[  16m], Batch [24170], G_Loss[0.182], D_Real_Loss[0.543], D_Fake_Loss[0.307]
Progress[ 91%], ETA[  16m], Batch [24180], G_Loss[0.092], D_Real_Loss[0.175], D_Fake_Loss[1.140]
Progress[ 91%], ETA[  16m], Batch [24190], G_Loss[0.125], D_Real_Loss[0.341], D_Fake_Loss[0.628]
Progress[ 91%], ETA[  16m], Batch [24200], G_Loss[0.247], D_Real_Loss[0.376], D_Fake_Loss[0.137]
    Saved train/batch024200_out.png
Progress[ 91%], ETA[  16m], Batch [24210], G_Loss[0.237], D_Real_Loss[0.258], D_Fake_Loss[0.153]
Progress[ 91%], ETA[  16m], Batch [24220], G_Loss[0.200], D_Real_Loss[0.504], D_Fake_Loss[0.261]
Progress[ 91%], ETA[  16m], Batch [24230], G_Loss[0.226], D_Real_Loss[0.321], D_Fake_Loss[0.189]
Progress[ 91%], ETA[  16m], Batch [24240], G_Loss[0.119], D_Real_Loss[0.481], D_Fake_Loss[0.662]
Progress[ 91%], ETA[  16m], Batch [24250], G_Loss[0.172], D_Real_Loss[0.456], D_Fake_Loss[0.333]
Progress[ 91%], ETA[  16m], Batch [24260], G_Loss[0.157], D_Real_Loss[0.676], D_Fake_Loss[0.426]
Progress[ 91%], ETA[  16m], Batch [24270], G_Loss[0.159], D_Real_Loss[0.099], D_Fake_Loss[0.474]
Progress[ 91%], ETA[  16m], Batch [24280], G_Loss[0.189], D_Real_Loss[0.098], D_Fake_Loss[0.266]
Progress[ 91%], ETA[  16m], Batch [24290], G_Loss[0.319], D_Real_Loss[0.579], D_Fake_Loss[0.076]
Progress[ 91%], ETA[  16m], Batch [24300], G_Loss[0.196], D_Real_Loss[0.681], D_Fake_Loss[0.273]
Progress[ 91%], ETA[  16m], Batch [24310], G_Loss[0.196], D_Real_Loss[0.790], D_Fake_Loss[0.307]
Progress[ 92%], ETA[  15m], Batch [24320], G_Loss[0.132], D_Real_Loss[0.492], D_Fake_Loss[0.579]
Progress[ 92%], ETA[  15m], Batch [24330], G_Loss[0.124], D_Real_Loss[0.097], D_Fake_Loss[0.617]
Progress[ 92%], ETA[  15m], Batch [24340], G_Loss[0.185], D_Real_Loss[0.516], D_Fake_Loss[0.291]
Progress[ 92%], ETA[  15m], Batch [24350], G_Loss[0.129], D_Real_Loss[0.818], D_Fake_Loss[0.566]
Progress[ 92%], ETA[  15m], Batch [24360], G_Loss[0.180], D_Real_Loss[0.668], D_Fake_Loss[0.419]
Progress[ 92%], ETA[  15m], Batch [24370], G_Loss[0.143], D_Real_Loss[0.217], D_Fake_Loss[0.563]
Progress[ 92%], ETA[  15m], Batch [24380], G_Loss[0.136], D_Real_Loss[0.345], D_Fake_Loss[0.594]
Progress[ 92%], ETA[  15m], Batch [24390], G_Loss[0.247], D_Real_Loss[0.538], D_Fake_Loss[0.154]
Progress[ 92%], ETA[  15m], Batch [24400], G_Loss[0.210], D_Real_Loss[0.653], D_Fake_Loss[0.231]
    Saved train/batch024400_out.png
Progress[ 92%], ETA[  15m], Batch [24410], G_Loss[0.289], D_Real_Loss[0.462], D_Fake_Loss[0.103]
Progress[ 92%], ETA[  15m], Batch [24420], G_Loss[0.123], D_Real_Loss[0.771], D_Fake_Loss[0.600]
Progress[ 92%], ETA[  15m], Batch [24430], G_Loss[0.193], D_Real_Loss[0.205], D_Fake_Loss[0.282]
Progress[ 92%], ETA[  15m], Batch [24440], G_Loss[0.272], D_Real_Loss[0.530], D_Fake_Loss[0.122]
Progress[ 92%], ETA[  15m], Batch [24450], G_Loss[0.170], D_Real_Loss[0.309], D_Fake_Loss[0.361]
Progress[ 92%], ETA[  15m], Batch [24460], G_Loss[0.237], D_Real_Loss[0.534], D_Fake_Loss[0.190]
Progress[ 92%], ETA[  14m], Batch [24470], G_Loss[0.131], D_Real_Loss[0.112], D_Fake_Loss[0.567]
Progress[ 92%], ETA[  14m], Batch [24480], G_Loss[0.260], D_Real_Loss[0.494], D_Fake_Loss[0.131]
Progress[ 92%], ETA[  14m], Batch [24490], G_Loss[0.196], D_Real_Loss[0.577], D_Fake_Loss[0.266]
Progress[ 92%], ETA[  14m], Batch [24500], G_Loss[0.110], D_Real_Loss[0.146], D_Fake_Loss[0.750]
Progress[ 92%], ETA[  14m], Batch [24510], G_Loss[0.158], D_Real_Loss[0.174], D_Fake_Loss[0.421]
Progress[ 92%], ETA[  14m], Batch [24520], G_Loss[0.213], D_Real_Loss[0.280], D_Fake_Loss[0.225]
Progress[ 92%], ETA[  14m], Batch [24530], G_Loss[0.123], D_Real_Loss[0.183], D_Fake_Loss[0.581]
Progress[ 92%], ETA[  14m], Batch [24540], G_Loss[0.151], D_Real_Loss[0.397], D_Fake_Loss[0.467]
Progress[ 92%], ETA[  14m], Batch [24550], G_Loss[0.178], D_Real_Loss[0.439], D_Fake_Loss[0.350]
Progress[ 92%], ETA[  14m], Batch [24560], G_Loss[0.184], D_Real_Loss[0.644], D_Fake_Loss[0.298]
Progress[ 92%], ETA[  14m], Batch [24570], G_Loss[0.203], D_Real_Loss[0.056], D_Fake_Loss[0.254]
Progress[ 92%], ETA[  14m], Batch [24580], G_Loss[0.180], D_Real_Loss[0.530], D_Fake_Loss[0.352]
Progress[ 92%], ETA[  14m], Batch [24590], G_Loss[0.078], D_Real_Loss[0.304], D_Fake_Loss[1.237]
Progress[ 92%], ETA[  14m], Batch [24600], G_Loss[0.214], D_Real_Loss[0.391], D_Fake_Loss[0.243]
    Saved train/batch024600_out.png
Progress[ 92%], ETA[  14m], Batch [24610], G_Loss[0.294], D_Real_Loss[0.347], D_Fake_Loss[0.093]
Progress[ 93%], ETA[  13m], Batch [24620], G_Loss[0.114], D_Real_Loss[0.294], D_Fake_Loss[0.903]
Progress[ 93%], ETA[  13m], Batch [24630], G_Loss[0.148], D_Real_Loss[0.417], D_Fake_Loss[0.425]
Progress[ 93%], ETA[  13m], Batch [24640], G_Loss[0.119], D_Real_Loss[0.835], D_Fake_Loss[0.642]
Progress[ 93%], ETA[  13m], Batch [24650], G_Loss[0.080], D_Real_Loss[0.076], D_Fake_Loss[1.181]
Progress[ 93%], ETA[  13m], Batch [24660], G_Loss[0.091], D_Real_Loss[0.109], D_Fake_Loss[1.022]
Progress[ 93%], ETA[  13m], Batch [24670], G_Loss[0.127], D_Real_Loss[0.230], D_Fake_Loss[0.579]
Progress[ 93%], ETA[  13m], Batch [24680], G_Loss[0.095], D_Real_Loss[0.085], D_Fake_Loss[0.943]
Progress[ 93%], ETA[  13m], Batch [24690], G_Loss[0.128], D_Real_Loss[0.259], D_Fake_Loss[0.654]
Progress[ 93%], ETA[  13m], Batch [24700], G_Loss[0.226], D_Real_Loss[0.358], D_Fake_Loss[0.175]
Progress[ 93%], ETA[  13m], Batch [24710], G_Loss[0.169], D_Real_Loss[0.312], D_Fake_Loss[0.354]
Progress[ 93%], ETA[  13m], Batch [24720], G_Loss[0.188], D_Real_Loss[0.366], D_Fake_Loss[0.270]
Progress[ 93%], ETA[  13m], Batch [24730], G_Loss[0.153], D_Real_Loss[0.293], D_Fake_Loss[0.397]
Progress[ 93%], ETA[  13m], Batch [24740], G_Loss[0.169], D_Real_Loss[0.230], D_Fake_Loss[0.327]
Progress[ 93%], ETA[  13m], Batch [24750], G_Loss[0.232], D_Real_Loss[0.325], D_Fake_Loss[0.176]
Progress[ 93%], ETA[  13m], Batch [24760], G_Loss[0.105], D_Real_Loss[0.202], D_Fake_Loss[0.735]
Progress[ 93%], ETA[  12m], Batch [24770], G_Loss[0.110], D_Real_Loss[0.224], D_Fake_Loss[0.725]
Progress[ 93%], ETA[  12m], Batch [24780], G_Loss[0.138], D_Real_Loss[0.321], D_Fake_Loss[0.479]
Progress[ 93%], ETA[  12m], Batch [24790], G_Loss[0.162], D_Real_Loss[0.215], D_Fake_Loss[0.338]
Progress[ 93%], ETA[  12m], Batch [24800], G_Loss[0.187], D_Real_Loss[0.313], D_Fake_Loss[0.292]
    Saved train/batch024800_out.png
Progress[ 93%], ETA[  12m], Batch [24810], G_Loss[0.175], D_Real_Loss[1.553], D_Fake_Loss[0.299]
Progress[ 93%], ETA[  12m], Batch [24820], G_Loss[0.097], D_Real_Loss[0.284], D_Fake_Loss[0.793]
Progress[ 93%], ETA[  12m], Batch [24830], G_Loss[0.183], D_Real_Loss[0.423], D_Fake_Loss[0.314]
Progress[ 93%], ETA[  12m], Batch [24840], G_Loss[0.130], D_Real_Loss[0.249], D_Fake_Loss[0.531]
Progress[ 93%], ETA[  12m], Batch [24850], G_Loss[0.218], D_Real_Loss[0.496], D_Fake_Loss[0.199]
Progress[ 93%], ETA[  12m], Batch [24860], G_Loss[0.078], D_Real_Loss[0.381], D_Fake_Loss[1.257]
Progress[ 93%], ETA[  12m], Batch [24870], G_Loss[0.137], D_Real_Loss[0.208], D_Fake_Loss[0.515]
Progress[ 93%], ETA[  12m], Batch [24880], G_Loss[0.137], D_Real_Loss[0.379], D_Fake_Loss[0.475]
Progress[ 93%], ETA[  12m], Batch [24890], G_Loss[0.103], D_Real_Loss[0.264], D_Fake_Loss[0.804]
Progress[ 93%], ETA[  12m], Batch [24900], G_Loss[0.162], D_Real_Loss[0.303], D_Fake_Loss[0.357]
Progress[ 93%], ETA[  12m], Batch [24910], G_Loss[0.162], D_Real_Loss[0.254], D_Fake_Loss[0.369]
Progress[ 94%], ETA[  11m], Batch [24920], G_Loss[0.125], D_Real_Loss[0.390], D_Fake_Loss[0.547]
Progress[ 94%], ETA[  11m], Batch [24930], G_Loss[0.203], D_Real_Loss[0.425], D_Fake_Loss[0.236]
Progress[ 94%], ETA[  11m], Batch [24940], G_Loss[0.157], D_Real_Loss[0.390], D_Fake_Loss[0.374]
Progress[ 94%], ETA[  11m], Batch [24950], G_Loss[0.094], D_Real_Loss[0.110], D_Fake_Loss[0.879]
Progress[ 94%], ETA[  11m], Batch [24960], G_Loss[0.192], D_Real_Loss[0.464], D_Fake_Loss[0.262]
Progress[ 94%], ETA[  11m], Batch [24970], G_Loss[0.196], D_Real_Loss[0.297], D_Fake_Loss[0.237]
Progress[ 94%], ETA[  11m], Batch [24980], G_Loss[0.162], D_Real_Loss[0.482], D_Fake_Loss[0.357]
Progress[ 94%], ETA[  11m], Batch [24990], G_Loss[0.225], D_Real_Loss[0.689], D_Fake_Loss[0.174]
Progress[ 94%], ETA[  11m], Batch [25000], G_Loss[0.180], D_Real_Loss[0.214], D_Fake_Loss[0.308]
    Saved train/batch025000_out.png
Progress[ 94%], ETA[  11m], Batch [25010], G_Loss[0.151], D_Real_Loss[0.351], D_Fake_Loss[0.417]
Progress[ 94%], ETA[  11m], Batch [25020], G_Loss[0.130], D_Real_Loss[0.151], D_Fake_Loss[0.509]
Progress[ 94%], ETA[  11m], Batch [25030], G_Loss[0.215], D_Real_Loss[0.718], D_Fake_Loss[0.198]
Progress[ 94%], ETA[  11m], Batch [25040], G_Loss[0.120], D_Real_Loss[0.698], D_Fake_Loss[0.614]
Progress[ 94%], ETA[  11m], Batch [25050], G_Loss[0.237], D_Real_Loss[0.874], D_Fake_Loss[0.166]
Progress[ 94%], ETA[  11m], Batch [25060], G_Loss[0.151], D_Real_Loss[0.193], D_Fake_Loss[0.379]
Progress[ 94%], ETA[  10m], Batch [25070], G_Loss[0.216], D_Real_Loss[1.023], D_Fake_Loss[0.199]
Progress[ 94%], ETA[  10m], Batch [25080], G_Loss[0.132], D_Real_Loss[0.372], D_Fake_Loss[0.539]
Progress[ 94%], ETA[  10m], Batch [25090], G_Loss[0.188], D_Real_Loss[0.624], D_Fake_Loss[0.258]
Progress[ 94%], ETA[  10m], Batch [25100], G_Loss[0.126], D_Real_Loss[0.405], D_Fake_Loss[0.581]
Progress[ 94%], ETA[  10m], Batch [25110], G_Loss[0.138], D_Real_Loss[0.448], D_Fake_Loss[0.452]
Progress[ 94%], ETA[  10m], Batch [25120], G_Loss[0.208], D_Real_Loss[0.366], D_Fake_Loss[0.242]
Progress[ 94%], ETA[  10m], Batch [25130], G_Loss[0.170], D_Real_Loss[0.336], D_Fake_Loss[0.335]
Progress[ 94%], ETA[  10m], Batch [25140], G_Loss[0.140], D_Real_Loss[0.386], D_Fake_Loss[0.510]
Progress[ 94%], ETA[  10m], Batch [25150], G_Loss[0.150], D_Real_Loss[0.402], D_Fake_Loss[0.388]
Progress[ 94%], ETA[  10m], Batch [25160], G_Loss[0.166], D_Real_Loss[0.225], D_Fake_Loss[0.348]
Progress[ 94%], ETA[  10m], Batch [25170], G_Loss[0.172], D_Real_Loss[0.726], D_Fake_Loss[0.336]
Progress[ 94%], ETA[  10m], Batch [25180], G_Loss[0.154], D_Real_Loss[0.569], D_Fake_Loss[0.426]
Progress[ 94%], ETA[  10m], Batch [25190], G_Loss[0.133], D_Real_Loss[0.624], D_Fake_Loss[0.530]
Progress[ 94%], ETA[  10m], Batch [25200], G_Loss[0.132], D_Real_Loss[0.788], D_Fake_Loss[0.499]
    Saved train/batch025200_out.png
Progress[ 94%], ETA[  10m], Batch [25210], G_Loss[0.226], D_Real_Loss[1.174], D_Fake_Loss[0.178]
Progress[ 95%], ETA[   9m], Batch [25220], G_Loss[0.235], D_Real_Loss[0.396], D_Fake_Loss[0.180]
Progress[ 95%], ETA[   9m], Batch [25230], G_Loss[0.140], D_Real_Loss[0.568], D_Fake_Loss[0.474]
Progress[ 95%], ETA[   9m], Batch [25240], G_Loss[0.237], D_Real_Loss[0.375], D_Fake_Loss[0.157]
Progress[ 95%], ETA[   9m], Batch [25250], G_Loss[0.165], D_Real_Loss[0.459], D_Fake_Loss[0.362]
Progress[ 95%], ETA[   9m], Batch [25260], G_Loss[0.101], D_Real_Loss[0.433], D_Fake_Loss[0.782]
Progress[ 95%], ETA[   9m], Batch [25270], G_Loss[0.175], D_Real_Loss[0.828], D_Fake_Loss[0.307]
Progress[ 95%], ETA[   9m], Batch [25280], G_Loss[0.234], D_Real_Loss[0.903], D_Fake_Loss[0.159]
Progress[ 95%], ETA[   9m], Batch [25290], G_Loss[0.197], D_Real_Loss[0.647], D_Fake_Loss[0.243]
Progress[ 95%], ETA[   9m], Batch [25300], G_Loss[0.192], D_Real_Loss[0.562], D_Fake_Loss[0.244]
Progress[ 95%], ETA[   9m], Batch [25310], G_Loss[0.093], D_Real_Loss[0.048], D_Fake_Loss[1.277]
Progress[ 95%], ETA[   9m], Batch [25320], G_Loss[0.215], D_Real_Loss[0.283], D_Fake_Loss[0.204]
Progress[ 95%], ETA[   9m], Batch [25330], G_Loss[0.150], D_Real_Loss[1.274], D_Fake_Loss[0.405]
Progress[ 95%], ETA[   9m], Batch [25340], G_Loss[0.144], D_Real_Loss[0.290], D_Fake_Loss[0.438]
Progress[ 95%], ETA[   9m], Batch [25350], G_Loss[0.127], D_Real_Loss[0.379], D_Fake_Loss[0.585]
Progress[ 95%], ETA[   9m], Batch [25360], G_Loss[0.196], D_Real_Loss[0.470], D_Fake_Loss[0.241]
Progress[ 95%], ETA[   9m], Batch [25370], G_Loss[0.252], D_Real_Loss[0.207], D_Fake_Loss[0.137]
Progress[ 95%], ETA[   8m], Batch [25380], G_Loss[0.180], D_Real_Loss[0.396], D_Fake_Loss[0.321]
Progress[ 95%], ETA[   8m], Batch [25390], G_Loss[0.210], D_Real_Loss[0.933], D_Fake_Loss[0.198]
Progress[ 95%], ETA[   8m], Batch [25400], G_Loss[0.182], D_Real_Loss[0.383], D_Fake_Loss[0.280]
    Saved train/batch025400_out.png
Progress[ 95%], ETA[   8m], Batch [25410], G_Loss[0.176], D_Real_Loss[1.091], D_Fake_Loss[0.292]
Progress[ 95%], ETA[   8m], Batch [25420], G_Loss[0.154], D_Real_Loss[0.680], D_Fake_Loss[0.374]
Progress[ 95%], ETA[   8m], Batch [25430], G_Loss[0.170], D_Real_Loss[0.670], D_Fake_Loss[0.316]
Progress[ 95%], ETA[   8m], Batch [25440], G_Loss[0.120], D_Real_Loss[0.152], D_Fake_Loss[0.603]
Progress[ 95%], ETA[   8m], Batch [25450], G_Loss[0.177], D_Real_Loss[0.596], D_Fake_Loss[0.294]
Progress[ 95%], ETA[   8m], Batch [25460], G_Loss[0.099], D_Real_Loss[0.249], D_Fake_Loss[0.835]
Progress[ 95%], ETA[   8m], Batch [25470], G_Loss[0.231], D_Real_Loss[0.623], D_Fake_Loss[0.170]
Progress[ 95%], ETA[   8m], Batch [25480], G_Loss[0.095], D_Real_Loss[0.510], D_Fake_Loss[0.889]
Progress[ 95%], ETA[   8m], Batch [25490], G_Loss[0.156], D_Real_Loss[0.406], D_Fake_Loss[0.428]
Progress[ 95%], ETA[   8m], Batch [25500], G_Loss[0.235], D_Real_Loss[0.119], D_Fake_Loss[0.169]
Progress[ 95%], ETA[   8m], Batch [25510], G_Loss[0.211], D_Real_Loss[0.343], D_Fake_Loss[0.231]
Progress[ 96%], ETA[   7m], Batch [25520], G_Loss[0.130], D_Real_Loss[0.076], D_Fake_Loss[0.508]
Progress[ 96%], ETA[   7m], Batch [25530], G_Loss[0.167], D_Real_Loss[0.176], D_Fake_Loss[0.335]
Progress[ 96%], ETA[   7m], Batch [25540], G_Loss[0.185], D_Real_Loss[0.314], D_Fake_Loss[0.268]
Progress[ 96%], ETA[   7m], Batch [25550], G_Loss[0.204], D_Real_Loss[0.543], D_Fake_Loss[0.231]
Progress[ 96%], ETA[   7m], Batch [25560], G_Loss[0.144], D_Real_Loss[0.068], D_Fake_Loss[0.425]
Progress[ 96%], ETA[   7m], Batch [25570], G_Loss[0.179], D_Real_Loss[0.851], D_Fake_Loss[0.288]
Progress[ 96%], ETA[   7m], Batch [25580], G_Loss[0.139], D_Real_Loss[0.214], D_Fake_Loss[0.519]
Progress[ 96%], ETA[   7m], Batch [25590], G_Loss[0.319], D_Real_Loss[1.067], D_Fake_Loss[0.066]
Progress[ 96%], ETA[   7m], Batch [25600], G_Loss[0.121], D_Real_Loss[0.382], D_Fake_Loss[0.575]
    Saved train/batch025600_out.png
Progress[ 96%], ETA[   7m], Batch [25610], G_Loss[0.167], D_Real_Loss[0.383], D_Fake_Loss[0.341]
Progress[ 96%], ETA[   7m], Batch [25620], G_Loss[0.090], D_Real_Loss[0.302], D_Fake_Loss[1.037]
Progress[ 96%], ETA[   7m], Batch [25630], G_Loss[0.140], D_Real_Loss[0.486], D_Fake_Loss[0.458]
Progress[ 96%], ETA[   7m], Batch [25640], G_Loss[0.123], D_Real_Loss[0.275], D_Fake_Loss[0.566]
Progress[ 96%], ETA[   7m], Batch [25650], G_Loss[0.178], D_Real_Loss[0.464], D_Fake_Loss[0.297]
Progress[ 96%], ETA[   7m], Batch [25660], G_Loss[0.185], D_Real_Loss[0.323], D_Fake_Loss[0.284]
Progress[ 96%], ETA[   6m], Batch [25670], G_Loss[0.170], D_Real_Loss[0.264], D_Fake_Loss[0.313]
Progress[ 96%], ETA[   6m], Batch [25680], G_Loss[0.227], D_Real_Loss[0.510], D_Fake_Loss[0.184]
Progress[ 96%], ETA[   6m], Batch [25690], G_Loss[0.111], D_Real_Loss[0.134], D_Fake_Loss[0.718]
Progress[ 96%], ETA[   6m], Batch [25700], G_Loss[0.195], D_Real_Loss[0.548], D_Fake_Loss[0.257]
Progress[ 96%], ETA[   6m], Batch [25710], G_Loss[0.253], D_Real_Loss[0.184], D_Fake_Loss[0.146]
Progress[ 96%], ETA[   6m], Batch [25720], G_Loss[0.153], D_Real_Loss[0.216], D_Fake_Loss[0.451]
Progress[ 96%], ETA[   6m], Batch [25730], G_Loss[0.108], D_Real_Loss[0.465], D_Fake_Loss[0.688]
Progress[ 96%], ETA[   6m], Batch [25740], G_Loss[0.138], D_Real_Loss[0.192], D_Fake_Loss[0.541]
Progress[ 96%], ETA[   6m], Batch [25750], G_Loss[0.214], D_Real_Loss[0.515], D_Fake_Loss[0.189]
Progress[ 96%], ETA[   6m], Batch [25760], G_Loss[0.168], D_Real_Loss[0.300], D_Fake_Loss[0.332]
Progress[ 96%], ETA[   6m], Batch [25770], G_Loss[0.260], D_Real_Loss[1.141], D_Fake_Loss[0.124]
Progress[ 96%], ETA[   6m], Batch [25780], G_Loss[0.181], D_Real_Loss[1.002], D_Fake_Loss[0.309]
Progress[ 96%], ETA[   6m], Batch [25790], G_Loss[0.125], D_Real_Loss[0.169], D_Fake_Loss[0.550]
Progress[ 96%], ETA[   6m], Batch [25800], G_Loss[0.136], D_Real_Loss[0.220], D_Fake_Loss[0.534]
    Saved train/batch025800_out.png
Progress[ 96%], ETA[   6m], Batch [25810], G_Loss[0.191], D_Real_Loss[1.283], D_Fake_Loss[0.272]
Progress[ 97%], ETA[   5m], Batch [25820], G_Loss[0.227], D_Real_Loss[0.381], D_Fake_Loss[0.176]
Progress[ 97%], ETA[   5m], Batch [25830], G_Loss[0.122], D_Real_Loss[0.665], D_Fake_Loss[0.610]
Progress[ 97%], ETA[   5m], Batch [25840], G_Loss[0.188], D_Real_Loss[0.524], D_Fake_Loss[0.325]
Progress[ 97%], ETA[   5m], Batch [25850], G_Loss[0.167], D_Real_Loss[0.844], D_Fake_Loss[0.403]
Progress[ 97%], ETA[   5m], Batch [25860], G_Loss[0.150], D_Real_Loss[0.236], D_Fake_Loss[0.400]
Progress[ 97%], ETA[   5m], Batch [25870], G_Loss[0.164], D_Real_Loss[0.320], D_Fake_Loss[0.353]
Progress[ 97%], ETA[   5m], Batch [25880], G_Loss[0.098], D_Real_Loss[0.417], D_Fake_Loss[0.830]
Progress[ 97%], ETA[   5m], Batch [25890], G_Loss[0.150], D_Real_Loss[0.385], D_Fake_Loss[0.451]
Progress[ 97%], ETA[   5m], Batch [25900], G_Loss[0.243], D_Real_Loss[0.449], D_Fake_Loss[0.148]
Progress[ 97%], ETA[   5m], Batch [25910], G_Loss[0.192], D_Real_Loss[0.436], D_Fake_Loss[0.275]
Progress[ 97%], ETA[   5m], Batch [25920], G_Loss[0.090], D_Real_Loss[0.520], D_Fake_Loss[0.931]
Progress[ 97%], ETA[   5m], Batch [25930], G_Loss[0.153], D_Real_Loss[0.504], D_Fake_Loss[0.420]
Progress[ 97%], ETA[   5m], Batch [25940], G_Loss[0.157], D_Real_Loss[0.645], D_Fake_Loss[0.391]
Progress[ 97%], ETA[   5m], Batch [25950], G_Loss[0.135], D_Real_Loss[1.497], D_Fake_Loss[0.516]
Progress[ 97%], ETA[   5m], Batch [25960], G_Loss[0.151], D_Real_Loss[0.254], D_Fake_Loss[0.390]
Progress[ 97%], ETA[   5m], Batch [25970], G_Loss[0.200], D_Real_Loss[0.337], D_Fake_Loss[0.228]
Progress[ 97%], ETA[   4m], Batch [25980], G_Loss[0.262], D_Real_Loss[0.482], D_Fake_Loss[0.116]
Progress[ 97%], ETA[   4m], Batch [25990], G_Loss[0.182], D_Real_Loss[0.204], D_Fake_Loss[0.290]
Progress[ 97%], ETA[   4m], Batch [26000], G_Loss[0.122], D_Real_Loss[0.216], D_Fake_Loss[0.591]
    Saved train/batch026000_out.png
Progress[ 97%], ETA[   4m], Batch [26010], G_Loss[0.068], D_Real_Loss[0.155], D_Fake_Loss[1.397]
Progress[ 97%], ETA[   4m], Batch [26020], G_Loss[0.245], D_Real_Loss[0.572], D_Fake_Loss[0.141]
Progress[ 97%], ETA[   4m], Batch [26030], G_Loss[0.169], D_Real_Loss[0.261], D_Fake_Loss[0.326]
Progress[ 97%], ETA[   4m], Batch [26040], G_Loss[0.127], D_Real_Loss[0.270], D_Fake_Loss[0.528]
Progress[ 97%], ETA[   4m], Batch [26050], G_Loss[0.202], D_Real_Loss[0.387], D_Fake_Loss[0.236]
Progress[ 97%], ETA[   4m], Batch [26060], G_Loss[0.098], D_Real_Loss[0.313], D_Fake_Loss[0.894]
Progress[ 97%], ETA[   4m], Batch [26070], G_Loss[0.156], D_Real_Loss[0.201], D_Fake_Loss[0.398]
Progress[ 97%], ETA[   4m], Batch [26080], G_Loss[0.225], D_Real_Loss[0.423], D_Fake_Loss[0.190]
Progress[ 97%], ETA[   4m], Batch [26090], G_Loss[0.268], D_Real_Loss[0.191], D_Fake_Loss[0.108]
Progress[ 97%], ETA[   4m], Batch [26100], G_Loss[0.252], D_Real_Loss[0.782], D_Fake_Loss[0.145]
Progress[ 97%], ETA[   4m], Batch [26110], G_Loss[0.188], D_Real_Loss[0.964], D_Fake_Loss[0.274]
Progress[ 98%], ETA[   4m], Batch [26120], G_Loss[0.155], D_Real_Loss[0.167], D_Fake_Loss[0.410]
Progress[ 98%], ETA[   3m], Batch [26130], G_Loss[0.125], D_Real_Loss[0.154], D_Fake_Loss[0.594]
Progress[ 98%], ETA[   3m], Batch [26140], G_Loss[0.223], D_Real_Loss[0.298], D_Fake_Loss[0.176]
Progress[ 98%], ETA[   3m], Batch [26150], G_Loss[0.146], D_Real_Loss[0.620], D_Fake_Loss[0.503]
Progress[ 98%], ETA[   3m], Batch [26160], G_Loss[0.154], D_Real_Loss[0.162], D_Fake_Loss[0.426]
Progress[ 98%], ETA[   3m], Batch [26170], G_Loss[0.181], D_Real_Loss[0.414], D_Fake_Loss[0.307]
Progress[ 98%], ETA[   3m], Batch [26180], G_Loss[0.077], D_Real_Loss[0.300], D_Fake_Loss[1.146]
Progress[ 98%], ETA[   3m], Batch [26190], G_Loss[0.092], D_Real_Loss[0.345], D_Fake_Loss[0.899]
Progress[ 98%], ETA[   3m], Batch [26200], G_Loss[0.148], D_Real_Loss[0.729], D_Fake_Loss[0.441]
    Saved train/batch026200_out.png
Progress[ 98%], ETA[   3m], Batch [26210], G_Loss[0.203], D_Real_Loss[0.376], D_Fake_Loss[0.237]
Progress[ 98%], ETA[   3m], Batch [26220], G_Loss[0.097], D_Real_Loss[0.310], D_Fake_Loss[0.845]
Progress[ 98%], ETA[   3m], Batch [26230], G_Loss[0.110], D_Real_Loss[0.228], D_Fake_Loss[0.670]
Progress[ 98%], ETA[   3m], Batch [26240], G_Loss[0.141], D_Real_Loss[0.878], D_Fake_Loss[0.463]
Progress[ 98%], ETA[   3m], Batch [26250], G_Loss[0.124], D_Real_Loss[0.225], D_Fake_Loss[0.583]
Progress[ 98%], ETA[   3m], Batch [26260], G_Loss[0.096], D_Real_Loss[0.279], D_Fake_Loss[0.826]
Progress[ 98%], ETA[   3m], Batch [26270], G_Loss[0.219], D_Real_Loss[0.128], D_Fake_Loss[0.213]
Progress[ 98%], ETA[   2m], Batch [26280], G_Loss[0.126], D_Real_Loss[0.438], D_Fake_Loss[0.554]
Progress[ 98%], ETA[   2m], Batch [26290], G_Loss[0.231], D_Real_Loss[1.018], D_Fake_Loss[0.164]
Progress[ 98%], ETA[   2m], Batch [26300], G_Loss[0.137], D_Real_Loss[0.277], D_Fake_Loss[0.452]
Progress[ 98%], ETA[   2m], Batch [26310], G_Loss[0.172], D_Real_Loss[0.121], D_Fake_Loss[0.333]
Progress[ 98%], ETA[   2m], Batch [26320], G_Loss[0.208], D_Real_Loss[0.499], D_Fake_Loss[0.204]
Progress[ 98%], ETA[   2m], Batch [26330], G_Loss[0.127], D_Real_Loss[0.788], D_Fake_Loss[0.603]
Progress[ 98%], ETA[   2m], Batch [26340], G_Loss[0.102], D_Real_Loss[0.204], D_Fake_Loss[0.800]
Progress[ 98%], ETA[   2m], Batch [26350], G_Loss[0.188], D_Real_Loss[0.471], D_Fake_Loss[0.269]
Progress[ 98%], ETA[   2m], Batch [26360], G_Loss[0.158], D_Real_Loss[0.522], D_Fake_Loss[0.381]
Progress[ 98%], ETA[   2m], Batch [26370], G_Loss[0.208], D_Real_Loss[0.107], D_Fake_Loss[0.233]
Progress[ 98%], ETA[   2m], Batch [26380], G_Loss[0.148], D_Real_Loss[0.653], D_Fake_Loss[0.402]
Progress[ 98%], ETA[   2m], Batch [26390], G_Loss[0.125], D_Real_Loss[0.373], D_Fake_Loss[0.570]
Progress[ 98%], ETA[   2m], Batch [26400], G_Loss[0.249], D_Real_Loss[0.479], D_Fake_Loss[0.172]
    Saved train/batch026400_out.png
Progress[ 98%], ETA[   2m], Batch [26410], G_Loss[0.169], D_Real_Loss[0.414], D_Fake_Loss[0.361]
Progress[ 99%], ETA[   2m], Batch [26420], G_Loss[0.126], D_Real_Loss[0.372], D_Fake_Loss[0.545]
Progress[ 99%], ETA[   1m], Batch [26430], G_Loss[0.207], D_Real_Loss[0.656], D_Fake_Loss[0.222]
Progress[ 99%], ETA[   1m], Batch [26440], G_Loss[0.183], D_Real_Loss[0.626], D_Fake_Loss[0.289]
Progress[ 99%], ETA[   1m], Batch [26450], G_Loss[0.083], D_Real_Loss[0.276], D_Fake_Loss[1.000]
Progress[ 99%], ETA[   1m], Batch [26460], G_Loss[0.186], D_Real_Loss[1.169], D_Fake_Loss[0.299]
Progress[ 99%], ETA[   1m], Batch [26470], G_Loss[0.227], D_Real_Loss[0.329], D_Fake_Loss[0.174]
Progress[ 99%], ETA[   1m], Batch [26480], G_Loss[0.147], D_Real_Loss[0.077], D_Fake_Loss[0.450]
Progress[ 99%], ETA[   1m], Batch [26490], G_Loss[0.237], D_Real_Loss[1.354], D_Fake_Loss[0.161]
Progress[ 99%], ETA[   1m], Batch [26500], G_Loss[0.265], D_Real_Loss[0.303], D_Fake_Loss[0.112]
Progress[ 99%], ETA[   1m], Batch [26510], G_Loss[0.128], D_Real_Loss[0.864], D_Fake_Loss[0.541]
Progress[ 99%], ETA[   1m], Batch [26520], G_Loss[0.279], D_Real_Loss[0.520], D_Fake_Loss[0.111]
Progress[ 99%], ETA[   1m], Batch [26530], G_Loss[0.106], D_Real_Loss[0.336], D_Fake_Loss[0.735]
Progress[ 99%], ETA[   1m], Batch [26540], G_Loss[0.186], D_Real_Loss[0.654], D_Fake_Loss[0.272]
Progress[ 99%], ETA[   1m], Batch [26550], G_Loss[0.163], D_Real_Loss[0.293], D_Fake_Loss[0.347]
Progress[ 99%], ETA[   1m], Batch [26560], G_Loss[0.158], D_Real_Loss[0.287], D_Fake_Loss[0.366]
Progress[ 99%], ETA[   1m], Batch [26570], G_Loss[0.133], D_Real_Loss[0.434], D_Fake_Loss[0.499]
Progress[ 99%], ETA[   0m], Batch [26580], G_Loss[0.148], D_Real_Loss[0.451], D_Fake_Loss[0.412]
Progress[ 99%], ETA[   0m], Batch [26590], G_Loss[0.131], D_Real_Loss[0.101], D_Fake_Loss[0.516]
Progress[ 99%], ETA[   0m], Batch [26600], G_Loss[0.167], D_Real_Loss[0.392], D_Fake_Loss[0.335]
    Saved train/batch026600_out.png
Progress[ 99%], ETA[   0m], Batch [26610], G_Loss[0.244], D_Real_Loss[0.441], D_Fake_Loss[0.139]
Progress[ 99%], ETA[   0m], Batch [26620], G_Loss[0.134], D_Real_Loss[0.046], D_Fake_Loss[0.505]
Progress[ 99%], ETA[   0m], Batch [26630], G_Loss[0.136], D_Real_Loss[0.304], D_Fake_Loss[0.553]
Progress[ 99%], ETA[   0m], Batch [26640], G_Loss[0.115], D_Real_Loss[0.181], D_Fake_Loss[0.668]
Progress[ 99%], ETA[   0m], Batch [26650], G_Loss[0.252], D_Real_Loss[0.359], D_Fake_Loss[0.128]
Progress[ 99%], ETA[   0m], Batch [26660], G_Loss[0.179], D_Real_Loss[0.462], D_Fake_Loss[0.309]
Progress[ 99%], ETA[   0m], Batch [26670], G_Loss[0.315], D_Real_Loss[0.600], D_Fake_Loss[0.075]
Progress[ 99%], ETA[   0m], Batch [26680], G_Loss[0.265], D_Real_Loss[0.354], D_Fake_Loss[0.121]
Progress[ 99%], ETA[   0m], Batch [26690], G_Loss[0.141], D_Real_Loss[0.229], D_Fake_Loss[0.424]
Progress[ 99%], ETA[   0m], Batch [26700], G_Loss[0.224], D_Real_Loss[0.060], D_Fake_Loss[0.175]
Progress[ 99%], ETA[   0m], Batch [26710], G_Loss[0.180], D_Real_Loss[0.490], D_Fake_Loss[0.302]
Progress[100%], ETA[   0m], Batch [26720], G_Loss[0.144], D_Real_Loss[0.366], D_Fake_Loss[0.438]
    Checkpoint saved
Finished training!
